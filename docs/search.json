[
  {
    "objectID": "mc-stan-org/developers.html",
    "href": "mc-stan-org/developers.html",
    "title": "Stan Project’s Software Development Lifecycle",
    "section": "",
    "text": "The development, release, and maintenance of Stan is a collaborative process involving the Stan development team. The team covers multiple statistical and computational disciplines and its members work in academia, industry, or both. The Stan project employs standard software development, code review, and testing methodologies.\nThis document describes the software development lifecycle (SDLC) for projects managed by the Stan project and hosted by Stan’s GitHub organization stan-dev. Projects covered include the math library, core C++ algorithms, parser and code generator, and all of the interface and visualization packages.\nThe layout and content of this document very closely follows the R regulatory compliance and validation document.\n\n\nCommunication among team members takes place in several venues. Most discussions take place openly on the Stan forum.\n\nStan’s forum is hosted by Discourse at http://discourse.mc-stan.org\n\nThe Stan forums are archived and may be read by anyone at any time. Communication that’s not suitable for the public, such as grant funding, is carried out on a private group restricted to the core Stan developers. Further issue-specific discussion takes place concurrently with development and source control.\n\nStan’s issue trackers are hosted by GitHub.\n\nBigger design issues require design documents in the form of a community RFC.\n\nstan/dev:design-docs is hosted on GitHub\n\nVarious project meetings among developers and users take place online in various forums including Zoom and Google Hangouts. These are not recorded or stored. Developers also meet informally at their places of employment or at conferences and workshops when multiple team members are in attendance. The developers also host meetups for the public in locations including Berlin, Boston, London, Sydney, and New York.\n\n\n\nStan’s C++ library and the CmdStan interface are released under the terms of the new (3 clause) BSD license, with two dependent libraries (Boost and Eigen), released under compatible libraries. The R interface RStan and Python interface PyStan are released under the GPLv3 license.\n\n\n\nThe size of the Stan community is difficult to estimate reliably because there are no sales transactions and Stan’s version control distribution system (GitHub) does not provide download statistics. There were over 2000 users subscribed the users group on Google before it was moved to Discourse, on which there are dozens of active threads at any given time. This substantial user base provides the means to do continuous reviews of real-world performance in real settings. Unlike proprietary software only available in binary form, Stan’s open-source code base allows users to provide feedback at the code and documentation level.\n\n\n\n\n\n\nAll of the code is hosted on public version control repositories and may be reviewed at any time by all members of the Stan community. This allows continuous feedback for both coding standards, functionality, and statistical accuracy.\nThe source code for Stan’s C++ library, CmdStan, PyStan, and RStan is managed in separate version-control libraries based on Git and hosted by GitHub under the GitHub organization stan-dev:\n\nhttps://github.com/stan-dev\n\nPush access (i.e., the ability to write to the repository, specifically in approving pull requests and merging) is restricted to core developers and very closely managed. At the same time, any user may provide (and many users have provided) pull requests with patches for the system (which are treated as any other pull request and fully tested and code reviewed). Because of Git’s distributed nature, everyone who clones a repository produces a full backup of the system and all past versions.\nStan follows the Git process outlined by Vincent Driessen in his blog post, a successful branching model for Git.\nNew features and ordinary (not hot) bugfixes are developed in branches from and merged back into the development branch. These are then collected into releases and merged with the master branch, which tracks the releases. Hotfix branches are like feature or ordinary bugfix branches, but branch from master and merge back into master.\nThe basic Git process for branching, releasing, hotfixing, and merging follows standard Git procedure. A diagram outlining the process is presented in the figure above. The key idea is that the master branch is always at the latest release, with older commits tagged for previous releases.\nThe development branch always represents the current state of development. Feature and bugfix branches branch from the development branch. Before being merged back into the development branch, they must be wrapped in a pull request for GitHub, which supplies differences with current code and a forum for code review and comment on the issue. All branches must have appropriate unit tests and documentation as part of their pull request before they will be merged (see the pull request template, which all requests must follow). Each pull request must provide a summary of the change, a detailed description of the intended effect (often coupled with pointers to one or more issues on the issue tracker and one or more Wiki pages), a description of how the change was tested and its effects can be verified, a description of any side effects, a description of any user-facing documentation changes, and suggestions for reviewers.\nTaken together, the testing, code review, and merge process ensures that the development branch is always in a releasable state.\nGit itself provides extensive log facilities for comparing changes made in any given commit (which has a unique ID under Git) with any other commit, including the current development or master branch. GitHub provides further graphical facilities for commentary and graphical differences.\nFor each release, the Git logs are scanned and a set of user-facing release notes provided summarizing the changes. The full set of changes, including differences with previous versions, is available through Git. These logs are complete back to the first version of Stan, which was originally managed under the Subversion version control system.\nMore information on the mechanics of the process are available from on the Developer process Wiki.\n\n\n\n\n\nStan C++, CmdStan, PyStan, and RStan are all extensively unit tested. The core C++ code and CmdStan code is tested directly in C++ using the Google test framework . PyStan is tested using the Python unit testing framework unittest.\nRStan is tested using the RUnit package.\nThe point of unit testing is to test the program at the application programmer interface (API) level, not the end-to-end functional level.\nThe tests are run automatically when pull requests are created through a continuous integration process. Stan packages use a combination of the Travis continuous integration framework and the Jenkins continuous integration framework.\nThe continuous integration servers provide detailed reports of the various tests they run and whether they succeeded or failed. If they failed, console output is available pointing to the failed tests. The continuous integration servers also provide graphs and charts summarizing ongoing and past testing behavior.\nStan and its interfaces’ unit tests are all distributed with the system software and may be run by users on their specific platform with their specific compilers and configurations to provide support for the reliability of a particular installation of Stan.\nAs with any statistical software, users need to be careful to consider the appropriateness of the statistical model, the ability to fit it with existing data, and its suitability to its intended application.\nThe entire source repository is available to users. A snapshot at any given release (or commit within a branch) may be downloaded as an archive (zip file) or may be cloned for development under Git. Cloning in Git provides a complete copy of all version history, including every commit to every branch since the beginning of the project.\nUser feedback is accommodated through three channels. First, and most formally, there is an issue tracker for each of Stan C++, CmdStan, RStan and PyStan, which allows users to submit formal bug reports or make feature requests. Any user bug report is reviewed by the development team, assessed for validity and reproducibility, and assigned to a specific developer for a particular release target. A second route for reporting bugs is our users group; bugs reported to the user group by users are then submitted to the issue tracker by the developers and then put through the usual process. A third method of bug reporting is informal e-mail or comments; like the user group reports, these are channeled through the issue tracker by the developers before being tackled.\nContinuous integration is run on a combination of Windows, Mac OS X, and Linux platforms. All core Stan C++ code is tested on Windows, Mac OS, and Linux before release.\n\n\n\nIn addition to unit testing at the individual function level, Stan undergoes rigorous end-to-end testing of its model fitting functionality. Models with known answers are evaluated for both speed and accuracy. Models without analytic solutions are evaluated in terms of MCMC error.\n\n\n\n\nAt various stages, typically when major new functionality has been added or a serious bug has been fixed, the development branch is declared ready for release by the Stan development team. At this point, the branch is tested one last time on all platforms before being merged with the master branch. Releases are managed through GitHub releases mechanism. For example, releases for Stan C++ are available as GitHub releases. Each release further bundles the manual and provides both a zipped and tar-gzipped archive of the release.\nStan is released exclusively as source code, so nothing needs to be done with respect to binary release management or compatibility. The source is tested so that it can be used under Windows, Mac OS X, and Linux.\nInstructions for installing Stan C++, CmdStan, RStan, and PyStan are managed separately and distributed with the associated product.\n\n\n\nStan version numbers follow the standard semantic version numbering pattern in which version numbers are of the form Major.Minor.Patch. For example, version 2.9.1 is major release 2, minor release 9, and patch release 1. Semantic versioning signals important information about features and compatibility for the Stan language and how it is used. It does not provide information about underlying implementation; changes in implementation do not affect version numbering in and of itself.\nThe reference manual lists deprecated features in an appendix.\n\n\nA change in a library breaks backward compatibility if a program using only supported APIs (for Stan, that is the language reference; click here for the Math library) that worked in the previous version no longer works the same way in the current version. For backward-compatibility breaking changes, the major version number is incremented. When the major version is updated, the minor version reverts to 0. Because breaking backward compatibility is such a disturbance for users, there are very few major releases.\n\n\n\nA change in a library introduces a new feature if a program that works in the current version will not work in a previous version; that is, it breaks forward compatibility. When a version introduces a new feature without breaking backward compatibility, its minor version number is incremented. Whenever the minor version is incremented, the patch level reverts to 0. Most Stan releases increment the minor version.\n\n\n\nIf a release does not add new functionality or break backward compatibility, only its patch version is incremented. Patch releases of Stan are made when an important bug is fixed before any new work is done. Because Stan keeps its development branch clean, pending patches are easily rolled into minor releases."
  },
  {
    "objectID": "mc-stan-org/developers.html#communication",
    "href": "mc-stan-org/developers.html#communication",
    "title": "Stan Project’s Software Development Lifecycle",
    "section": "",
    "text": "Communication among team members takes place in several venues. Most discussions take place openly on the Stan forum.\n\nStan’s forum is hosted by Discourse at http://discourse.mc-stan.org\n\nThe Stan forums are archived and may be read by anyone at any time. Communication that’s not suitable for the public, such as grant funding, is carried out on a private group restricted to the core Stan developers. Further issue-specific discussion takes place concurrently with development and source control.\n\nStan’s issue trackers are hosted by GitHub.\n\nBigger design issues require design documents in the form of a community RFC.\n\nstan/dev:design-docs is hosted on GitHub\n\nVarious project meetings among developers and users take place online in various forums including Zoom and Google Hangouts. These are not recorded or stored. Developers also meet informally at their places of employment or at conferences and workshops when multiple team members are in attendance. The developers also host meetups for the public in locations including Berlin, Boston, London, Sydney, and New York."
  },
  {
    "objectID": "mc-stan-org/developers.html#licensing",
    "href": "mc-stan-org/developers.html#licensing",
    "title": "Stan Project’s Software Development Lifecycle",
    "section": "",
    "text": "Stan’s C++ library and the CmdStan interface are released under the terms of the new (3 clause) BSD license, with two dependent libraries (Boost and Eigen), released under compatible libraries. The R interface RStan and Python interface PyStan are released under the GPLv3 license."
  },
  {
    "objectID": "mc-stan-org/developers.html#community-size",
    "href": "mc-stan-org/developers.html#community-size",
    "title": "Stan Project’s Software Development Lifecycle",
    "section": "",
    "text": "The size of the Stan community is difficult to estimate reliably because there are no sales transactions and Stan’s version control distribution system (GitHub) does not provide download statistics. There were over 2000 users subscribed the users group on Google before it was moved to Discourse, on which there are dozens of active threads at any given time. This substantial user base provides the means to do continuous reviews of real-world performance in real settings. Unlike proprietary software only available in binary form, Stan’s open-source code base allows users to provide feedback at the code and documentation level."
  },
  {
    "objectID": "mc-stan-org/developers.html#hosting-and-version-control",
    "href": "mc-stan-org/developers.html#hosting-and-version-control",
    "title": "Stan Project’s Software Development Lifecycle",
    "section": "",
    "text": "All of the code is hosted on public version control repositories and may be reviewed at any time by all members of the Stan community. This allows continuous feedback for both coding standards, functionality, and statistical accuracy.\nThe source code for Stan’s C++ library, CmdStan, PyStan, and RStan is managed in separate version-control libraries based on Git and hosted by GitHub under the GitHub organization stan-dev:\n\nhttps://github.com/stan-dev\n\nPush access (i.e., the ability to write to the repository, specifically in approving pull requests and merging) is restricted to core developers and very closely managed. At the same time, any user may provide (and many users have provided) pull requests with patches for the system (which are treated as any other pull request and fully tested and code reviewed). Because of Git’s distributed nature, everyone who clones a repository produces a full backup of the system and all past versions.\nStan follows the Git process outlined by Vincent Driessen in his blog post, a successful branching model for Git.\nNew features and ordinary (not hot) bugfixes are developed in branches from and merged back into the development branch. These are then collected into releases and merged with the master branch, which tracks the releases. Hotfix branches are like feature or ordinary bugfix branches, but branch from master and merge back into master.\nThe basic Git process for branching, releasing, hotfixing, and merging follows standard Git procedure. A diagram outlining the process is presented in the figure above. The key idea is that the master branch is always at the latest release, with older commits tagged for previous releases.\nThe development branch always represents the current state of development. Feature and bugfix branches branch from the development branch. Before being merged back into the development branch, they must be wrapped in a pull request for GitHub, which supplies differences with current code and a forum for code review and comment on the issue. All branches must have appropriate unit tests and documentation as part of their pull request before they will be merged (see the pull request template, which all requests must follow). Each pull request must provide a summary of the change, a detailed description of the intended effect (often coupled with pointers to one or more issues on the issue tracker and one or more Wiki pages), a description of how the change was tested and its effects can be verified, a description of any side effects, a description of any user-facing documentation changes, and suggestions for reviewers.\nTaken together, the testing, code review, and merge process ensures that the development branch is always in a releasable state.\nGit itself provides extensive log facilities for comparing changes made in any given commit (which has a unique ID under Git) with any other commit, including the current development or master branch. GitHub provides further graphical facilities for commentary and graphical differences.\nFor each release, the Git logs are scanned and a set of user-facing release notes provided summarizing the changes. The full set of changes, including differences with previous versions, is available through Git. These logs are complete back to the first version of Stan, which was originally managed under the Subversion version control system.\nMore information on the mechanics of the process are available from on the Developer process Wiki."
  },
  {
    "objectID": "mc-stan-org/developers.html#testing-and-validation",
    "href": "mc-stan-org/developers.html#testing-and-validation",
    "title": "Stan Project’s Software Development Lifecycle",
    "section": "",
    "text": "Stan C++, CmdStan, PyStan, and RStan are all extensively unit tested. The core C++ code and CmdStan code is tested directly in C++ using the Google test framework . PyStan is tested using the Python unit testing framework unittest.\nRStan is tested using the RUnit package.\nThe point of unit testing is to test the program at the application programmer interface (API) level, not the end-to-end functional level.\nThe tests are run automatically when pull requests are created through a continuous integration process. Stan packages use a combination of the Travis continuous integration framework and the Jenkins continuous integration framework.\nThe continuous integration servers provide detailed reports of the various tests they run and whether they succeeded or failed. If they failed, console output is available pointing to the failed tests. The continuous integration servers also provide graphs and charts summarizing ongoing and past testing behavior.\nStan and its interfaces’ unit tests are all distributed with the system software and may be run by users on their specific platform with their specific compilers and configurations to provide support for the reliability of a particular installation of Stan.\nAs with any statistical software, users need to be careful to consider the appropriateness of the statistical model, the ability to fit it with existing data, and its suitability to its intended application.\nThe entire source repository is available to users. A snapshot at any given release (or commit within a branch) may be downloaded as an archive (zip file) or may be cloned for development under Git. Cloning in Git provides a complete copy of all version history, including every commit to every branch since the beginning of the project.\nUser feedback is accommodated through three channels. First, and most formally, there is an issue tracker for each of Stan C++, CmdStan, RStan and PyStan, which allows users to submit formal bug reports or make feature requests. Any user bug report is reviewed by the development team, assessed for validity and reproducibility, and assigned to a specific developer for a particular release target. A second route for reporting bugs is our users group; bugs reported to the user group by users are then submitted to the issue tracker by the developers and then put through the usual process. A third method of bug reporting is informal e-mail or comments; like the user group reports, these are channeled through the issue tracker by the developers before being tackled.\nContinuous integration is run on a combination of Windows, Mac OS X, and Linux platforms. All core Stan C++ code is tested on Windows, Mac OS, and Linux before release.\n\n\n\nIn addition to unit testing at the individual function level, Stan undergoes rigorous end-to-end testing of its model fitting functionality. Models with known answers are evaluated for both speed and accuracy. Models without analytic solutions are evaluated in terms of MCMC error."
  },
  {
    "objectID": "mc-stan-org/developers.html#release-cycles",
    "href": "mc-stan-org/developers.html#release-cycles",
    "title": "Stan Project’s Software Development Lifecycle",
    "section": "",
    "text": "At various stages, typically when major new functionality has been added or a serious bug has been fixed, the development branch is declared ready for release by the Stan development team. At this point, the branch is tested one last time on all platforms before being merged with the master branch. Releases are managed through GitHub releases mechanism. For example, releases for Stan C++ are available as GitHub releases. Each release further bundles the manual and provides both a zipped and tar-gzipped archive of the release.\nStan is released exclusively as source code, so nothing needs to be done with respect to binary release management or compatibility. The source is tested so that it can be used under Windows, Mac OS X, and Linux.\nInstructions for installing Stan C++, CmdStan, RStan, and PyStan are managed separately and distributed with the associated product."
  },
  {
    "objectID": "mc-stan-org/developers.html#versioning-and-release-compatibility",
    "href": "mc-stan-org/developers.html#versioning-and-release-compatibility",
    "title": "Stan Project’s Software Development Lifecycle",
    "section": "",
    "text": "Stan version numbers follow the standard semantic version numbering pattern in which version numbers are of the form Major.Minor.Patch. For example, version 2.9.1 is major release 2, minor release 9, and patch release 1. Semantic versioning signals important information about features and compatibility for the Stan language and how it is used. It does not provide information about underlying implementation; changes in implementation do not affect version numbering in and of itself.\nThe reference manual lists deprecated features in an appendix.\n\n\nA change in a library breaks backward compatibility if a program using only supported APIs (for Stan, that is the language reference; click here for the Math library) that worked in the previous version no longer works the same way in the current version. For backward-compatibility breaking changes, the major version number is incremented. When the major version is updated, the minor version reverts to 0. Because breaking backward compatibility is such a disturbance for users, there are very few major releases.\n\n\n\nA change in a library introduces a new feature if a program that works in the current version will not work in a previous version; that is, it breaks forward compatibility. When a version introduces a new feature without breaking backward compatibility, its minor version number is incremented. Whenever the minor version is incremented, the patch level reverts to 0. Most Stan releases increment the minor version.\n\n\n\nIf a release does not add new functionality or break backward compatibility, only its patch version is incremented. Patch releases of Stan are made when an important bug is fixed before any new work is done. Because Stan keeps its development branch clean, pending patches are easily rolled into minor releases."
  },
  {
    "objectID": "mc-stan-org/developers.html#availability-of-current-and-historical-archive-versions",
    "href": "mc-stan-org/developers.html#availability-of-current-and-historical-archive-versions",
    "title": "Stan Project’s Software Development Lifecycle",
    "section": "Availability of current and historical archive versions",
    "text": "Availability of current and historical archive versions\nCurrent and older versions of Stan C++, CmdStan, RStan, and PyStan are available through the GitHub pages for the corresponding repository. Official releases are bundled as archives and available through GitHub’s releases.\nAny intermediate commit is also available through GitHub in one of two ways. First, all of Stan (or CmdStan, RStan, or PyStan) may be downloaded by cloning the repository, at which point a user has a complete record of the entire project’s commits and branches. After first cloning a repository, it may be kept up to date using Git’s pull command (available from the command-line or platform-specific graphical user interfaces). An alternative delivery mechanism is as a zip archive of a snapshot of the system."
  },
  {
    "objectID": "mc-stan-org/developers.html#maintenance-support-and-retirement",
    "href": "mc-stan-org/developers.html#maintenance-support-and-retirement",
    "title": "Stan Project’s Software Development Lifecycle",
    "section": "Maintenance, support, and retirement",
    "text": "Maintenance, support, and retirement\nStan support extends only to the most current release. Specifically, patches are not backported to older versions.\nEarly fixes of bugs are available to users in the form of updated development branches. Snapshots of the entire code base at every commit, including development patches and official releases, are available from GitHub. Git itself may be used to download a complete clone of the entire source code history at any time.\nThere is extensive documentation in the form of manuals available for the Stan language and algorithms. There is also extensive interface documentation as well as the interfaces for the command line, R, Python, MATLAB, Mathematica, Stata, Julia, and Scala\nThere is also an extensive suite of tutorials and example models, which may be used directly or modified by users. There is also a fairly extensive set of Wiki pages for developers.\nIssue trackers for reporting bugs and requesting features are available online for Stan’s C++ math library and core library, as well as for the interfaces (all available from the stan-dev organization page.\nThere is Stan forum for users and developers. The users topics allow users can request support for installation issues, modeling issues, or performance/accuracy issues. These lists all come with built-in search facilities through their host or simply through top-level web searches in the search engine of your choice.\nA number of books provide introductions to Stan, including Gelman et al.’s Bayesian Data Analysis, 3rd Edition, Krushcke’s Doing Bayesian Data Analysis, 2nd Edition, and McElreath’s Statistical Rethinking. All of the examples from several other books have been translated to Stan, including Lee and Wagnemakers’ Bayesian Cognitive Modeling: A Practical Course, Lunn et al.’s The BUGS Book, Gelman and Hill’s Data Analysis Using Regression and Multilevel-Hierarchical Models, and Kéry Schaub’s Bayesian population analysis using WinBUGS.\nThe major.minor.0 releases are maintained through patch releases major.minor.n releases. At each new major.minor.0 release, prior versions are retired from support. All efforts are focused on the current release. No further development or bug fixes are made available for earlier versions. The earlier versions can still be accessed through version control."
  },
  {
    "objectID": "mc-stan-org/developers.html#qualified-personnel",
    "href": "mc-stan-org/developers.html#qualified-personnel",
    "title": "Stan Project’s Software Development Lifecycle",
    "section": "Qualified personnel",
    "text": "Qualified personnel\nThe members of the Stan development team are drawn from multiple computational, scientific, and statistical disciplines across academic, not-for-profit, and industrial laboratories.\nMany of Stan’s developers have Ph.D. degrees, some have Master’s degrees, and some are currently enrolled as undergraduate or graduate students. All of the developers with advanced degrees have published extensively in peer reviewed journals. Several have written books on statistics and/or computing. Many members of the core development team were well known internationally outside of their contributions to Stan. The group overall is widely acknowledged as leading experts in statistical computing, software development, and applied statistics.\nThe managers of the development process have extensive industrial programming experience and have designed or contributed to other software systems that are still in production.\nInstitutions at which the members of the Stan development team hold appointments as of Stan release 2.17.1 include Columbia University, Adobe Creative Technologies Lab, University of Warwick, University of Toronto (Scarborough), Dartmouth College, University of Washington, Lucidworks, CNRS (Paris), St. George’s, University of London, University of Massachusetts (Amherst), Aalto University, and Novartis Pharma."
  },
  {
    "objectID": "mc-stan-org/developers.html#physical-and-logical-security",
    "href": "mc-stan-org/developers.html#physical-and-logical-security",
    "title": "Stan Project’s Software Development Lifecycle",
    "section": "Physical and logical security",
    "text": "Physical and logical security\nThe Stan project maintains its integration servers for Stan C++ and CmdStan on site at Columbia University. The integration servers for Stan C++ and CmdStan are password protected and run on isolated, standalone machines used only as integration servers. The network is maintained by Columbia University’s Information Technology (CUIT) group.\nThe integration server for PyStan is hosted by the Travis open-source continuous integration project, and is password protected on an account basis.\nThe version control system is hosted by GitHub. Due to Git’s distributed nature, each developer maintains a complete record of the entire project’s commit history. Everything is openly available, but privileges to modify the existing branches is restricted to the core developers. Any change to the code base is easily reversed through Git.\nThe archived releases as well as clones of the full repositories are also managed through GitHub.\nStan’s web pages are also served by GitHub and are password protected. The web pages are purely informational and nothing is distributed through the web pages themselves other than case studies and documentation.\nIndividual contributors work on their own personal computers or on compute clusters at Columbia or elsewhere."
  },
  {
    "objectID": "mc-stan-org/developers.html#disaster-recovery",
    "href": "mc-stan-org/developers.html#disaster-recovery",
    "title": "Stan Project’s Software Development Lifecycle",
    "section": "Disaster recovery",
    "text": "Disaster recovery\nThe entire history of the Stan C++, CmdStan, RStan, and PyStan repositories is maintained on the GitHub servers as well as on each developer’s individual copy of the repository. Specifically, each repository can be reconstituted from any of the core developers’ machines.\n\n Copyright (2020) Stan Development Team and their assignees. Licensed under CC-BY ND 4.0."
  },
  {
    "objectID": "learn-stan/stancon/stancon2019-abstracts.html",
    "href": "learn-stan/stancon/stancon2019-abstracts.html",
    "title": "StanCon 2019 Programme",
    "section": "",
    "text": "Pharmaceuticals/Medicine\n\nComputing prediction and tolerance intervals for a mixture of normal distributions. Jean-francois Michiels, Timothy Mutsvari, Oussama Errazi. Pharmalex. Abstract\nParallel numerical ODE solution in Torsten for population models. Yi Zhang, William R. Gillespie. Metrum LLC Abstract\nMulti-channel Gaussian Processes as flexible alternatives to linear models: perspectives and challenges to scaling up Bayesian inference to genomic-scale data. Caetano Souto-Maior, Susan T. Harbison. Laboratory of Systems Genetics, National Heart Lung and Blood Institute, NIH. Abstract\nEstimating the prevalence of HIV infection in England using Bayesian evidence synthesis. Anne Presanis, Christopher Jackson [presenting author], Daniela De Angelis (MRC Biostatistics Unit, University of Cambridge); Peter Kirwan, Alison Brown, Ada Miltz, Ross Harris, Cuong Chau, Stephanie Migchelsen, Hamish Mohammed, Katy Davison, Sara Croxford, Sarika Desai, Kathy Lowndes, Valerie Delpech, Noel Gill (Public Health England).  Abstract Video\nA Decision-Theoretic Journey From Early Clinical Data to Late Stage Efficacy using Hierarchical Joint Models.. Krzysztof Sakrejda, Eric Novik.  Generable  Abstract Video\nBayesian analyses of time-to-event data using the rstanarm R package. Eren M. Elçi, Sam Brilleman. Public Health and Preventive Medicine, Monash University. Abstract Video\nModelling enzyme kinetics with Stan. Teddy Groves. DTU BIOSUSTAIN Quantitative Modelling of Cell Metabolism Team Abstract Video\nThe emergence of HIV resistance to antiretroviral therapy in southern Africa: a mechanistic meta-analysis of survey data. Julien Riou, Matthias Egger, Christian Althaus. Institute of Social and Preventive Medicine, University of Bern, Switzerland Abstract Video\nHandling missing data, censored values and measurement error in machine learning models using multiple imputation for early stage drug discovery. Rowan Swiers. AstraZeneca Abstract Video\nA Bayesian multi-layered model to predict mechanisms, types, and severity of drug-induced liver injury. Elizaveta Semenova, Dominic Williams, Stanley E Lazic. Data Science and Quantitative Biology group, AstraZeneca, Cambridge UK Abstract\n\nModeling\n\nGaussian process modeling and covariate selection for longitudinal data. Juho Timonen, Aki Vehtari, Harri Lähdesmäki. Aalto University Abstract\nEstimating the effect of age and league on scoring rate in professional soccer. Benjamin Torvaney. Wefarm Abstract\nHierarchical models for gamma-ray burst populations. J. Michael Burgess.  MPE  Abstract\nModeling cocoa bean fermentation processes. Mauricio Moreno-Zambrano, Sergio Grimbs, Matthias S. Ullrich and Marc-Thorsten Hütt.  Department of Life Sciences & Chemistry, Jacobs University Bremen Abstract Video\nApproximate leave-future-out cross-validation for Bayesian time series models. Paul Bürkner, Jonah Gabry, Aki Vehtari.  Abstract Video\nWhen seasonality meets Bayesian: Decomposing seasonalities in Stan. Hyunji Moon, SNU, Hyeonseop Lee, PUBG.  Abstract Video\nPrediction and causal inference for time-to-event outcomes truncated by death. . Leah Comment.  Abstract Video\nFast Forward Like a Lambo (skrrt skrrt). Daniel Lee. Generable Abstract Video\nThe Currency of Place and the Short-Term Rental Market. Mikael Brunila.  Abstract Video\nProfit-Maximizing A/B Tests. Elea McDonnell Feit, Ron Berman. Drexel Univeristy, The Wharton School Abstract Video\nStructured priors for survey estimates in the presence of non-representative data. Yuxiang Gao (University of Toronto), Lauren Kennedy (Columbia University), Daniel Simpson (University of Toronto).  Abstract Video\nChronikis: a Bayesian time-series modeling language. Kevin S. Van Horn. Adobe Inc. Abstract Video\nA long-short term event memory state-space model for multi-party elections. Marcus Groß. INWT Statistics GmbH Abstract\nSimulation of Statistic Mechanical Systems using Stan. Forrest Eli Hurley. North Carolina State University Abstract Video\nRegularized Hierarchical Models for Remotely Sensed Forest Inventories. Nathan E. Rutenbeck SilviaTerra Abstract \nGetting the Lead out–Does New York City’s childhood lead testing make statistical sense?. Jonathan Auerbach, Breck Baldwin. Columbia Univeristy Abstract Video \n\nInference\n\nMaking Stan Faster using Sequential Monte Carlo samplers. Simon Maskell (University of Liverpool), Alessandro Varsi (University of Liverpool), Peter Green (University of Liverpool), Paul Horridge (University of Liverpool), Alejandro Diaz (University of Liverpool), Lee Devlin (University of Liverpool), Rob Moore (University of Liverpool), Katerina Chatzopoulou (University of Liverpool), Jinglai Li (University of Liverpool), Maria Sudell (University of Liverpool), Luke Mason (STFC), Robin Pinning (STFC), Jack Taylor (STFC), Vassil Alexandrov (STFC), Ed Pyzer-Knapp (IBM) .  Abstract\nOne weird trick: Non-parametric Bayesian updating by kernels. Robert Grant. BayesCamp Abstract\nSemiparametric Modeling of the Mean,Variance and Scale Parameters in Skew Normal Regression Models: A Bayesian Perspective. Héctor Zarate.  Abstract\nPrior choice in logit models of discrete choice. Jim Savage. Schmidt Futures Abstract Video\nStacking for multimodal posterior distributions. Yuling Yao, Aki Vehtari and Andrew Gelman.  Abstract Video\nBayesian leave-one-out cross-validation for large data. Måns Magnusson, Aalto, Michael Riis Andersen, Danish Technical University, Johan Jonasson, Chalmers Technical University, Aki Vehtari, Aalto.  Abstract Video\n\nCore Stan\n\nThe State of GPU Computation Support for Stan. Rok Češnovar (University of Ljubljana - UL), Steve Bronder (Capital One), Davor Sluga (UL), Jure Demšar (UL), Tadej Ciglarič (UL), Sean Talts (Columbia University), Erik Štrumbelj (UL).  Abstract Video\nExtending Stan’s Automatic Differentiation (AD) capabilities using dco/c++. Philip Maybank. Numerical Algorithms Group (NAG) Abstract Video\n\n\n\n\n\n Regularized Hierarchical Models for Remotely Sensed Forest Inventories. Nathan E. Rutenbeck SilviaTerra \nManagement and conservation of the world’s forests is critical for maintaining global timber supply, as well as for the ecosystem services forestlands provide. Forest biometrics remains a field focused on traditional methods in sampling and regression, despite the fact that these methods are ill equipped to utilize the profusion of remote sensing data now available. When remote sensing data is used, it is often deployed within simple population-level regression models that simultaneously leave out information regarding known forest structure and sample design, and are prone to overfitting of effects at the population level. Using Stan, we show that for the prediction of forest basal area (a key inventory attribute) incorporating known structural attributes (forest stands) and sample design information into a hierarchical modeling framework along with remote sensing data can yield beneficial results in terms of reducing overfitting and improving predictive performance when compared to more conventional methods. We fit and compared four candidate models, examining their performance with respect to one another and to the conventional frequentist inferences that are so widely used for operational forest inventory. The four models we examined are 1) a hierarchical model incorporating forest stand and sample design effects; 2) a population-level remote sensing principal components model; 3) the hierarchical model with the addition of remote sensing principal component effects at the population level; and 4) the hierarchical and remote sensing model with the addition of regularizing horseshoe priors on remote sensing effects. The hierarchical model without remote sensing effects showed the expected shrinkage of stand-level mean basal area predictions toward the global mean. The addition of remote sensing effects showed overall reductions in prediction error in comparison to the sample design model. Incorporating regularizing priors on the remote sensing principal components effects retained signal from the remote sensing data but showed further shrinkage of predictions of stand-level mean basal area toward sample means. Our results suggest that the penalized hierarchical model can be used in developing operational forest inventories that balance information from known forest structural heterogeneity, the sample design, and remote sensing data.\n A Bayesian multi-layered model to predict mechanisms, types, and severity of drug-induced liver injury. Elizaveta Semenova, Dominic Williams, Stanley E Lazic. Data Science and Quantitative Biology group, AstraZeneca, Cambridge UK \nAbstract: Drug-induced liver injury (DILI) is a major cause of attrition in drug development and a common reason for withdrawing a drug from the market. Predicting clinical liver toxicity is difficult, but preclinical in vitro assays and physical/chemical properties of drugs can be used as predictors. We developed a multi-layered Bayesian model where we use assay results to predict the mechanism(s) of toxicity, use the mechanisms to predict the type of liver injury, and then combine the type of injury with the clinical dose of a drug to predict the severity of injury. The model therefore has a layered structure, enabling uncertainty to propagate through the layers. Based only on assay and physchem data, along with the clinical dose, the model enables safety pharmacologists to predict the severity, type, and mechanism of liver toxicity with good accuracy.\n\n \n Getting the Lead out–Does New York City’s childhood lead testing make statistical sense?. Jonathan Auerbach, Breck Baldwin. Columbia Univeristy .  Video\nAbstract: The US has dramatically reduced blood lead levels in children over the past 30 years and that effort continues. New York City (NYC) was an early adopter of lead reduction policies and that effort continues with laws that require all children be tested and with mandatory interventions for those tested blood levels (tbll) greater than 5mg/dL. But there is a statistically interesting story around how current blood level limits are set, the performance of common tests and how to apply common Bayes rule reasoning to publicly available data.\nThe data we have: We have high quality blood lead level (bll) tests applied nation wide (NHANES) for 5,000 children, we have NYC supplied data that provides counts for all children’s tested blood lead level, the number greater than 5mg/dL, 10mg/dL and 15/dL and claims of blood tests that widely vary from sources like FDA applications for blood testing equipment, actual studies of test performance and government testing standards.\nThe data we want: New York city recently dropped the threshold for intervention from 10mg/dL to 5mg/dL. It is an open question what the false positive rate is for these test thresholds with some research suggesting that it is as high as 70%. On the other extreme is an FDA applications for the LeadCare Plus testing device claim a standard deviation of .5 at the 5mg/dL which suggests a very low false positive rate…but that depends on the distribution of actual blls in the NYC population.\nHow we got the data we wanted: This is a simple application of Bayes rule: p(bll &gt; 5|t &gt;5) = p(tbll &gt; 5| bll&gt;5) p(bll&gt;5)/p(tbll&gt;5) where we don’t know p(bll&gt;5) for NYC. NYC refused to release non-quantized data for tbll under FIOA requests, which if we had, would allow a fairly straightforward determination of false positive rates from tbll test evaluations. But we do have data for the US as a whole in non-quantized form.\nThe paper describes a process of model refinement staring with naive approaches and incrementally modifying our models to better suite NYC data. The final approach, subject to change as we do more work, is to fit national NHANES data with an exponential distribution, assume that similar distributions apply to NYC and recover a believable false positive rate across a range of reported blood test performance. Along the way we show an interesting simple use of the ‘integrate_ode_rk45’ function in Stan and demonstrate Bayesian workflow.\n\n Simulation of Statistic Mechanical Systems using Stan. Forrest Eli Hurley. North Carolina State University  Video\nAbstract: Bayesian statistics is closely coupled with physics. The metropolis algorithm (1953) was developed by scientists working at Los Alamos as a method for thermodynamic simulation of molecular dynamics. Not until the work of W. K. Hastings (1970) was the method generalized to arbitrary probability distributions. Hamiltonian Monte Carlo is even more deeply rooted in physics than the Metropolis-Hastings algorithm. The simulation of states with velocities, energies, and a Hamiltonian describes nothing other than a physical system. It matches a canonical ensemble in that there is not a fixed energy between steps, only an overall fixed temperature. The temperature is usually only implicit, but some tempering methods simulate chains at higher temperatures to smooth the probability distributions. The Ising Model, a proxy for magnetization, is a prevalent introductory model in the study of statistical mechanics. It consists of an N-dimensional grid of spin up or down particles. The energy varies depending on the alignment of spins between nearest neighbors. At low temperatures spins tend to align on a macroscopic scale; at high temperatures they become evenly distributed. We simulate the XY Model, similar to the Ising Model but allowing spins to be represented by unit vectors in two dimensions, using Stan. We create chains at several temperatures to identify the locations of phase transitions in macroscopic properties. Our work shows the applicability of Stan for computation in continuous statistical mechanical problems.\n\n A long-short term event memory state-space model for multi-party elections. Marcus Groß. INWT Statistics GmbH \nAbstract: State-space models are a popular choice in modelling voting intentions and election results by using poll data. The presented multivariate state-space model attempts to go beyond random-walk or Kalman-filter approaches (with comparable performance to simple weighted survey averages) to the problem by introducing a long-short term event memory effect. This effect serves as reasonable explanation to the observation that the voter’s share partially tends to reverse to the party’s long-term trend after larger short term movements. Any event influencing the voter’s share of a party is presumed to have a convex shaped effect decomposable into a short term effect due to e.g. media spreading and a smaller long term effect remaining despite overlay effects of new events and forgetting. This effect is modelled by a mixture of a random walk and two contrasting autoregressive processes. By also taking advantage of the widely observed effect that government parties tend to fall in voter’s share, whereas the opposite effect is observed for opposition parties, mid- and long-term predictions of election outcomes can be considerably be improved. The Stan-model is fitted and evaluated on poll data from seven pollsters for the German national elections (“Bundestagswahl”) from 1994 to 2017, where low double digits (out-of-sample) improvements in prediction performance can be seen between 3- and 18-months prior elections. By taking into account the pollsters house effects, their poll errors and even more importantly their correlations in poll errors, an appropriate and realistic estimation error can be propagated.\n\n Bayesian leave-one-out cross-validation for large data. Måns Magnusson, Aalto, Michael Riis Andersen, Danish Technical University, Johan Jonasson, Chalmers Technical University, Aki Vehtari, Aalto.  Video\nAbstract: Model inference, such as model comparison, model checking, and model selection, is an important part of model development. Leave-one-out cross-validation (LOO) is a general approach for assessing the generalizability of a model, but unfortunately, LOO does not scale well to large datasets. We propose a combination of using approximate inference techniques and probability-proportional-to-size-sampling (PPS) for fast LOO model evaluation for large datasets. We provide both theoretical and empirical results showing good properties for large data.\n\n Stacking for multimodal posterior distributions. Yuling Yao, Aki Vehtari and Andrew Gelman.  Video \nAbstract: When working with multimodal posterior distributions, MCMC algorithms can have difficulty moving between modes, and default variational or mode-based approximate inferences can understate posterior uncertainty. And, even if the most important modes can be found, it is difficult to evaluate their relative weights in the posterior, which requires computing the integral of the posterior in the neighborhood of each mode. Here we propose an alternative approach, using parallel runs of MCMC, variational, or mode- based inferences to hit as many modes as possible, and then using Bayesian stacking to weight the set of simulations at each mode. Bayesian stacking is a method for constructing a weighted average of distributions so as to minimize cross-validated prediction errors. The result from stacking is not necessarily equivalent, even asymptotically, to fully Bayesian inference, but it serves many of the same goals. We discuss in the context of several theoretical and applied examples.\n\n Chronikis: a Bayesian time-series modeling language. Kevin S. Van Horn. Adobe Inc.  Video\nAbstract: Chronikis (http://chronikis.org) is an open-source language for Bayesian time-series models that compiles to Stan and R. It currently focuses on linear state-space models, with plans to incrementally expand the class of supported models over time. The goal for Chronikis is to allow one to quickly and reliably create and apply a variety of models to a time series, doing a full Bayesian analysis on each.\nThus the Chronikis language itself focuses on concise and clear model specification, and as far as possible the task of creating efficient estimation and forecasting code is left to the compiler. These twin goals are facilitated by making the Chronikis language fully declarative: the body of a Chronikis program is just an expression whose ““value”” is a probability distribution over time series.\nThe compiler applies a series of semantics-preserving transformations to the body of a Chronikis program, eventually arriving at a form that it can straightforwardly translate to Stan. Along the way it infers types and shapes for all variables except the parameters of main(), reparameterizes in some cases to use non-centered parameterization, assigns each variable to the appropriate Stan block, and infers bounds for variables assigned to the parameters block.\nFor the sake of clarity, Chronikis supports operations for constructing complex models from simpler components. For example, here is a Chronikis program for a random-walk model with observation noise:\ndef main(s_rw, s_obs: real{0.0,}, mu0: real, sigma0: real{0.0,}) = sigma_rw ~ half_cauchy(s_rw); sigma_obs ~ half_cauchy(s_obs);\naccum(wn(sigma_rw)) + constp(mu0, sigma0) + wn(sigma_obs)\nNotes on the above:\n\nThe main() parameters s_rw, s_obs, mu0, and sigma0 are prior parameters.\nsigma_rw^2 and sigma_obs^2 are the random-walk and observation-error variances.\nwn(s) is a white noise process with variance s^2.\nconstp(m,s) is a distribution over constant time series, with a Normal(m,s) distribution for the constant value.\naccum is an operator on time-series distributions; accum(D) is a time-series distribution whose draws are cumulative sums of a time series drawn from D.\nSum (+) is another operator on time-series distributions; D1 + D2 is a time-series distribution whose draws are the element-wise sum of independent draws from D1 and D2.\n\nChronikis also has some innovative support for (quasi-)periodic time-series model components. The period can be arbitrarily large, and need not even be an integer. One can allow the periodic pattern to slowly change over time. There is a smoothness parameter, and this bounds the size of the latent state required, regardless of how large the period may be. Chronikis accomplishes all this by constructing a linear state-space model that approximates the zero-mean Gaussian process defined by variant of MacKay’s periodic kernel, modified to ensure that the realizations of the process are themselves zero-centered.\n\n Structured priors for survey estimates in the presence of non-representative data. Yuxiang Gao (University of Toronto), Lauren Kennedy (Columbia University), Daniel Simpson (University of Toronto).  Video \nAbstract:A central theme in the field of survey statistics is estimating population-level quantities through data coming from potentially non-representative samples of the population. Multilevel Regression and Poststratification (MRP), a model-based approach, is gaining traction against the traditional weighted approach for survey estimates. MRP uses partial pooling through random effects, thus shrinking model estimates to an overall mean and reducing potential overfitting. Despite MRP’s straightforward specification of prior distributions, the estimates coming from it are susceptible to bias if there is an underlying structure that the prior does not capture. This work aims to provide a new framework for specifying structured prior distributions that lead to bias reduction in MRP estimates. We use simulation studies to explore the benefit of these priors and demonstrate on US survey data.\n\n Profit-Maximizing A/B Tests. Elea McDonnell Feit, Ron Berman. Drexel University, The Wharton School  Video\nAbstract: Marketers often use A/B testing as a tactical tool to compare marketing treatments in a test stage and then deploy the better-performing treatment to the remainder of the consumer population. While these tests have traditionally been analyzed using hypothesis testing, we re-frame such tactical tests as a Bayesian decision problem with an explicit trade-off between the opportunity cost of the test (where some customers receive a sub-optimal treatment) and the potential losses associated with deploying a sub-optimal treatment to the remainder of the population.\nWe derive a closed-form expression for the profit-maximizing test size and show that it is substantially smaller than that typically recommended for a hypothesis test, particularly when the response is noisy or when the total population is small. The common practice of using small holdout groups for media testing can be rationalized by asymmetric priors. The proposed test design achieves nearly the same expected regret as the flexible, yet harder-to-implement multi-armed bandit.\nAdopting a Bayesian approach to experimental design requires informative priors. We show how priors can be estimated from data on past A/B test, using Stan to fit a hierarchical meta model. An R notebook will be provided which shows the complete process from meta-analysis of past experiments to determining the profit-maximizing sample size for the new A/B test.\nA full paper is available at https://arxiv.org/abs/1811.00457.\n\n The Currency of Place and the Short-Term Rental Market. Mikael Brunila.  Video \nAbstract: Airbnb and short-term rentals are raising rents in cities through the use of new technologies and by catering to culturally savvy populations. As a phenomenon of the attention economy, Airbnb is a platform where meaning becomes priced, as efficient and attractive communication is awarded by more bookings. In this paper, we look at how this capitalization of meaning can be understood by modelling the use of neighbourhood names. Using Natural Language Processing techniques and Bayesian hierarchical logit models with Intrinsic Auto-Regressive priors, we explore how listings draw upon the value placed on well-known neighbourhoods to promote themselves. Our findings separate different spatial effects as well as neighbourhood and listing level patterns that help us explain how neighbourhood names are deployed to promote short-term rentals on Airbnb.\n\n Fast Forward Like a Lambo (skrrt skrrt). Daniel Lee. Generable Video\nAbstract: Exploring simple, automatic within-chain parallelization. For any (well-behaved) statistical model written in the Stan language, the Stan Math library (Math) provides the gradient of the log joint probability distribution function specified. It currently provides the gradient with reverse-mode automatic differentiation. Math also provides forward-mode automatic differentiation, which isn’t as well tested as reverse-mode, but is available none-the less. Reverse-mode automatic differentiation scales well as it can tackle an arbitrary number of parameters with one sweep. However, this can’t be parallelized easily. Forward-mode requires N sweeps to evaluate N directional derivatives, but each of these sweeps can be done in parallel. With the adoption of C++14 capable compilers, we’re now able to use threading as an easy paradigm to coordinate within-chain parallelization. We’ll show some of the performance considerations and some preliminary results.\n\n Prediction and causal inference for time-to-event outcomes truncated by death. Leah Comment.  Video\nAbstract: Predicting customer behaviour is crucial for making decisions such as the cost of acquisition or planning for production or service capacity. In the model being presented individual purchase data of a fashion retailer is utilized to describe and predict their behaviour using Bayeasian multi-layered architecture to allow for heterogeneity and latent variables, such as customer state of activity.\n\n–&gt;\n When seasonality meets Bayesian: Decomposing seasonalities in Stan. Hyunji Moon, SNU, Hyeonseop Lee, PUBG.   Video\nAbstract: Multiple seasonalities play a key role in time series forecasting, especially for business time series where seasonal effects are often dramatic. Previous approaches including Fourier decomposition, exponential smoothing, and Seasonal ARIMA do not reflect distinct characteristics of each period in seasonal patterns such as unique behavior of specific day of the week in business data. We propose a multi-dimensional hierarchical model. Intermediate parameters for each seasonal period are first estimated, then mixture of intermediate parameters are then taken, resulting in the model which successfully reflects interactions between multiple seasonalities. Although this process leads to the reduction of data available for each parameter, a robust estimation can be obtained through a hierarchical Bayesian model. Consideration of not only the characteristics of each seasonal periods but also the interactions between characteristics from multiple seasonalities becomes possible through this model. Our new model is implemented in Stan and considerable improvements in prediction accuracy compared to previous models are achieved. Previous models include Fourier decomposition which Prophet uses to model seasonalities. Comparison has been performed on real-world dataset from a nation-scale logistic network.\n\n Approximate leave-future-out cross-validation for Bayesian time series models. Paul Bürkner, Jonah Gabry, Aki Vehtari.  Video\nAbstract: One of the common goals of time series analysis is to use the observed series to inform predictions for future observations. In the absence of any actual new data to predict, cross-validation can be used to estimate a model’s future predictive accuracy, for instance, for the purpose of model comparison or selection. As exact cross-validation for Bayesian models is often computationally expensive, approximate cross-validation methods have been developed; most notably methods for leave-one-out cross-validation (LOO-CV). If the actual prediction task is to predict the future given the past, LOO-CV provides an overly optimistic estimate as the information from future observations is available to influence predictions of the past. To tackle the prediction task properly and account for the time series structure, we can use leave-future-out cross-validation (LFO-CV). Like exact LOO-CV, exact LFO-CV requires refitting the model many times to different subsets of the data. Using Pareto smoothed importance sampling, we propose a method for approximating exact LFO-CV that drastically reduces the computational costs while also providing informative diagnostics about the quality of the approximation. We provide examples using Bayesian time-series models fitted with Stan.\n\n Handling missing data, censored values and measurement error in machine learning models using multiple imputation for early stage drug discovery. Rowan Swiers. AstraZeneca  Video\nAbstract: Multiple imputation is a technique for handling missing data, censored values and measurement error. Currently it is underused in the machine learning field due to lack of familiarity and experience with the technique, whilst other missing data solutions such as full Bayesian models can be hard to set up. However, randomization-based evaluations of Bayesianly derived repeated imputations can provide approximately valid inference of the posterior distributions and allow use of techniques which rely upon complete data such as SVMs and random Forest models.\nThis paper, using simulated data sets inspired by AstraZeneca drug data, shows how multiple imputation techniques can improve the analysis of data with missing values or with uncertainty. We pay close attention to the prediction of Bayesian posterior coverage due its importance in industrial applications. Comparisons are made to other commonly used methods of handling missing data such as single uniform imputation and data removal. Furthermore, we review several standard multiple imputation models and compare them on our simulated data sets. We provide recommendations on when to use each technique and where extra care is needed based upon data distributions. Finally, using simulated data, we give examples of how correct use of multiple imputation can affect investment decisions in the early stages of drug discovery.\nAnalysis was performed using both Python and Stan and is provided in a Jupyter notebook.\n\n The emergence of HIV resistance to antiretroviral therapy in southern Africa: a mechanistic meta-analysis of survey data. Julien Riou, Matthias Egger, Christian Althaus. Institute of Social and Preventive Medicine, University of Bern, Switzerland Video\nAbstract: Large-scale campaigns providing access to antiretroviral therapy (ART) to people living with HIV in southern Africa have been ongoing since the early 2000s. The success of these campaigns is now threatened by the emergence of HIV drug resistance, most of all resistance to non-nucleoside reverse-transcriptase inhibitors (NNRTI), a class of drugs constitutive of ART. Systematic reviews of cross-sectional surveys have provided insights into the temporal trends of NNRTI resistance among HIV-infected individuals. However, these simple temporal trends fail to account for the local dynamics of HIV transmission and treatment that create the evolutionary pressure generating resistance mutations. Such approaches limit our general understanding of the phenomena of resistance emergence in response to drug introduction and disallow any between-country comparison. Here, we propose a mechanistic approach linking the observed levels of NNRTI resistance to the underlying dynamics of HIV in each country.\nWe developed a SIR-like model consisting of a hierarchical system of ordinary differential equations in Stan. The model considered the infection of susceptible individuals with HIV, the treatment of diagnosed individuals with ART from the early 2000s, the occurrence of resistance mutations in response to the evolutionary pressure created by ART, and the transmission of mutant, resistant viruses to susceptible individuals. The model was fitted jointly to country-level data regarding different aspects of the HIV epidemic (prevalence of HIV, number of people under ART and population size in 8 countries of southern Africa from 2000 to 2016) and to measurements of NNRTI resistance in cross-sectional surveys (60 surveys from 2000 to 2016). Partial pooling was allowed by introducing a hierarchical structure by country on the parameters governing the occurrence of resistance, as well as a hierarchical structure by survey on resistance data.\nThe model could adequately reproduce the dynamics of the HIV epidemics in each country. We found substantial heterogeneity between the rates of emergence of NNRTI resistance across countries that is not explained by differences in the local dynamics of HIV transmission and treatment. Understanding the factors associated with this heterogeneity will allow public health authorities to anticipate on potential issues of drug resistance emergence related to local characteristics.\n\n Modelling enzyme kinetics with Stan.Teddy Groves. DTU BIOSUSTAIN Quantitative Modelling of Cell Metabolism Team Video\nAbstract: The advent of high-throughput technologies has transformed molecular biology into a data-rich discipline. However, integrating this data into a predictive modeling framework is not trivial because many different sources of uncertainty about the molecular processes governing cell metabolism must be taken into account. In particular, reaction fluxes and steady-state reactant concentrations can at best be measured noisily, and even for the best-understood organisms pre-experimental knowledge of kinetic parameters is incomplete and imprecise.\nWe are using Stan to overcome the existing limitations in the study of cell metabolism by combining pre-experimental knowledge about kinetic parameters with experimental measurements of reactant concentrations and reaction fluxes. The presentation and accompanying notebook show a simple but instructive case.\nWe model cell metabolism as a set of differential equations describing enzyme-catalysed reactions. Expert knowledge is taken into account in the form of priors over parameters describing the enzymes’ dynamics. Measured metabolite concentrations and reaction fluxes are treated as depending on the parameters via the differential equations, with random noise representing measurement error.\nWe will discuss how our approach compares to others in the same field, how we plan to develop our project and some of the challenges we have faced so far. The biggest challenge is that a large and complicated system of ODEs must be solved every time the joint log probability density is evaluated. We demonstrate a strategy for speeding up this calculation by exploiting the assumption that the system of reactions is at steady state.\nhttps://www.biosustain.dtu.dk/research/scientific-sections/quantitative-modelling-of-cell-metabolism/staff-quantitative-modelling-of-cell-metabolism\n\n Modeling cocoa bean fermentation processes. Mauricio Moreno-Zambrano, Sergio Grimbs, Matthias S. Ullrich and Marc-Thorsten Hütt.  Department of Life Sciences & Chemistry, Jacobs University Bremen Video\nAbstract:A key step in the production of chocolate is the fermentation of cocoa beans. This importance relies on its role in the development of chocolate’s flavor and aroma. Unlike other food fermentation processes, this specific fermentation is well known because of its lack of control and multiple ways in which it is performed. Here, a quantitative model of cocoa bean fermentation is constructed on previously available data regarding microbiological and metabolites dynamics. The model is formulated as a system of coupled ordinary differential equations (ODEs) with two different types of state variables: (1) Metabolite concentrations of glucose (Glc), fructose (Fru), ethanol (EtOH), lactic acid (LA) and acetic acid (Ac), and (2) population sizes of yeast (Y), lactic acid bacteria (LAB) and acetic acid bacteria (AAB). In total, the model comprehends 25 unknown parameters that were estimated using the Markov chain Monte Carlo No-U-Turn sampler in Rstan. Thereafter, we demonstrate that the model can quantitatively describe existing fermentation series and that the estimated parameters can be used to extract and interpret differences in environmental conditions between two independent fermentation trials [1].\nReferences\n[1] Moreno-Zambrano, M., Grimbs, S., Ullrich M. S. and Hütt, M-T. (2018). A mathematical model of cocoa bean fermantation. Royal Society Open Science, 5(10), 180 964.\n\n Bayesian analyses of time-to-event data using the rstanarm R package. Eren M. Elçi, Sam Brilleman. Public Health and Preventive Medicine, Monash University.  Video\nAbstract: Time-to-event data refers to the observed time from a defined origin (e.g. diagnosis of a disease) until a terminating event of interest (e.g. death). Time-to-event data emerges in a range of industries and scientific disciplines, although it is particularly common in medical and pharmaceutical research. In these research fields, time-to-event data is commonly known as survival data reflecting the fact that death is an event endpoint often used in clinical studies. Analyses of survival data are widely used for decision making in clinical trials, drug development and regulatory approvals.\nIn this talk we introduce a flexible family of Bayesian survival models that are being integrated into the rstanarm R package through the new stan_surv modelling function. The implementation uses a familiar formula syntax for specifying covariates and censoring mechanisms, based on the widely recognised survival R package. The stan_surv modelling function accommodates standard parametric (e.g. exponential, Weibull and Gompertz) survival models under either hazard or accelerated failure time formulations. Additionally, flexible parametric (cubic spline-based) hazard models are available. These allow the time-dependent baseline hazard and time-dependent effects of covariates to both be modelled using flexible smooth functions. We demonstrate the software using an example dataset. We put particular emphasis on functionality that allows practitioners to implement survival analyses as part of a robust Bayesian workflow, including prior and posterior checks and efficient leave-one-out cross-validation.\n\n Prior choice in logit models of discrete choice. Jim Savage. Schmidt Futures Video\nAbstract: In models of discrete choice, sensible-seeming priors on part-worth coefficients can imply priors in the choice probability space that are highly implausible, putting close to 100% prior weight on a single choice dominating all others. This problem reveals itself in problems with initialization and poor fit quality. Yet choosing priors is complicated by the research design, including the dimensionality of choice attributes, and their scale and covariance. In this talk I provide intuition for how priors and choice attributes interact to create extreme prior choice probabilities, and describe a new method to define priors that implies close-to-uniform weight in the choice probability space.\n\n Semiparametric Modeling of the Mean,Variance and Scale Parameters in Skew NormalRegression Models: A Bayesian Perspective. Héctor Zarate. \nAbstract: The goal of this paper is to estimate the location, scale and shape functions in heteroscedastic semiparametric models when the response variable comes from a skew normal distribution. We rely on the connection among smoothing methods that use basis functions with penalization, mixed models and a Bayesian Markov Chain sampling simulation methodology. The novelty of our strategy lies in its potential to contribute to a simple and unified computational methodology that takes into account the factors that affect the parameters in the responses, which in turn is important for an efficient estimation and correct inference without the requirement of fully parametric models. A simulation study investigates the performance of the estimates. Finally, an application using the forecasting predictive densities, highlights the merits of our approach.\n\n Hierarchical models for gamma-ray burst populations. J. Michael Burgess.  MPE \nAbstract: Inferring the number, rate and intrinsic properties of short gamma-ray bursts has been a long studied problem in the field. As it is closely related to the number of GW events expected for neutron star mergers, the topic has begun to be discussed int he literature again. However, the utilized techniques for GRBs still rely on improper statistical modeling V/Vmax estimators and in many cases, methods are simply guessed. I will discuss the use of Bayesian hierarchal models to infer population and object level parameters of inhomogeneous-Poisson process distributed populations. Techniques to handle high-dimensional selections effects will be introduced. The methodology will then be applied to sGRB population data with the aim of understand how many of these objects there are, where they are in the Universe and what are their properties under given modeling assumptions. The methodology is general, thus extensions to other populations can be made easily.\n\n A Decision-Theoretic Journey From Early Clinical Data to Late Stage Efficacy using Hierarchical Joint Models.. Krzysztof Sakrejda, Eric Novik.  Generable  Video\nAbstract: Most statistical problems end with estimating the quantities of interest which may be unobservable parameters or in the prediction context, potentially observable data. As statisticians we sometimes forget that models are often decision-making tools and making decisions conditional on our understanding of the uncertainties in the system is the ultimate goal of the consumers of our models. In this talk, we will introduce a decision problem of advancing therapies to late-stage clinical trials from early-stage clinical data. We do this in the context of a Bayesian Joint Model.\nIn clinical studies, it is common to measure a clinical biomarker repeatedly over time (‘longitudinal data’). It is also common to measure the patient-specific time from a defined origin, e.g. diagnosis of a disease, until a clinical event of interest, such as death or disease progression (‘survival data’). Joint Modeling as it is called in the Survival literature aims to model both the longitudinal biomarker evolutions and survival endpoints simultaneously. Commonly, this is achieved by specifying a joint likelihood formulation for longitudinal and survival outcomes.\nJoint modeling approaches provide several benefits over more traditional modeling and have applications to health through (i) improving the understanding of how biomarkers influence event endpoints; (ii) the development of dynamic risk prediction models for use in personalized medicine; and in the context of clinical trials (iii) requiring fewer patients than the event model alone.\nOnce the inferences from the Joint Model are obtained, we set up a Utility function describing the risk preferences of the trial’s sponsors and take its expectation with respect to the posterior distribution. The resulting function is then maximized.\n\n The State of GPU Computation Support for Stan. Rok Češnovar (University of Ljubljana - UL), Steve Bronder (Capital One), Davor Sluga (UL), Jure Demšar (UL), Tadej Ciglarič (UL), Sean Talts (Columbia University), Erik Štrumbelj (UL).  Video\nAbstract: Our presentations details the current state of and future work on the OpenCL-based framework that allows the Stan automatic differentiation library to utilize GPUs. Our research was initially motivated by large Gaussian Process models where the computation is dominated by the Cholesky decomposition but has since developed into an extensible framework.\nThe following GPU-optimized routines for matrix algebra primitives are already available to Stan users (including reverse mode): matrix multiplication, solving triangular systems, Cholesky decomposition and some special cases. Several support functions are available in the Math library but not exposed to Stan users: matrix initialization, input validity checking, copy, pack/unpack, multiplication by scalar, and transpose. We have made progress on implementing commonly used likelihoods - 4 Generalized Linear Model likelihoods can already be used: normal (identity), Bernoulli (logit), Poisson (log) and Negative Binomial (log). And data caching is now available and substantially reduces the overhead of transferring data to the GPU.\nWe will show how problem size, model and choice of hardware impact the speedups that we can achieve with GPU computation in Stan. Finally, we will discuss directions for future work, routines to implement next, autotuning tunable GPU parameters and advanced data caching.\n\n Extending Stan’s Automatic Differentiation (AD) capabilities using dco/c++. Philip Maybank. Numerical Algorithms Group (NAG)  Video\nAbstract: Tape-based AD Libraries, such as NAG’s dco/c++ tool, keep a record of calculations that are executed by a program in order to evaluate derivatives. They are applicable to a wider range of numerical codes than tape-free AD libraries, which are typically written to compute derivatives for a specific library of functions. The Stan Math Library is a tape-free AD library. The basic idea of the work in this presentation is that dco/c++ can be used to supply derivatives to Stan. This extends the range of functions which can be used by Stan’s MCMC samplers. We illustrate this idea on a toy problem: inferring the parameters of a damped harmonic oscillator driven by white noise using Stan’s NUTS.\n\n Estimating the prevalence of HIV infection in England using Bayesian evidence synthesis. Anne Presanis, Christopher Jackson [presenting author], Daniela De Angelis (MRC Biostatistics Unit, University of Cambridge); Peter Kirwan, Alison Brown, Ada Miltz, Ross Harris, Cuong Chau, Stephanie Migchelsen, Hamish Mohammed, Katy Davison, Sara Croxford, Sarika Desai, Kathy Lowndes, Valerie Delpech, Noel Gill (Public Health England).  Video\nAbstract: We present a substantive application of Stan that has informed national health policy.\nAnnual estimation of the number of people living with HIV in England, including those who are unaware of their infection, has, for several years, been based on a Bayesian model that combines evidence from multiple sources of data. For several demographic and risk groups, the model estimates the number of people in each group, the prevalence of HIV, and the proportion of HIV infections that are diagnosed.\nIn the 2018 version of this model, implemented in Stan, the strata are defined by age, gender, sexual behaviour, injecting drug use, ethnicity and region. Changes between years are also modelled. Routinely-collected data sources include a register of diagnosed HIV infections, a register of attendances at genitourinary medicine (GUM) clinics, and the national census. These are combined with data from several surveys of health and sexual behaviour among different groups, HIV testing data from unlinked anonymous surveys of drug users, and data from HIV testing of donated blood.\nThis is an example of a ““multiparameter evidence synthesis”“, where the quantities of interest cannot be estimated directly, but can be inferred indirectly through a network of model assumptions. Potential biases due to selection, under-reporting and missing data are represented explicitly through structural assumptions and informative priors. A four-level hierarchical model is used to borrow strength between stratum-specific parameters. Stan’s model description language makes the assumptions explicit, and its inference engine provides posterior estimates efficiently.\nThe estimates from 2018 demonstrate that the UN-AIDS target of 90% of infections diagnosed by 2020 has been met in England, and the estimates continue to inform policies around HIV testing, treatment and prevention.\n\n Estimating the effect of age and league on scoring rate in professional soccer. Benjamin Torvaney. Wefarm\nAbstract: Understanding the effect of different factors on player output is critical to accurately evaluating player performance. In particular, it is useful to be able to project performance into the future, whether to assess a potential new signing, or to aid in squad management. To do this, we must account for footballing context. Intuitively, we know that scoring goals in the Norwegian Eliteserien is less impressive than scoring in the Premier League; however, this is rarely quantified.\nIf we propose a model in which a player’s expected goalscoring rate is the product of their ability, the difficulty of the competition, and a relative age effect, we can estimate the effect of each parameter from historical goalscoring tallies (accompanied by minutes played). We can extend the model to allow competition factors to vary over time, to reflect the changing dynamics of professional soccer.\nSuch a model yields promising results: high profile soccer stars have the highest model estimates; a clear age curve for goalscoring is produced; competition strengths vary over time in accordance with popular perception.\n\n Multi-channel Gaussian Processes as flexible alternatives to linear models: perspectives and challenges to scaling up Bayesian inference to genomic-scale data. Caetano Souto-Maior, Susan T. Harbison. Laboratory of Systems Genetics, National Heart Lung and Blood Institute, NIH.\nAbstract:\n\n One weird trick: Non-parametric Bayesian updating by kernels. Robert Grant.  BayesCamp\nAbstract: One of the big attractions for people adopting Bayesian methods is the promise of ““updating”” their parameter estimates and predictions as more data arrive. Yesterday’s posterior becomes today’s prior. In practice, this is not always simple, requiring at the very least a complete set of sufficient statistics, random samples from an unchanging population, and no changes of mind about the probability distribution for the priors. Sometimes, one would like to update without imposing an a priori distribution on yesterday’s posterior and without estimating lots of statistics. I discuss a kernel approach, which is easily incorporated in Stan by an additional target+= statement, looping over yesterday’s posterior draws, and uniform proposal densities. I compare this with parametric updates, and explore the potential to reduce computation by using kernels weighted by counts of posterior draws inside hypercubes of parameter space.\n\n Making Stan Faster using Sequential Monte Carlo samplers. Simon Maskell (University of Liverpool), Alessandro Varsi (University of Liverpool), Peter Green (University of Liverpool), Paul Horridge (University of Liverpool), Alejandro Diaz (University of Liverpool), Lee Devlin (University of Liverpool), Rob Moore (University of Liverpool), Katerina Chatzopoulou (University of Liverpool), Jinglai Li (University of Liverpool), Maria Sudell (University of Liverpool), Luke Mason (STFC), Robin Pinning (STFC), Jack Taylor (STFC), Vassil Alexandrov (STFC), Ed Pyzer-Knapp (IBM). \nAbstract: Stan uses the No U-Turn Sampler (NUTS), a specific instance of Markov Chain Monte Carlo (MCMC). MCMC can be slow, e.g., when dimensionality is high and it would be better if NUTS was faster. We have recently been working to improve the run-time of a solution to problems that Stan can tackle (and those that it cannot, e.g. those that would require reversible jump MCMC). Our approach has been to replace NUTS with a variant of a Sequential Monte Carlo (SMC) sampler that uses the clever ideas embodied in NUTS without coupling them to MCMC specifically. SMC samplers manipulate a population of samples, making it possible to distribute computation across each of many processors. Our work has shown that SMC samplers can be configured to exploit this parallelism (and the advances that have led to the development of, for example, the use of NUTS as a proposal distribution). This can achieve faster run-time than MCMC in terms of the number of effective samples per second (by running the SMC sampler on clusters of hundreds of cores, as are routinely used in the context of Deep Learning, for example). Furthermore, we have shown that SMC samplers can be configured to outperform MCMC by making better use of the available processing resources. This is possible because MCMC’s convergence proofs require that the single sampling chain never goes wrong while the proofs for SMC samplers only require that the samples don’t all malfunction simultaneously. Put another way, SMC samplers have an additional degree of freedom in their design and this degree of freedom can be exploited to offer improved performance relative to MCMC. This talk will explain how SMC samplers can outperform MCMC per second and per flop. We will also describe our progress to date on integrating SMC samplers into Stan: our intent is to make it possible to use all Stan files. Thus far we’re able to achieve a runtime that is over an order of magnitude faster than MCMC.\n\n Gaussian process modeling and covariate selection for longitudinal data. Juho Timonen, Aki Vehtari, Harri Lähdesmäki. Alto University\nAbstract: Longitudinal data arises when the same observational units are measured repeatedly, and is common in clinical studies. Such data is often modeled using generalized linear mixed effect models with off-the-shelf software packages. These are, however, restricted to a parametric form and cannot model non-stationary disease effects. We demonstrate our new R-package for interpretable Bayesian non-parametric modeling of longitudinal data using additive Gaussian processes. Like the R-packages and brms, our goal is to provide an interface to Stan with a simple and intuitive syntax. However, our Stan program is specifically designed for Gaussian process modeling of longitudinal data, allowing the user to specify a model that mixes group and individual-specific age effects or effects of other continuous or categorical covariates. We show how our package uses Stan to model non-stationary disease effects and uncertainty of the observed disease onsets, identify heterogeneous effects present in only a subset of study subjects, and handles general non-Gaussian likelihoods. Furthermore, we define a way of resolving the relevance of any continuous or categorical covariate by sampling only one full model with all covariates included. Our focus is on biomedical applications, where is often vital to determine which covariates affect the response variable, in order to reduce future measurement costs or have a better interpretation about the progression of a disease.\n\n Computing prediction and tolerance intervals for a mixture of normal distributions. Jean-francois Michiels, Timothy Mutsvari, Oussama Errazi. Pharmalex\nAbstract: For the submission of a Biosimilar product, Biosimilarity assessment is the first step to achieve in the “Totality of Evidence” strategy as required by Authorities (e.g. FDA). The main objective of biosimilarity is to give evidence that the test biological product is as similar as possible to the reference product. The definition of ‘similar’ remains a critical component that needs to be addressed and justified. For biologicals, it is the process and its capability that should be evaluated, i.e. the risk of producing batches outside defendable limits. Thus, the first step is to set the acceptance limits. β-expectation and (β,γ), also known as Beta-Gamma, tolerance intervals are useful metrics to demonstrate that a test product (i.e. the biosimilar) is similar to a reference product. Biosimilarity is concluded if the β-expectation of the biosimilar product is within the (β,γ) of the reference. β-expectation interval is constructed to contain a β proportion of the population on average. A (β,γ) tolerance interval on the other hand is built to contain at least a β proportion of the population with a confidence level γ. In general, the pharmaceutical company producing the biosimilar has no access to the data of the reference product. Buying boxes of the reference product from several drugstores and analysing them is nevertheless one possible strategy to acquire knowledge on the process variability. Due to that sampling strategy, the distribution of the reference product can be quite exotic and it is likely that the distribution of the reference product is a mixture of normal distributions. Fitting a mixture of 2 normal distributions on data is performed using Stan. The output are the posterior distributions of the mean and standard deviation of the 2 normal distributions and the posterior distribution of the relative proportion of the 2 distributions. We present different algorithms to derive β-expectation and (β,γ) tolerance intervals for a mixture of 2 normal distributions. Using simulations, the operating characteristics of the intervals are shown (e.g. the capability to conclude similarity when it is actually similar).\n\n Parallel numerical ODE solution in Torsten for population models. Yi Zhang, William R. Gillespie. Metrum LLC\nAbstract: Torsten is a collection of functions to facilitate analysis of pharmacometric data using Stan. To seek an alternative to the ““map_rect”” function for within-chain parallel computation in Stan, we have implemented numerical ODE solution functions for population models with functional signatures that specify schedules of events such as doses and observations in a manner consistent with NONMEM compatible.\nThe population solution function feature is designed toward multi-level parallelization using Message Passing Interface(MPI). For that we first implemented Torsten’s own ODE integrators based on CVODES library. Table 1 shows MPI performance results of such an integrator on a group of 1000 Lorenz systems.\n\n\n\nn_processor\n\n\nWalltime(ms)\n\n\nSpeedup\n\n\nefficiency\n\n\n\n\n1\n\n\n10986\n\n\n1.00\n\n\n1.00\n\n\n\n\n2\n\n\n5505\n\n\n2.00\n\n\n1.00\n\n\n\n\n4\n\n\n3091\n\n\n3.55\n\n\n0.89\n\n\n\n\n8\n\n\n1459\n\n\n7.53\n\n\n0.94\n\n\n\n\n16\n\n\n1355\n\n\n8.11\n\n\n0.51\n\n\n\n\n32\n\n\n739\n\n\n14.87\n\n\n0.46\n\n\n\n\n64\n\n\n424\n\n\n25.91\n\n\n0.40\n\n\n\n\n128\n\n\n382\n\n\n28.76\n\n\n0.22\n\n\n\n\n256\n\n\n284\n\n\n38.68\n\n\n0.15\n\n\n\n\n512\n\n\n293\n\n\n37.49\n\n\n0.07\n\n\n\nTable 1: MPI performance of the Lorenz model solved by Torsten’s BDF integrator. (n_population = 1000)\nThen we developed MPI-based population solvers that are specifically designed for PKPD applications, for which ODE system size \\(n\\) is typically in the scale of \\(10^0\\sim 10^2\\). We employ the latest standard(MPI-3) functionalities for latency hiding, and test the implementation on two MPI implementations (OpenMPI and MPICH). Tables 2-5 show performance results of one such function on a simple two-compartment PK model(\\(n=3\\)) and a more complex PKPD model(\\(n=8\\)), run on a METWORX workflow.\n\n\n\nn_processor\n\n\nWalltime(ms)\n\n\nSpeedup\n\n\nefficiency\n\n\n\n\n1\n\n\n2966\n\n\n1.00\n\n\n1.00\n\n\n\n\n2\n\n\n1544\n\n\n1.92\n\n\n0.96\n\n\n\n\n4\n\n\n866\n\n\n3.42\n\n\n0.85\n\n\n\n\n8\n\n\n887\n\n\n3.34\n\n\n0.42\n\n\n\nTable 2: Parallel performance of solving a two-compartment population model using pmx_solve_group_bdf and OpenMPI.\n\n\n\nn_processor\n\n\nWalltime(ms)\n\n\nSpeedup\n\n\nefficiency\n\n\n\n\n1\n\n\n45791\n\n\n1.00\n\n\n1.00\n\n\n\n\n2\n\n\n23532\n\n\n1.95\n\n\n0.97\n\n\n\n\n4\n\n\n13421\n\n\n3.41\n\n\n0.85\n\n\n\n\n8\n\n\n10394\n\n\n4.41\n\n\n0.55\n\n\n\nTable 3: Parallel performance of solving a Neutropenia population model using pmx_solve_group_bdf and OpenMPI.\n\n\n\nn_processor\n\n\nWalltime(ms)\n\n\nSpeedup\n\n\nefficiency\n\n\n\n\n1\n\n\n2470\n\n\n1.00\n\n\n1.00\n\n\n\n\n2\n\n\n1419\n\n\n1.74\n\n\n0.87\n\n\n\n\n4\n\n\n1170\n\n\n2.11\n\n\n0.53\n\n\n\n\n8\n\n\n860\n\n\n2.87\n\n\n0.36\n\n\n\nTable 4: Parallel performance of solving a two-compartment population model using pmx_solve_group_bdf and MPICH.\n\n\n\nn_processor\n\n\nWalltime(ms)\n\n\nSpeedup\n\n\nefficiency\n\n\n\n\n1\n\n\n45087\n\n\n1.00\n\n\n1.00\n\n\n\n\n2\n\n\n22976\n\n\n1.96\n\n\n0.98\n\n\n\n\n4\n\n\n14158\n\n\n3.18\n\n\n0.80\n\n\n\n\n8\n\n\n10523\n\n\n4.28\n\n\n0.54\n\n\n\nTable 5: Parallel performance of solving a Neutropenia population model using pmx_solve_group_bdf and MPICH.\nIn addtional to population-level parallelization, we are also implementing individual-level parallelization based on parallel time integration with multigrid. This will enables us to reduce the solution time of a single ODE system, and create a multi-level parallelization for ODE-based population models. The results of a preliminary implementation are shown in Table 6.\n\n\n\nn_processor\n\n\nWalltime(ms)\n\n\nSpeedup\n\n\nefficiency\n\n\n\n\n1\n\n\n2.8\n\n\n1.00\n\n\n1.00\n\n\n\n\n2\n\n\n1.7\n\n\n1.65\n\n\n0.82\n\n\n\n\n4\n\n\n1.2\n\n\n2.33\n\n\n0.58\n\n\n\nTable 6: Parallel performance of solving 10^4 steps of a single Neutropenia ODE system using parallel-in-time technique."
  },
  {
    "objectID": "learn-stan/stancon/stancon2019-abstracts.html#talks-by-topic",
    "href": "learn-stan/stancon/stancon2019-abstracts.html#talks-by-topic",
    "title": "StanCon 2019 Programme",
    "section": "",
    "text": "Pharmaceuticals/Medicine\n\nComputing prediction and tolerance intervals for a mixture of normal distributions. Jean-francois Michiels, Timothy Mutsvari, Oussama Errazi. Pharmalex. Abstract\nParallel numerical ODE solution in Torsten for population models. Yi Zhang, William R. Gillespie. Metrum LLC Abstract\nMulti-channel Gaussian Processes as flexible alternatives to linear models: perspectives and challenges to scaling up Bayesian inference to genomic-scale data. Caetano Souto-Maior, Susan T. Harbison. Laboratory of Systems Genetics, National Heart Lung and Blood Institute, NIH. Abstract\nEstimating the prevalence of HIV infection in England using Bayesian evidence synthesis. Anne Presanis, Christopher Jackson [presenting author], Daniela De Angelis (MRC Biostatistics Unit, University of Cambridge); Peter Kirwan, Alison Brown, Ada Miltz, Ross Harris, Cuong Chau, Stephanie Migchelsen, Hamish Mohammed, Katy Davison, Sara Croxford, Sarika Desai, Kathy Lowndes, Valerie Delpech, Noel Gill (Public Health England).  Abstract Video\nA Decision-Theoretic Journey From Early Clinical Data to Late Stage Efficacy using Hierarchical Joint Models.. Krzysztof Sakrejda, Eric Novik.  Generable  Abstract Video\nBayesian analyses of time-to-event data using the rstanarm R package. Eren M. Elçi, Sam Brilleman. Public Health and Preventive Medicine, Monash University. Abstract Video\nModelling enzyme kinetics with Stan. Teddy Groves. DTU BIOSUSTAIN Quantitative Modelling of Cell Metabolism Team Abstract Video\nThe emergence of HIV resistance to antiretroviral therapy in southern Africa: a mechanistic meta-analysis of survey data. Julien Riou, Matthias Egger, Christian Althaus. Institute of Social and Preventive Medicine, University of Bern, Switzerland Abstract Video\nHandling missing data, censored values and measurement error in machine learning models using multiple imputation for early stage drug discovery. Rowan Swiers. AstraZeneca Abstract Video\nA Bayesian multi-layered model to predict mechanisms, types, and severity of drug-induced liver injury. Elizaveta Semenova, Dominic Williams, Stanley E Lazic. Data Science and Quantitative Biology group, AstraZeneca, Cambridge UK Abstract\n\nModeling\n\nGaussian process modeling and covariate selection for longitudinal data. Juho Timonen, Aki Vehtari, Harri Lähdesmäki. Aalto University Abstract\nEstimating the effect of age and league on scoring rate in professional soccer. Benjamin Torvaney. Wefarm Abstract\nHierarchical models for gamma-ray burst populations. J. Michael Burgess.  MPE  Abstract\nModeling cocoa bean fermentation processes. Mauricio Moreno-Zambrano, Sergio Grimbs, Matthias S. Ullrich and Marc-Thorsten Hütt.  Department of Life Sciences & Chemistry, Jacobs University Bremen Abstract Video\nApproximate leave-future-out cross-validation for Bayesian time series models. Paul Bürkner, Jonah Gabry, Aki Vehtari.  Abstract Video\nWhen seasonality meets Bayesian: Decomposing seasonalities in Stan. Hyunji Moon, SNU, Hyeonseop Lee, PUBG.  Abstract Video\nPrediction and causal inference for time-to-event outcomes truncated by death. . Leah Comment.  Abstract Video\nFast Forward Like a Lambo (skrrt skrrt). Daniel Lee. Generable Abstract Video\nThe Currency of Place and the Short-Term Rental Market. Mikael Brunila.  Abstract Video\nProfit-Maximizing A/B Tests. Elea McDonnell Feit, Ron Berman. Drexel Univeristy, The Wharton School Abstract Video\nStructured priors for survey estimates in the presence of non-representative data. Yuxiang Gao (University of Toronto), Lauren Kennedy (Columbia University), Daniel Simpson (University of Toronto).  Abstract Video\nChronikis: a Bayesian time-series modeling language. Kevin S. Van Horn. Adobe Inc. Abstract Video\nA long-short term event memory state-space model for multi-party elections. Marcus Groß. INWT Statistics GmbH Abstract\nSimulation of Statistic Mechanical Systems using Stan. Forrest Eli Hurley. North Carolina State University Abstract Video\nRegularized Hierarchical Models for Remotely Sensed Forest Inventories. Nathan E. Rutenbeck SilviaTerra Abstract \nGetting the Lead out–Does New York City’s childhood lead testing make statistical sense?. Jonathan Auerbach, Breck Baldwin. Columbia Univeristy Abstract Video \n\nInference\n\nMaking Stan Faster using Sequential Monte Carlo samplers. Simon Maskell (University of Liverpool), Alessandro Varsi (University of Liverpool), Peter Green (University of Liverpool), Paul Horridge (University of Liverpool), Alejandro Diaz (University of Liverpool), Lee Devlin (University of Liverpool), Rob Moore (University of Liverpool), Katerina Chatzopoulou (University of Liverpool), Jinglai Li (University of Liverpool), Maria Sudell (University of Liverpool), Luke Mason (STFC), Robin Pinning (STFC), Jack Taylor (STFC), Vassil Alexandrov (STFC), Ed Pyzer-Knapp (IBM) .  Abstract\nOne weird trick: Non-parametric Bayesian updating by kernels. Robert Grant. BayesCamp Abstract\nSemiparametric Modeling of the Mean,Variance and Scale Parameters in Skew Normal Regression Models: A Bayesian Perspective. Héctor Zarate.  Abstract\nPrior choice in logit models of discrete choice. Jim Savage. Schmidt Futures Abstract Video\nStacking for multimodal posterior distributions. Yuling Yao, Aki Vehtari and Andrew Gelman.  Abstract Video\nBayesian leave-one-out cross-validation for large data. Måns Magnusson, Aalto, Michael Riis Andersen, Danish Technical University, Johan Jonasson, Chalmers Technical University, Aki Vehtari, Aalto.  Abstract Video\n\nCore Stan\n\nThe State of GPU Computation Support for Stan. Rok Češnovar (University of Ljubljana - UL), Steve Bronder (Capital One), Davor Sluga (UL), Jure Demšar (UL), Tadej Ciglarič (UL), Sean Talts (Columbia University), Erik Štrumbelj (UL).  Abstract Video\nExtending Stan’s Automatic Differentiation (AD) capabilities using dco/c++. Philip Maybank. Numerical Algorithms Group (NAG) Abstract Video"
  },
  {
    "objectID": "learn-stan/stancon/stancon2019-abstracts.html#abstracts",
    "href": "learn-stan/stancon/stancon2019-abstracts.html#abstracts",
    "title": "StanCon 2019 Programme",
    "section": "",
    "text": "Regularized Hierarchical Models for Remotely Sensed Forest Inventories. Nathan E. Rutenbeck SilviaTerra \nManagement and conservation of the world’s forests is critical for maintaining global timber supply, as well as for the ecosystem services forestlands provide. Forest biometrics remains a field focused on traditional methods in sampling and regression, despite the fact that these methods are ill equipped to utilize the profusion of remote sensing data now available. When remote sensing data is used, it is often deployed within simple population-level regression models that simultaneously leave out information regarding known forest structure and sample design, and are prone to overfitting of effects at the population level. Using Stan, we show that for the prediction of forest basal area (a key inventory attribute) incorporating known structural attributes (forest stands) and sample design information into a hierarchical modeling framework along with remote sensing data can yield beneficial results in terms of reducing overfitting and improving predictive performance when compared to more conventional methods. We fit and compared four candidate models, examining their performance with respect to one another and to the conventional frequentist inferences that are so widely used for operational forest inventory. The four models we examined are 1) a hierarchical model incorporating forest stand and sample design effects; 2) a population-level remote sensing principal components model; 3) the hierarchical model with the addition of remote sensing principal component effects at the population level; and 4) the hierarchical and remote sensing model with the addition of regularizing horseshoe priors on remote sensing effects. The hierarchical model without remote sensing effects showed the expected shrinkage of stand-level mean basal area predictions toward the global mean. The addition of remote sensing effects showed overall reductions in prediction error in comparison to the sample design model. Incorporating regularizing priors on the remote sensing principal components effects retained signal from the remote sensing data but showed further shrinkage of predictions of stand-level mean basal area toward sample means. Our results suggest that the penalized hierarchical model can be used in developing operational forest inventories that balance information from known forest structural heterogeneity, the sample design, and remote sensing data.\n A Bayesian multi-layered model to predict mechanisms, types, and severity of drug-induced liver injury. Elizaveta Semenova, Dominic Williams, Stanley E Lazic. Data Science and Quantitative Biology group, AstraZeneca, Cambridge UK \nAbstract: Drug-induced liver injury (DILI) is a major cause of attrition in drug development and a common reason for withdrawing a drug from the market. Predicting clinical liver toxicity is difficult, but preclinical in vitro assays and physical/chemical properties of drugs can be used as predictors. We developed a multi-layered Bayesian model where we use assay results to predict the mechanism(s) of toxicity, use the mechanisms to predict the type of liver injury, and then combine the type of injury with the clinical dose of a drug to predict the severity of injury. The model therefore has a layered structure, enabling uncertainty to propagate through the layers. Based only on assay and physchem data, along with the clinical dose, the model enables safety pharmacologists to predict the severity, type, and mechanism of liver toxicity with good accuracy.\n\n \n Getting the Lead out–Does New York City’s childhood lead testing make statistical sense?. Jonathan Auerbach, Breck Baldwin. Columbia Univeristy .  Video\nAbstract: The US has dramatically reduced blood lead levels in children over the past 30 years and that effort continues. New York City (NYC) was an early adopter of lead reduction policies and that effort continues with laws that require all children be tested and with mandatory interventions for those tested blood levels (tbll) greater than 5mg/dL. But there is a statistically interesting story around how current blood level limits are set, the performance of common tests and how to apply common Bayes rule reasoning to publicly available data.\nThe data we have: We have high quality blood lead level (bll) tests applied nation wide (NHANES) for 5,000 children, we have NYC supplied data that provides counts for all children’s tested blood lead level, the number greater than 5mg/dL, 10mg/dL and 15/dL and claims of blood tests that widely vary from sources like FDA applications for blood testing equipment, actual studies of test performance and government testing standards.\nThe data we want: New York city recently dropped the threshold for intervention from 10mg/dL to 5mg/dL. It is an open question what the false positive rate is for these test thresholds with some research suggesting that it is as high as 70%. On the other extreme is an FDA applications for the LeadCare Plus testing device claim a standard deviation of .5 at the 5mg/dL which suggests a very low false positive rate…but that depends on the distribution of actual blls in the NYC population.\nHow we got the data we wanted: This is a simple application of Bayes rule: p(bll &gt; 5|t &gt;5) = p(tbll &gt; 5| bll&gt;5) p(bll&gt;5)/p(tbll&gt;5) where we don’t know p(bll&gt;5) for NYC. NYC refused to release non-quantized data for tbll under FIOA requests, which if we had, would allow a fairly straightforward determination of false positive rates from tbll test evaluations. But we do have data for the US as a whole in non-quantized form.\nThe paper describes a process of model refinement staring with naive approaches and incrementally modifying our models to better suite NYC data. The final approach, subject to change as we do more work, is to fit national NHANES data with an exponential distribution, assume that similar distributions apply to NYC and recover a believable false positive rate across a range of reported blood test performance. Along the way we show an interesting simple use of the ‘integrate_ode_rk45’ function in Stan and demonstrate Bayesian workflow.\n\n Simulation of Statistic Mechanical Systems using Stan. Forrest Eli Hurley. North Carolina State University  Video\nAbstract: Bayesian statistics is closely coupled with physics. The metropolis algorithm (1953) was developed by scientists working at Los Alamos as a method for thermodynamic simulation of molecular dynamics. Not until the work of W. K. Hastings (1970) was the method generalized to arbitrary probability distributions. Hamiltonian Monte Carlo is even more deeply rooted in physics than the Metropolis-Hastings algorithm. The simulation of states with velocities, energies, and a Hamiltonian describes nothing other than a physical system. It matches a canonical ensemble in that there is not a fixed energy between steps, only an overall fixed temperature. The temperature is usually only implicit, but some tempering methods simulate chains at higher temperatures to smooth the probability distributions. The Ising Model, a proxy for magnetization, is a prevalent introductory model in the study of statistical mechanics. It consists of an N-dimensional grid of spin up or down particles. The energy varies depending on the alignment of spins between nearest neighbors. At low temperatures spins tend to align on a macroscopic scale; at high temperatures they become evenly distributed. We simulate the XY Model, similar to the Ising Model but allowing spins to be represented by unit vectors in two dimensions, using Stan. We create chains at several temperatures to identify the locations of phase transitions in macroscopic properties. Our work shows the applicability of Stan for computation in continuous statistical mechanical problems.\n\n A long-short term event memory state-space model for multi-party elections. Marcus Groß. INWT Statistics GmbH \nAbstract: State-space models are a popular choice in modelling voting intentions and election results by using poll data. The presented multivariate state-space model attempts to go beyond random-walk or Kalman-filter approaches (with comparable performance to simple weighted survey averages) to the problem by introducing a long-short term event memory effect. This effect serves as reasonable explanation to the observation that the voter’s share partially tends to reverse to the party’s long-term trend after larger short term movements. Any event influencing the voter’s share of a party is presumed to have a convex shaped effect decomposable into a short term effect due to e.g. media spreading and a smaller long term effect remaining despite overlay effects of new events and forgetting. This effect is modelled by a mixture of a random walk and two contrasting autoregressive processes. By also taking advantage of the widely observed effect that government parties tend to fall in voter’s share, whereas the opposite effect is observed for opposition parties, mid- and long-term predictions of election outcomes can be considerably be improved. The Stan-model is fitted and evaluated on poll data from seven pollsters for the German national elections (“Bundestagswahl”) from 1994 to 2017, where low double digits (out-of-sample) improvements in prediction performance can be seen between 3- and 18-months prior elections. By taking into account the pollsters house effects, their poll errors and even more importantly their correlations in poll errors, an appropriate and realistic estimation error can be propagated.\n\n Bayesian leave-one-out cross-validation for large data. Måns Magnusson, Aalto, Michael Riis Andersen, Danish Technical University, Johan Jonasson, Chalmers Technical University, Aki Vehtari, Aalto.  Video\nAbstract: Model inference, such as model comparison, model checking, and model selection, is an important part of model development. Leave-one-out cross-validation (LOO) is a general approach for assessing the generalizability of a model, but unfortunately, LOO does not scale well to large datasets. We propose a combination of using approximate inference techniques and probability-proportional-to-size-sampling (PPS) for fast LOO model evaluation for large datasets. We provide both theoretical and empirical results showing good properties for large data.\n\n Stacking for multimodal posterior distributions. Yuling Yao, Aki Vehtari and Andrew Gelman.  Video \nAbstract: When working with multimodal posterior distributions, MCMC algorithms can have difficulty moving between modes, and default variational or mode-based approximate inferences can understate posterior uncertainty. And, even if the most important modes can be found, it is difficult to evaluate their relative weights in the posterior, which requires computing the integral of the posterior in the neighborhood of each mode. Here we propose an alternative approach, using parallel runs of MCMC, variational, or mode- based inferences to hit as many modes as possible, and then using Bayesian stacking to weight the set of simulations at each mode. Bayesian stacking is a method for constructing a weighted average of distributions so as to minimize cross-validated prediction errors. The result from stacking is not necessarily equivalent, even asymptotically, to fully Bayesian inference, but it serves many of the same goals. We discuss in the context of several theoretical and applied examples.\n\n Chronikis: a Bayesian time-series modeling language. Kevin S. Van Horn. Adobe Inc.  Video\nAbstract: Chronikis (http://chronikis.org) is an open-source language for Bayesian time-series models that compiles to Stan and R. It currently focuses on linear state-space models, with plans to incrementally expand the class of supported models over time. The goal for Chronikis is to allow one to quickly and reliably create and apply a variety of models to a time series, doing a full Bayesian analysis on each.\nThus the Chronikis language itself focuses on concise and clear model specification, and as far as possible the task of creating efficient estimation and forecasting code is left to the compiler. These twin goals are facilitated by making the Chronikis language fully declarative: the body of a Chronikis program is just an expression whose ““value”” is a probability distribution over time series.\nThe compiler applies a series of semantics-preserving transformations to the body of a Chronikis program, eventually arriving at a form that it can straightforwardly translate to Stan. Along the way it infers types and shapes for all variables except the parameters of main(), reparameterizes in some cases to use non-centered parameterization, assigns each variable to the appropriate Stan block, and infers bounds for variables assigned to the parameters block.\nFor the sake of clarity, Chronikis supports operations for constructing complex models from simpler components. For example, here is a Chronikis program for a random-walk model with observation noise:\ndef main(s_rw, s_obs: real{0.0,}, mu0: real, sigma0: real{0.0,}) = sigma_rw ~ half_cauchy(s_rw); sigma_obs ~ half_cauchy(s_obs);\naccum(wn(sigma_rw)) + constp(mu0, sigma0) + wn(sigma_obs)\nNotes on the above:\n\nThe main() parameters s_rw, s_obs, mu0, and sigma0 are prior parameters.\nsigma_rw^2 and sigma_obs^2 are the random-walk and observation-error variances.\nwn(s) is a white noise process with variance s^2.\nconstp(m,s) is a distribution over constant time series, with a Normal(m,s) distribution for the constant value.\naccum is an operator on time-series distributions; accum(D) is a time-series distribution whose draws are cumulative sums of a time series drawn from D.\nSum (+) is another operator on time-series distributions; D1 + D2 is a time-series distribution whose draws are the element-wise sum of independent draws from D1 and D2.\n\nChronikis also has some innovative support for (quasi-)periodic time-series model components. The period can be arbitrarily large, and need not even be an integer. One can allow the periodic pattern to slowly change over time. There is a smoothness parameter, and this bounds the size of the latent state required, regardless of how large the period may be. Chronikis accomplishes all this by constructing a linear state-space model that approximates the zero-mean Gaussian process defined by variant of MacKay’s periodic kernel, modified to ensure that the realizations of the process are themselves zero-centered.\n\n Structured priors for survey estimates in the presence of non-representative data. Yuxiang Gao (University of Toronto), Lauren Kennedy (Columbia University), Daniel Simpson (University of Toronto).  Video \nAbstract:A central theme in the field of survey statistics is estimating population-level quantities through data coming from potentially non-representative samples of the population. Multilevel Regression and Poststratification (MRP), a model-based approach, is gaining traction against the traditional weighted approach for survey estimates. MRP uses partial pooling through random effects, thus shrinking model estimates to an overall mean and reducing potential overfitting. Despite MRP’s straightforward specification of prior distributions, the estimates coming from it are susceptible to bias if there is an underlying structure that the prior does not capture. This work aims to provide a new framework for specifying structured prior distributions that lead to bias reduction in MRP estimates. We use simulation studies to explore the benefit of these priors and demonstrate on US survey data.\n\n Profit-Maximizing A/B Tests. Elea McDonnell Feit, Ron Berman. Drexel University, The Wharton School  Video\nAbstract: Marketers often use A/B testing as a tactical tool to compare marketing treatments in a test stage and then deploy the better-performing treatment to the remainder of the consumer population. While these tests have traditionally been analyzed using hypothesis testing, we re-frame such tactical tests as a Bayesian decision problem with an explicit trade-off between the opportunity cost of the test (where some customers receive a sub-optimal treatment) and the potential losses associated with deploying a sub-optimal treatment to the remainder of the population.\nWe derive a closed-form expression for the profit-maximizing test size and show that it is substantially smaller than that typically recommended for a hypothesis test, particularly when the response is noisy or when the total population is small. The common practice of using small holdout groups for media testing can be rationalized by asymmetric priors. The proposed test design achieves nearly the same expected regret as the flexible, yet harder-to-implement multi-armed bandit.\nAdopting a Bayesian approach to experimental design requires informative priors. We show how priors can be estimated from data on past A/B test, using Stan to fit a hierarchical meta model. An R notebook will be provided which shows the complete process from meta-analysis of past experiments to determining the profit-maximizing sample size for the new A/B test.\nA full paper is available at https://arxiv.org/abs/1811.00457.\n\n The Currency of Place and the Short-Term Rental Market. Mikael Brunila.  Video \nAbstract: Airbnb and short-term rentals are raising rents in cities through the use of new technologies and by catering to culturally savvy populations. As a phenomenon of the attention economy, Airbnb is a platform where meaning becomes priced, as efficient and attractive communication is awarded by more bookings. In this paper, we look at how this capitalization of meaning can be understood by modelling the use of neighbourhood names. Using Natural Language Processing techniques and Bayesian hierarchical logit models with Intrinsic Auto-Regressive priors, we explore how listings draw upon the value placed on well-known neighbourhoods to promote themselves. Our findings separate different spatial effects as well as neighbourhood and listing level patterns that help us explain how neighbourhood names are deployed to promote short-term rentals on Airbnb.\n\n Fast Forward Like a Lambo (skrrt skrrt). Daniel Lee. Generable Video\nAbstract: Exploring simple, automatic within-chain parallelization. For any (well-behaved) statistical model written in the Stan language, the Stan Math library (Math) provides the gradient of the log joint probability distribution function specified. It currently provides the gradient with reverse-mode automatic differentiation. Math also provides forward-mode automatic differentiation, which isn’t as well tested as reverse-mode, but is available none-the less. Reverse-mode automatic differentiation scales well as it can tackle an arbitrary number of parameters with one sweep. However, this can’t be parallelized easily. Forward-mode requires N sweeps to evaluate N directional derivatives, but each of these sweeps can be done in parallel. With the adoption of C++14 capable compilers, we’re now able to use threading as an easy paradigm to coordinate within-chain parallelization. We’ll show some of the performance considerations and some preliminary results.\n\n Prediction and causal inference for time-to-event outcomes truncated by death. Leah Comment.  Video\nAbstract: Predicting customer behaviour is crucial for making decisions such as the cost of acquisition or planning for production or service capacity. In the model being presented individual purchase data of a fashion retailer is utilized to describe and predict their behaviour using Bayeasian multi-layered architecture to allow for heterogeneity and latent variables, such as customer state of activity.\n\n–&gt;\n When seasonality meets Bayesian: Decomposing seasonalities in Stan. Hyunji Moon, SNU, Hyeonseop Lee, PUBG.   Video\nAbstract: Multiple seasonalities play a key role in time series forecasting, especially for business time series where seasonal effects are often dramatic. Previous approaches including Fourier decomposition, exponential smoothing, and Seasonal ARIMA do not reflect distinct characteristics of each period in seasonal patterns such as unique behavior of specific day of the week in business data. We propose a multi-dimensional hierarchical model. Intermediate parameters for each seasonal period are first estimated, then mixture of intermediate parameters are then taken, resulting in the model which successfully reflects interactions between multiple seasonalities. Although this process leads to the reduction of data available for each parameter, a robust estimation can be obtained through a hierarchical Bayesian model. Consideration of not only the characteristics of each seasonal periods but also the interactions between characteristics from multiple seasonalities becomes possible through this model. Our new model is implemented in Stan and considerable improvements in prediction accuracy compared to previous models are achieved. Previous models include Fourier decomposition which Prophet uses to model seasonalities. Comparison has been performed on real-world dataset from a nation-scale logistic network.\n\n Approximate leave-future-out cross-validation for Bayesian time series models. Paul Bürkner, Jonah Gabry, Aki Vehtari.  Video\nAbstract: One of the common goals of time series analysis is to use the observed series to inform predictions for future observations. In the absence of any actual new data to predict, cross-validation can be used to estimate a model’s future predictive accuracy, for instance, for the purpose of model comparison or selection. As exact cross-validation for Bayesian models is often computationally expensive, approximate cross-validation methods have been developed; most notably methods for leave-one-out cross-validation (LOO-CV). If the actual prediction task is to predict the future given the past, LOO-CV provides an overly optimistic estimate as the information from future observations is available to influence predictions of the past. To tackle the prediction task properly and account for the time series structure, we can use leave-future-out cross-validation (LFO-CV). Like exact LOO-CV, exact LFO-CV requires refitting the model many times to different subsets of the data. Using Pareto smoothed importance sampling, we propose a method for approximating exact LFO-CV that drastically reduces the computational costs while also providing informative diagnostics about the quality of the approximation. We provide examples using Bayesian time-series models fitted with Stan.\n\n Handling missing data, censored values and measurement error in machine learning models using multiple imputation for early stage drug discovery. Rowan Swiers. AstraZeneca  Video\nAbstract: Multiple imputation is a technique for handling missing data, censored values and measurement error. Currently it is underused in the machine learning field due to lack of familiarity and experience with the technique, whilst other missing data solutions such as full Bayesian models can be hard to set up. However, randomization-based evaluations of Bayesianly derived repeated imputations can provide approximately valid inference of the posterior distributions and allow use of techniques which rely upon complete data such as SVMs and random Forest models.\nThis paper, using simulated data sets inspired by AstraZeneca drug data, shows how multiple imputation techniques can improve the analysis of data with missing values or with uncertainty. We pay close attention to the prediction of Bayesian posterior coverage due its importance in industrial applications. Comparisons are made to other commonly used methods of handling missing data such as single uniform imputation and data removal. Furthermore, we review several standard multiple imputation models and compare them on our simulated data sets. We provide recommendations on when to use each technique and where extra care is needed based upon data distributions. Finally, using simulated data, we give examples of how correct use of multiple imputation can affect investment decisions in the early stages of drug discovery.\nAnalysis was performed using both Python and Stan and is provided in a Jupyter notebook.\n\n The emergence of HIV resistance to antiretroviral therapy in southern Africa: a mechanistic meta-analysis of survey data. Julien Riou, Matthias Egger, Christian Althaus. Institute of Social and Preventive Medicine, University of Bern, Switzerland Video\nAbstract: Large-scale campaigns providing access to antiretroviral therapy (ART) to people living with HIV in southern Africa have been ongoing since the early 2000s. The success of these campaigns is now threatened by the emergence of HIV drug resistance, most of all resistance to non-nucleoside reverse-transcriptase inhibitors (NNRTI), a class of drugs constitutive of ART. Systematic reviews of cross-sectional surveys have provided insights into the temporal trends of NNRTI resistance among HIV-infected individuals. However, these simple temporal trends fail to account for the local dynamics of HIV transmission and treatment that create the evolutionary pressure generating resistance mutations. Such approaches limit our general understanding of the phenomena of resistance emergence in response to drug introduction and disallow any between-country comparison. Here, we propose a mechanistic approach linking the observed levels of NNRTI resistance to the underlying dynamics of HIV in each country.\nWe developed a SIR-like model consisting of a hierarchical system of ordinary differential equations in Stan. The model considered the infection of susceptible individuals with HIV, the treatment of diagnosed individuals with ART from the early 2000s, the occurrence of resistance mutations in response to the evolutionary pressure created by ART, and the transmission of mutant, resistant viruses to susceptible individuals. The model was fitted jointly to country-level data regarding different aspects of the HIV epidemic (prevalence of HIV, number of people under ART and population size in 8 countries of southern Africa from 2000 to 2016) and to measurements of NNRTI resistance in cross-sectional surveys (60 surveys from 2000 to 2016). Partial pooling was allowed by introducing a hierarchical structure by country on the parameters governing the occurrence of resistance, as well as a hierarchical structure by survey on resistance data.\nThe model could adequately reproduce the dynamics of the HIV epidemics in each country. We found substantial heterogeneity between the rates of emergence of NNRTI resistance across countries that is not explained by differences in the local dynamics of HIV transmission and treatment. Understanding the factors associated with this heterogeneity will allow public health authorities to anticipate on potential issues of drug resistance emergence related to local characteristics.\n\n Modelling enzyme kinetics with Stan.Teddy Groves. DTU BIOSUSTAIN Quantitative Modelling of Cell Metabolism Team Video\nAbstract: The advent of high-throughput technologies has transformed molecular biology into a data-rich discipline. However, integrating this data into a predictive modeling framework is not trivial because many different sources of uncertainty about the molecular processes governing cell metabolism must be taken into account. In particular, reaction fluxes and steady-state reactant concentrations can at best be measured noisily, and even for the best-understood organisms pre-experimental knowledge of kinetic parameters is incomplete and imprecise.\nWe are using Stan to overcome the existing limitations in the study of cell metabolism by combining pre-experimental knowledge about kinetic parameters with experimental measurements of reactant concentrations and reaction fluxes. The presentation and accompanying notebook show a simple but instructive case.\nWe model cell metabolism as a set of differential equations describing enzyme-catalysed reactions. Expert knowledge is taken into account in the form of priors over parameters describing the enzymes’ dynamics. Measured metabolite concentrations and reaction fluxes are treated as depending on the parameters via the differential equations, with random noise representing measurement error.\nWe will discuss how our approach compares to others in the same field, how we plan to develop our project and some of the challenges we have faced so far. The biggest challenge is that a large and complicated system of ODEs must be solved every time the joint log probability density is evaluated. We demonstrate a strategy for speeding up this calculation by exploiting the assumption that the system of reactions is at steady state.\nhttps://www.biosustain.dtu.dk/research/scientific-sections/quantitative-modelling-of-cell-metabolism/staff-quantitative-modelling-of-cell-metabolism\n\n Modeling cocoa bean fermentation processes. Mauricio Moreno-Zambrano, Sergio Grimbs, Matthias S. Ullrich and Marc-Thorsten Hütt.  Department of Life Sciences & Chemistry, Jacobs University Bremen Video\nAbstract:A key step in the production of chocolate is the fermentation of cocoa beans. This importance relies on its role in the development of chocolate’s flavor and aroma. Unlike other food fermentation processes, this specific fermentation is well known because of its lack of control and multiple ways in which it is performed. Here, a quantitative model of cocoa bean fermentation is constructed on previously available data regarding microbiological and metabolites dynamics. The model is formulated as a system of coupled ordinary differential equations (ODEs) with two different types of state variables: (1) Metabolite concentrations of glucose (Glc), fructose (Fru), ethanol (EtOH), lactic acid (LA) and acetic acid (Ac), and (2) population sizes of yeast (Y), lactic acid bacteria (LAB) and acetic acid bacteria (AAB). In total, the model comprehends 25 unknown parameters that were estimated using the Markov chain Monte Carlo No-U-Turn sampler in Rstan. Thereafter, we demonstrate that the model can quantitatively describe existing fermentation series and that the estimated parameters can be used to extract and interpret differences in environmental conditions between two independent fermentation trials [1].\nReferences\n[1] Moreno-Zambrano, M., Grimbs, S., Ullrich M. S. and Hütt, M-T. (2018). A mathematical model of cocoa bean fermantation. Royal Society Open Science, 5(10), 180 964.\n\n Bayesian analyses of time-to-event data using the rstanarm R package. Eren M. Elçi, Sam Brilleman. Public Health and Preventive Medicine, Monash University.  Video\nAbstract: Time-to-event data refers to the observed time from a defined origin (e.g. diagnosis of a disease) until a terminating event of interest (e.g. death). Time-to-event data emerges in a range of industries and scientific disciplines, although it is particularly common in medical and pharmaceutical research. In these research fields, time-to-event data is commonly known as survival data reflecting the fact that death is an event endpoint often used in clinical studies. Analyses of survival data are widely used for decision making in clinical trials, drug development and regulatory approvals.\nIn this talk we introduce a flexible family of Bayesian survival models that are being integrated into the rstanarm R package through the new stan_surv modelling function. The implementation uses a familiar formula syntax for specifying covariates and censoring mechanisms, based on the widely recognised survival R package. The stan_surv modelling function accommodates standard parametric (e.g. exponential, Weibull and Gompertz) survival models under either hazard or accelerated failure time formulations. Additionally, flexible parametric (cubic spline-based) hazard models are available. These allow the time-dependent baseline hazard and time-dependent effects of covariates to both be modelled using flexible smooth functions. We demonstrate the software using an example dataset. We put particular emphasis on functionality that allows practitioners to implement survival analyses as part of a robust Bayesian workflow, including prior and posterior checks and efficient leave-one-out cross-validation.\n\n Prior choice in logit models of discrete choice. Jim Savage. Schmidt Futures Video\nAbstract: In models of discrete choice, sensible-seeming priors on part-worth coefficients can imply priors in the choice probability space that are highly implausible, putting close to 100% prior weight on a single choice dominating all others. This problem reveals itself in problems with initialization and poor fit quality. Yet choosing priors is complicated by the research design, including the dimensionality of choice attributes, and their scale and covariance. In this talk I provide intuition for how priors and choice attributes interact to create extreme prior choice probabilities, and describe a new method to define priors that implies close-to-uniform weight in the choice probability space.\n\n Semiparametric Modeling of the Mean,Variance and Scale Parameters in Skew NormalRegression Models: A Bayesian Perspective. Héctor Zarate. \nAbstract: The goal of this paper is to estimate the location, scale and shape functions in heteroscedastic semiparametric models when the response variable comes from a skew normal distribution. We rely on the connection among smoothing methods that use basis functions with penalization, mixed models and a Bayesian Markov Chain sampling simulation methodology. The novelty of our strategy lies in its potential to contribute to a simple and unified computational methodology that takes into account the factors that affect the parameters in the responses, which in turn is important for an efficient estimation and correct inference without the requirement of fully parametric models. A simulation study investigates the performance of the estimates. Finally, an application using the forecasting predictive densities, highlights the merits of our approach.\n\n Hierarchical models for gamma-ray burst populations. J. Michael Burgess.  MPE \nAbstract: Inferring the number, rate and intrinsic properties of short gamma-ray bursts has been a long studied problem in the field. As it is closely related to the number of GW events expected for neutron star mergers, the topic has begun to be discussed int he literature again. However, the utilized techniques for GRBs still rely on improper statistical modeling V/Vmax estimators and in many cases, methods are simply guessed. I will discuss the use of Bayesian hierarchal models to infer population and object level parameters of inhomogeneous-Poisson process distributed populations. Techniques to handle high-dimensional selections effects will be introduced. The methodology will then be applied to sGRB population data with the aim of understand how many of these objects there are, where they are in the Universe and what are their properties under given modeling assumptions. The methodology is general, thus extensions to other populations can be made easily.\n\n A Decision-Theoretic Journey From Early Clinical Data to Late Stage Efficacy using Hierarchical Joint Models.. Krzysztof Sakrejda, Eric Novik.  Generable  Video\nAbstract: Most statistical problems end with estimating the quantities of interest which may be unobservable parameters or in the prediction context, potentially observable data. As statisticians we sometimes forget that models are often decision-making tools and making decisions conditional on our understanding of the uncertainties in the system is the ultimate goal of the consumers of our models. In this talk, we will introduce a decision problem of advancing therapies to late-stage clinical trials from early-stage clinical data. We do this in the context of a Bayesian Joint Model.\nIn clinical studies, it is common to measure a clinical biomarker repeatedly over time (‘longitudinal data’). It is also common to measure the patient-specific time from a defined origin, e.g. diagnosis of a disease, until a clinical event of interest, such as death or disease progression (‘survival data’). Joint Modeling as it is called in the Survival literature aims to model both the longitudinal biomarker evolutions and survival endpoints simultaneously. Commonly, this is achieved by specifying a joint likelihood formulation for longitudinal and survival outcomes.\nJoint modeling approaches provide several benefits over more traditional modeling and have applications to health through (i) improving the understanding of how biomarkers influence event endpoints; (ii) the development of dynamic risk prediction models for use in personalized medicine; and in the context of clinical trials (iii) requiring fewer patients than the event model alone.\nOnce the inferences from the Joint Model are obtained, we set up a Utility function describing the risk preferences of the trial’s sponsors and take its expectation with respect to the posterior distribution. The resulting function is then maximized.\n\n The State of GPU Computation Support for Stan. Rok Češnovar (University of Ljubljana - UL), Steve Bronder (Capital One), Davor Sluga (UL), Jure Demšar (UL), Tadej Ciglarič (UL), Sean Talts (Columbia University), Erik Štrumbelj (UL).  Video\nAbstract: Our presentations details the current state of and future work on the OpenCL-based framework that allows the Stan automatic differentiation library to utilize GPUs. Our research was initially motivated by large Gaussian Process models where the computation is dominated by the Cholesky decomposition but has since developed into an extensible framework.\nThe following GPU-optimized routines for matrix algebra primitives are already available to Stan users (including reverse mode): matrix multiplication, solving triangular systems, Cholesky decomposition and some special cases. Several support functions are available in the Math library but not exposed to Stan users: matrix initialization, input validity checking, copy, pack/unpack, multiplication by scalar, and transpose. We have made progress on implementing commonly used likelihoods - 4 Generalized Linear Model likelihoods can already be used: normal (identity), Bernoulli (logit), Poisson (log) and Negative Binomial (log). And data caching is now available and substantially reduces the overhead of transferring data to the GPU.\nWe will show how problem size, model and choice of hardware impact the speedups that we can achieve with GPU computation in Stan. Finally, we will discuss directions for future work, routines to implement next, autotuning tunable GPU parameters and advanced data caching.\n\n Extending Stan’s Automatic Differentiation (AD) capabilities using dco/c++. Philip Maybank. Numerical Algorithms Group (NAG)  Video\nAbstract: Tape-based AD Libraries, such as NAG’s dco/c++ tool, keep a record of calculations that are executed by a program in order to evaluate derivatives. They are applicable to a wider range of numerical codes than tape-free AD libraries, which are typically written to compute derivatives for a specific library of functions. The Stan Math Library is a tape-free AD library. The basic idea of the work in this presentation is that dco/c++ can be used to supply derivatives to Stan. This extends the range of functions which can be used by Stan’s MCMC samplers. We illustrate this idea on a toy problem: inferring the parameters of a damped harmonic oscillator driven by white noise using Stan’s NUTS.\n\n Estimating the prevalence of HIV infection in England using Bayesian evidence synthesis. Anne Presanis, Christopher Jackson [presenting author], Daniela De Angelis (MRC Biostatistics Unit, University of Cambridge); Peter Kirwan, Alison Brown, Ada Miltz, Ross Harris, Cuong Chau, Stephanie Migchelsen, Hamish Mohammed, Katy Davison, Sara Croxford, Sarika Desai, Kathy Lowndes, Valerie Delpech, Noel Gill (Public Health England).  Video\nAbstract: We present a substantive application of Stan that has informed national health policy.\nAnnual estimation of the number of people living with HIV in England, including those who are unaware of their infection, has, for several years, been based on a Bayesian model that combines evidence from multiple sources of data. For several demographic and risk groups, the model estimates the number of people in each group, the prevalence of HIV, and the proportion of HIV infections that are diagnosed.\nIn the 2018 version of this model, implemented in Stan, the strata are defined by age, gender, sexual behaviour, injecting drug use, ethnicity and region. Changes between years are also modelled. Routinely-collected data sources include a register of diagnosed HIV infections, a register of attendances at genitourinary medicine (GUM) clinics, and the national census. These are combined with data from several surveys of health and sexual behaviour among different groups, HIV testing data from unlinked anonymous surveys of drug users, and data from HIV testing of donated blood.\nThis is an example of a ““multiparameter evidence synthesis”“, where the quantities of interest cannot be estimated directly, but can be inferred indirectly through a network of model assumptions. Potential biases due to selection, under-reporting and missing data are represented explicitly through structural assumptions and informative priors. A four-level hierarchical model is used to borrow strength between stratum-specific parameters. Stan’s model description language makes the assumptions explicit, and its inference engine provides posterior estimates efficiently.\nThe estimates from 2018 demonstrate that the UN-AIDS target of 90% of infections diagnosed by 2020 has been met in England, and the estimates continue to inform policies around HIV testing, treatment and prevention.\n\n Estimating the effect of age and league on scoring rate in professional soccer. Benjamin Torvaney. Wefarm\nAbstract: Understanding the effect of different factors on player output is critical to accurately evaluating player performance. In particular, it is useful to be able to project performance into the future, whether to assess a potential new signing, or to aid in squad management. To do this, we must account for footballing context. Intuitively, we know that scoring goals in the Norwegian Eliteserien is less impressive than scoring in the Premier League; however, this is rarely quantified.\nIf we propose a model in which a player’s expected goalscoring rate is the product of their ability, the difficulty of the competition, and a relative age effect, we can estimate the effect of each parameter from historical goalscoring tallies (accompanied by minutes played). We can extend the model to allow competition factors to vary over time, to reflect the changing dynamics of professional soccer.\nSuch a model yields promising results: high profile soccer stars have the highest model estimates; a clear age curve for goalscoring is produced; competition strengths vary over time in accordance with popular perception.\n\n Multi-channel Gaussian Processes as flexible alternatives to linear models: perspectives and challenges to scaling up Bayesian inference to genomic-scale data. Caetano Souto-Maior, Susan T. Harbison. Laboratory of Systems Genetics, National Heart Lung and Blood Institute, NIH.\nAbstract:\n\n One weird trick: Non-parametric Bayesian updating by kernels. Robert Grant.  BayesCamp\nAbstract: One of the big attractions for people adopting Bayesian methods is the promise of ““updating”” their parameter estimates and predictions as more data arrive. Yesterday’s posterior becomes today’s prior. In practice, this is not always simple, requiring at the very least a complete set of sufficient statistics, random samples from an unchanging population, and no changes of mind about the probability distribution for the priors. Sometimes, one would like to update without imposing an a priori distribution on yesterday’s posterior and without estimating lots of statistics. I discuss a kernel approach, which is easily incorporated in Stan by an additional target+= statement, looping over yesterday’s posterior draws, and uniform proposal densities. I compare this with parametric updates, and explore the potential to reduce computation by using kernels weighted by counts of posterior draws inside hypercubes of parameter space.\n\n Making Stan Faster using Sequential Monte Carlo samplers. Simon Maskell (University of Liverpool), Alessandro Varsi (University of Liverpool), Peter Green (University of Liverpool), Paul Horridge (University of Liverpool), Alejandro Diaz (University of Liverpool), Lee Devlin (University of Liverpool), Rob Moore (University of Liverpool), Katerina Chatzopoulou (University of Liverpool), Jinglai Li (University of Liverpool), Maria Sudell (University of Liverpool), Luke Mason (STFC), Robin Pinning (STFC), Jack Taylor (STFC), Vassil Alexandrov (STFC), Ed Pyzer-Knapp (IBM). \nAbstract: Stan uses the No U-Turn Sampler (NUTS), a specific instance of Markov Chain Monte Carlo (MCMC). MCMC can be slow, e.g., when dimensionality is high and it would be better if NUTS was faster. We have recently been working to improve the run-time of a solution to problems that Stan can tackle (and those that it cannot, e.g. those that would require reversible jump MCMC). Our approach has been to replace NUTS with a variant of a Sequential Monte Carlo (SMC) sampler that uses the clever ideas embodied in NUTS without coupling them to MCMC specifically. SMC samplers manipulate a population of samples, making it possible to distribute computation across each of many processors. Our work has shown that SMC samplers can be configured to exploit this parallelism (and the advances that have led to the development of, for example, the use of NUTS as a proposal distribution). This can achieve faster run-time than MCMC in terms of the number of effective samples per second (by running the SMC sampler on clusters of hundreds of cores, as are routinely used in the context of Deep Learning, for example). Furthermore, we have shown that SMC samplers can be configured to outperform MCMC by making better use of the available processing resources. This is possible because MCMC’s convergence proofs require that the single sampling chain never goes wrong while the proofs for SMC samplers only require that the samples don’t all malfunction simultaneously. Put another way, SMC samplers have an additional degree of freedom in their design and this degree of freedom can be exploited to offer improved performance relative to MCMC. This talk will explain how SMC samplers can outperform MCMC per second and per flop. We will also describe our progress to date on integrating SMC samplers into Stan: our intent is to make it possible to use all Stan files. Thus far we’re able to achieve a runtime that is over an order of magnitude faster than MCMC.\n\n Gaussian process modeling and covariate selection for longitudinal data. Juho Timonen, Aki Vehtari, Harri Lähdesmäki. Alto University\nAbstract: Longitudinal data arises when the same observational units are measured repeatedly, and is common in clinical studies. Such data is often modeled using generalized linear mixed effect models with off-the-shelf software packages. These are, however, restricted to a parametric form and cannot model non-stationary disease effects. We demonstrate our new R-package for interpretable Bayesian non-parametric modeling of longitudinal data using additive Gaussian processes. Like the R-packages and brms, our goal is to provide an interface to Stan with a simple and intuitive syntax. However, our Stan program is specifically designed for Gaussian process modeling of longitudinal data, allowing the user to specify a model that mixes group and individual-specific age effects or effects of other continuous or categorical covariates. We show how our package uses Stan to model non-stationary disease effects and uncertainty of the observed disease onsets, identify heterogeneous effects present in only a subset of study subjects, and handles general non-Gaussian likelihoods. Furthermore, we define a way of resolving the relevance of any continuous or categorical covariate by sampling only one full model with all covariates included. Our focus is on biomedical applications, where is often vital to determine which covariates affect the response variable, in order to reduce future measurement costs or have a better interpretation about the progression of a disease.\n\n Computing prediction and tolerance intervals for a mixture of normal distributions. Jean-francois Michiels, Timothy Mutsvari, Oussama Errazi. Pharmalex\nAbstract: For the submission of a Biosimilar product, Biosimilarity assessment is the first step to achieve in the “Totality of Evidence” strategy as required by Authorities (e.g. FDA). The main objective of biosimilarity is to give evidence that the test biological product is as similar as possible to the reference product. The definition of ‘similar’ remains a critical component that needs to be addressed and justified. For biologicals, it is the process and its capability that should be evaluated, i.e. the risk of producing batches outside defendable limits. Thus, the first step is to set the acceptance limits. β-expectation and (β,γ), also known as Beta-Gamma, tolerance intervals are useful metrics to demonstrate that a test product (i.e. the biosimilar) is similar to a reference product. Biosimilarity is concluded if the β-expectation of the biosimilar product is within the (β,γ) of the reference. β-expectation interval is constructed to contain a β proportion of the population on average. A (β,γ) tolerance interval on the other hand is built to contain at least a β proportion of the population with a confidence level γ. In general, the pharmaceutical company producing the biosimilar has no access to the data of the reference product. Buying boxes of the reference product from several drugstores and analysing them is nevertheless one possible strategy to acquire knowledge on the process variability. Due to that sampling strategy, the distribution of the reference product can be quite exotic and it is likely that the distribution of the reference product is a mixture of normal distributions. Fitting a mixture of 2 normal distributions on data is performed using Stan. The output are the posterior distributions of the mean and standard deviation of the 2 normal distributions and the posterior distribution of the relative proportion of the 2 distributions. We present different algorithms to derive β-expectation and (β,γ) tolerance intervals for a mixture of 2 normal distributions. Using simulations, the operating characteristics of the intervals are shown (e.g. the capability to conclude similarity when it is actually similar).\n\n Parallel numerical ODE solution in Torsten for population models. Yi Zhang, William R. Gillespie. Metrum LLC\nAbstract: Torsten is a collection of functions to facilitate analysis of pharmacometric data using Stan. To seek an alternative to the ““map_rect”” function for within-chain parallel computation in Stan, we have implemented numerical ODE solution functions for population models with functional signatures that specify schedules of events such as doses and observations in a manner consistent with NONMEM compatible.\nThe population solution function feature is designed toward multi-level parallelization using Message Passing Interface(MPI). For that we first implemented Torsten’s own ODE integrators based on CVODES library. Table 1 shows MPI performance results of such an integrator on a group of 1000 Lorenz systems.\n\n\n\nn_processor\n\n\nWalltime(ms)\n\n\nSpeedup\n\n\nefficiency\n\n\n\n\n1\n\n\n10986\n\n\n1.00\n\n\n1.00\n\n\n\n\n2\n\n\n5505\n\n\n2.00\n\n\n1.00\n\n\n\n\n4\n\n\n3091\n\n\n3.55\n\n\n0.89\n\n\n\n\n8\n\n\n1459\n\n\n7.53\n\n\n0.94\n\n\n\n\n16\n\n\n1355\n\n\n8.11\n\n\n0.51\n\n\n\n\n32\n\n\n739\n\n\n14.87\n\n\n0.46\n\n\n\n\n64\n\n\n424\n\n\n25.91\n\n\n0.40\n\n\n\n\n128\n\n\n382\n\n\n28.76\n\n\n0.22\n\n\n\n\n256\n\n\n284\n\n\n38.68\n\n\n0.15\n\n\n\n\n512\n\n\n293\n\n\n37.49\n\n\n0.07\n\n\n\nTable 1: MPI performance of the Lorenz model solved by Torsten’s BDF integrator. (n_population = 1000)\nThen we developed MPI-based population solvers that are specifically designed for PKPD applications, for which ODE system size \\(n\\) is typically in the scale of \\(10^0\\sim 10^2\\). We employ the latest standard(MPI-3) functionalities for latency hiding, and test the implementation on two MPI implementations (OpenMPI and MPICH). Tables 2-5 show performance results of one such function on a simple two-compartment PK model(\\(n=3\\)) and a more complex PKPD model(\\(n=8\\)), run on a METWORX workflow.\n\n\n\nn_processor\n\n\nWalltime(ms)\n\n\nSpeedup\n\n\nefficiency\n\n\n\n\n1\n\n\n2966\n\n\n1.00\n\n\n1.00\n\n\n\n\n2\n\n\n1544\n\n\n1.92\n\n\n0.96\n\n\n\n\n4\n\n\n866\n\n\n3.42\n\n\n0.85\n\n\n\n\n8\n\n\n887\n\n\n3.34\n\n\n0.42\n\n\n\nTable 2: Parallel performance of solving a two-compartment population model using pmx_solve_group_bdf and OpenMPI.\n\n\n\nn_processor\n\n\nWalltime(ms)\n\n\nSpeedup\n\n\nefficiency\n\n\n\n\n1\n\n\n45791\n\n\n1.00\n\n\n1.00\n\n\n\n\n2\n\n\n23532\n\n\n1.95\n\n\n0.97\n\n\n\n\n4\n\n\n13421\n\n\n3.41\n\n\n0.85\n\n\n\n\n8\n\n\n10394\n\n\n4.41\n\n\n0.55\n\n\n\nTable 3: Parallel performance of solving a Neutropenia population model using pmx_solve_group_bdf and OpenMPI.\n\n\n\nn_processor\n\n\nWalltime(ms)\n\n\nSpeedup\n\n\nefficiency\n\n\n\n\n1\n\n\n2470\n\n\n1.00\n\n\n1.00\n\n\n\n\n2\n\n\n1419\n\n\n1.74\n\n\n0.87\n\n\n\n\n4\n\n\n1170\n\n\n2.11\n\n\n0.53\n\n\n\n\n8\n\n\n860\n\n\n2.87\n\n\n0.36\n\n\n\nTable 4: Parallel performance of solving a two-compartment population model using pmx_solve_group_bdf and MPICH.\n\n\n\nn_processor\n\n\nWalltime(ms)\n\n\nSpeedup\n\n\nefficiency\n\n\n\n\n1\n\n\n45087\n\n\n1.00\n\n\n1.00\n\n\n\n\n2\n\n\n22976\n\n\n1.96\n\n\n0.98\n\n\n\n\n4\n\n\n14158\n\n\n3.18\n\n\n0.80\n\n\n\n\n8\n\n\n10523\n\n\n4.28\n\n\n0.54\n\n\n\nTable 5: Parallel performance of solving a Neutropenia population model using pmx_solve_group_bdf and MPICH.\nIn addtional to population-level parallelization, we are also implementing individual-level parallelization based on parallel time integration with multigrid. This will enables us to reduce the solution time of a single ODE system, and create a multi-level parallelization for ODE-based population models. The results of a preliminary implementation are shown in Table 6.\n\n\n\nn_processor\n\n\nWalltime(ms)\n\n\nSpeedup\n\n\nefficiency\n\n\n\n\n1\n\n\n2.8\n\n\n1.00\n\n\n1.00\n\n\n\n\n2\n\n\n1.7\n\n\n1.65\n\n\n0.82\n\n\n\n\n4\n\n\n1.2\n\n\n2.33\n\n\n0.58\n\n\n\nTable 6: Parallel performance of solving 10^4 steps of a single Neutropenia ODE system using parallel-in-time technique."
  },
  {
    "objectID": "learn-stan/stancon/StanCon2019-program.html",
    "href": "learn-stan/stancon/StanCon2019-program.html",
    "title": "StanCon 2019 Schedule",
    "section": "",
    "text": "8:00am-9:00am Registration\n9:00am-11:30am Tutorials with Break\n\nTrack 1: Basics of Bayesian inference and Stan.\nTrack 2: Stan for Programmers.\nTrack 3: Hierarchical Modeling with Stan.\n\n11:30am-12:30pm Open Developers Meeting (loo, projpred, bayesplot, discourse)\n12:30pm-2:00pm Provided Lunch\n2:00pm-4:30pm Tutorials with Break\n\nTrack 1: Basics of Bayesian inference and Stan.\nTrack 2: A Dive into Stan’s C++ Model Concept.\nTrack 3: Population and ODE-based models using Stan and Torsten.\n\n4:30pm-5:30pm Open Developers Meeting (posteriordb = reference model and posterior database, bayesbenchr = framework for benchmarking inference algorithms)\n\n\n\n\n\n8:00am-9:00am Registration\n9:00am-11:30am Tutorials with Break\n\nTrack 1: Basics of Bayesian inference and Stan.\nTrack 2: Stan for Programmers.\nTrack 3: Hierarchical Modeling with Stan.\n\n11:30am-12:30pm Open Developers Meeting, (bayesflow for Bayesian workflow, parallelization, optimization, KINSOL solver)\n12:30pm-2:00pm Provided Lunch\n2:00pm-4:30pm Tutorials with Break\n\nTrack 1: Basics of Bayesian inference and Stan.\nTrack 2: Model assessment and selection.\nTrack 3: Population and ODE-based models using Stan and Torsten.\n\n4:30pm-5:30pm Open Developers Meeting, (sparse matrices, Laplace for GLVMs)\n\n\n\n\n\n8:00am-9:00am Registration\n9:00am-10:00am Submitted Talks\n\nPrior choice in logit models of discrete choice. Jim Savage.  Abstract  Video\nApproximate leave-future-out cross-validation for Bayesian time series models. Paul Bürkner, Jonah Gabry, Aki Vehtari.  Abstract  Video\nThe Currency of Place and the Short-Term Rental Market. Mikael Brunila.  Abstract  Video\n\n10:00am-10:40am Break\n10:40am-11:40am Submitted Talks\n\nModelling enzyme kinetics with Stan. Teddy Groves. DTU BIOSUSTAIN Quantitative Modelling of Cell Metabolism Team  Abstract  Video\nThe emergence of HIV resistance to antiretroviral therapy in southern Africa: a mechanistic meta-analysis of survey data. Julien Riou, Matthias Egger, Christian Althaus. Institute of Social and Preventive Medicine, University of Bern, Switzerland  Abstract  Video\nHandling missing data, censored values and measurement error in machine learning models using multiple imputation for early stage drug discovery. Rowan Swiers. AstraZeneca  Abstract  Video\n\n11:40am-12:00pm Sponsor Talks and Birds of Feather\n12:00pm-1:00pm Provided Lunch\n1:00pm-2:00pm Stan Community Meeting\n2:00pm-3:00pm Submitted Talks\n\nFast Forward Like a Lambo (skrrt skrrt). Daniel Lee. Generable  Abstract  Video\nProfit-Maximizing A/B Tests. Elea McDonnell Feit, Ron Berman. Drexel University, The Wharton School  Abstract  Video\nWhen seasonality meets Bayesian: Decomposing seasonalities in Stan. Hyunji Moon, SNU, Hyeonseop Lee, PUBG.  Abstract  Video\n\n3:00pm-3:40pm Break\n3:40pm-4:20pm Submitted Talks\n\nChronikis: a Bayesian time-series modeling language. Kevin S. Van Horn. Adobe Inc.  Abstract, Docker link  Video\nEstimating the prevalence of HIV infection in England using Bayesian evidence synthesis. Anne Presanis, Christopher Jackson (presenting author), Daniela De Angelis (MRC Biostatistics Unit, University of Cambridge); Peter Kirwan, Alison Brown, Ada Miltz, Ross Harris, Cuong Chau, Stephanie Migchelsen, Hamish Mohammed, Katy Davison, Sara Croxford, Sarika Desai, Kathy Lowndes, Valerie Delpech, Noel Gill (Public Health England).  Abstract  Video\n\n4:20pm-5:10pm David Spiegelhalter Communicating Uncertainty about Facts, Numbers and Science  Video\n5:10pm-6:30pm Networking at the Pub and pickup football (soccer) match\n6:30pm Dinner at King’s College\n\n\n\n\n\n8:00am-9:00am Registration\n9:00am-10:00am Submitted Talks\n\nExtending Stan’s Automatic Differentiation (AD) capabilities using dco/c++. Philip Maybank. Numerical Algorithms Group (NAG)  Abstract  Video\nThe State of GPU Computation Support for Stan. Rok Češnovar (University of Ljubljana - UL), Steve Bronder (Capital One), Davor Sluga (UL), Jure Demšar (UL), Tadej Ciglarič (UL), Sean Talts (Columbia University), Erik Štrumbelj (UL).  Abstract  Video\nModeling cocoa bean fermentation processes. Mauricio Moreno-Zambrano, Sergio Grimbs, Matthias S. Ullrich, and Marc-Thorsten Hütt. Department of Life Sciences & Chemistry, Jacobs University Bremen  Abstract  Video\n\n10:00am-10:40am Break\n10:40am-12:00pm Submitted Talks\n\nBayesian analyses of time-to-event data using the rstanarm R package. Eren M. Elçi, Sam Brilleman. Public Health and Preventive Medicine, Monash University  Abstract  Video\nA Decision-Theoretic Journey From Early Clinical Data to Late Stage Efficacy using Hierarchical Joint Models. Krzysztof Sakrejda, Eric Novik. Generable  Abstract  Video\nStacking for multimodal posterior distributions. Yuling Yao, Aki Vehtari, and Andrew Gelman.  Abstract  Video\nBayesian leave-one-out cross-validation for large data. Måns Magnusson (Aalto), Michael Riis Andersen (Danish Technical University), Johan Jonasson (Chalmers Technical University), Aki Vehtari (Aalto).  Abstract  Video\n\n12:00pm-1:00pm Provided Lunch\n1:00pm-2:00pm Open Developers Meeting, (stanc optimization)\n2:00pm-3:00pm Submitted Talks\n\nSimulation of Statistic Mechanical Systems using Stan. Forrest Eli Hurley. North Carolina State University  Abstract  Video\nStructured priors for survey estimates in the presence of non-representative data. Yuxiang Gao (University of Toronto), Lauren Kennedy (Columbia University), Daniel Simpson (University of Toronto).  Abstract  Video\nPrediction and causal inference for time-to-event outcomes truncated by death. Leah Comment.  Abstract  Video\n\n3:00pm-3:40pm Break\n3:40pm-4:00pm Submitted Talk\n\nGetting the Lead out–Does New York City’s childhood lead testing make statistical sense? Jonathan Auerbach, Breck Baldwin. Columbia University  Abstract  Video\n\n4:00pm-4:50pm Lauren Kennedy Out of Sample Prediction and the Quest for Generalization  Video"
  },
  {
    "objectID": "learn-stan/stancon/StanCon2019-program.html#tuesday-august-20-tutorials",
    "href": "learn-stan/stancon/StanCon2019-program.html#tuesday-august-20-tutorials",
    "title": "StanCon 2019 Schedule",
    "section": "",
    "text": "8:00am-9:00am Registration\n9:00am-11:30am Tutorials with Break\n\nTrack 1: Basics of Bayesian inference and Stan.\nTrack 2: Stan for Programmers.\nTrack 3: Hierarchical Modeling with Stan.\n\n11:30am-12:30pm Open Developers Meeting (loo, projpred, bayesplot, discourse)\n12:30pm-2:00pm Provided Lunch\n2:00pm-4:30pm Tutorials with Break\n\nTrack 1: Basics of Bayesian inference and Stan.\nTrack 2: A Dive into Stan’s C++ Model Concept.\nTrack 3: Population and ODE-based models using Stan and Torsten.\n\n4:30pm-5:30pm Open Developers Meeting (posteriordb = reference model and posterior database, bayesbenchr = framework for benchmarking inference algorithms)"
  },
  {
    "objectID": "learn-stan/stancon/StanCon2019-program.html#wednesday-august-21-tutorials",
    "href": "learn-stan/stancon/StanCon2019-program.html#wednesday-august-21-tutorials",
    "title": "StanCon 2019 Schedule",
    "section": "",
    "text": "8:00am-9:00am Registration\n9:00am-11:30am Tutorials with Break\n\nTrack 1: Basics of Bayesian inference and Stan.\nTrack 2: Stan for Programmers.\nTrack 3: Hierarchical Modeling with Stan.\n\n11:30am-12:30pm Open Developers Meeting, (bayesflow for Bayesian workflow, parallelization, optimization, KINSOL solver)\n12:30pm-2:00pm Provided Lunch\n2:00pm-4:30pm Tutorials with Break\n\nTrack 1: Basics of Bayesian inference and Stan.\nTrack 2: Model assessment and selection.\nTrack 3: Population and ODE-based models using Stan and Torsten.\n\n4:30pm-5:30pm Open Developers Meeting, (sparse matrices, Laplace for GLVMs)"
  },
  {
    "objectID": "learn-stan/stancon/StanCon2019-program.html#thursday-august-22-conference",
    "href": "learn-stan/stancon/StanCon2019-program.html#thursday-august-22-conference",
    "title": "StanCon 2019 Schedule",
    "section": "",
    "text": "8:00am-9:00am Registration\n9:00am-10:00am Submitted Talks\n\nPrior choice in logit models of discrete choice. Jim Savage.  Abstract  Video\nApproximate leave-future-out cross-validation for Bayesian time series models. Paul Bürkner, Jonah Gabry, Aki Vehtari.  Abstract  Video\nThe Currency of Place and the Short-Term Rental Market. Mikael Brunila.  Abstract  Video\n\n10:00am-10:40am Break\n10:40am-11:40am Submitted Talks\n\nModelling enzyme kinetics with Stan. Teddy Groves. DTU BIOSUSTAIN Quantitative Modelling of Cell Metabolism Team  Abstract  Video\nThe emergence of HIV resistance to antiretroviral therapy in southern Africa: a mechanistic meta-analysis of survey data. Julien Riou, Matthias Egger, Christian Althaus. Institute of Social and Preventive Medicine, University of Bern, Switzerland  Abstract  Video\nHandling missing data, censored values and measurement error in machine learning models using multiple imputation for early stage drug discovery. Rowan Swiers. AstraZeneca  Abstract  Video\n\n11:40am-12:00pm Sponsor Talks and Birds of Feather\n12:00pm-1:00pm Provided Lunch\n1:00pm-2:00pm Stan Community Meeting\n2:00pm-3:00pm Submitted Talks\n\nFast Forward Like a Lambo (skrrt skrrt). Daniel Lee. Generable  Abstract  Video\nProfit-Maximizing A/B Tests. Elea McDonnell Feit, Ron Berman. Drexel University, The Wharton School  Abstract  Video\nWhen seasonality meets Bayesian: Decomposing seasonalities in Stan. Hyunji Moon, SNU, Hyeonseop Lee, PUBG.  Abstract  Video\n\n3:00pm-3:40pm Break\n3:40pm-4:20pm Submitted Talks\n\nChronikis: a Bayesian time-series modeling language. Kevin S. Van Horn. Adobe Inc.  Abstract, Docker link  Video\nEstimating the prevalence of HIV infection in England using Bayesian evidence synthesis. Anne Presanis, Christopher Jackson (presenting author), Daniela De Angelis (MRC Biostatistics Unit, University of Cambridge); Peter Kirwan, Alison Brown, Ada Miltz, Ross Harris, Cuong Chau, Stephanie Migchelsen, Hamish Mohammed, Katy Davison, Sara Croxford, Sarika Desai, Kathy Lowndes, Valerie Delpech, Noel Gill (Public Health England).  Abstract  Video\n\n4:20pm-5:10pm David Spiegelhalter Communicating Uncertainty about Facts, Numbers and Science  Video\n5:10pm-6:30pm Networking at the Pub and pickup football (soccer) match\n6:30pm Dinner at King’s College"
  },
  {
    "objectID": "learn-stan/stancon/StanCon2019-program.html#friday-august-23",
    "href": "learn-stan/stancon/StanCon2019-program.html#friday-august-23",
    "title": "StanCon 2019 Schedule",
    "section": "",
    "text": "8:00am-9:00am Registration\n9:00am-10:00am Submitted Talks\n\nExtending Stan’s Automatic Differentiation (AD) capabilities using dco/c++. Philip Maybank. Numerical Algorithms Group (NAG)  Abstract  Video\nThe State of GPU Computation Support for Stan. Rok Češnovar (University of Ljubljana - UL), Steve Bronder (Capital One), Davor Sluga (UL), Jure Demšar (UL), Tadej Ciglarič (UL), Sean Talts (Columbia University), Erik Štrumbelj (UL).  Abstract  Video\nModeling cocoa bean fermentation processes. Mauricio Moreno-Zambrano, Sergio Grimbs, Matthias S. Ullrich, and Marc-Thorsten Hütt. Department of Life Sciences & Chemistry, Jacobs University Bremen  Abstract  Video\n\n10:00am-10:40am Break\n10:40am-12:00pm Submitted Talks\n\nBayesian analyses of time-to-event data using the rstanarm R package. Eren M. Elçi, Sam Brilleman. Public Health and Preventive Medicine, Monash University  Abstract  Video\nA Decision-Theoretic Journey From Early Clinical Data to Late Stage Efficacy using Hierarchical Joint Models. Krzysztof Sakrejda, Eric Novik. Generable  Abstract  Video\nStacking for multimodal posterior distributions. Yuling Yao, Aki Vehtari, and Andrew Gelman.  Abstract  Video\nBayesian leave-one-out cross-validation for large data. Måns Magnusson (Aalto), Michael Riis Andersen (Danish Technical University), Johan Jonasson (Chalmers Technical University), Aki Vehtari (Aalto).  Abstract  Video\n\n12:00pm-1:00pm Provided Lunch\n1:00pm-2:00pm Open Developers Meeting, (stanc optimization)\n2:00pm-3:00pm Submitted Talks\n\nSimulation of Statistic Mechanical Systems using Stan. Forrest Eli Hurley. North Carolina State University  Abstract  Video\nStructured priors for survey estimates in the presence of non-representative data. Yuxiang Gao (University of Toronto), Lauren Kennedy (Columbia University), Daniel Simpson (University of Toronto).  Abstract  Video\nPrediction and causal inference for time-to-event outcomes truncated by death. Leah Comment.  Abstract  Video\n\n3:00pm-3:40pm Break\n3:40pm-4:00pm Submitted Talk\n\nGetting the Lead out–Does New York City’s childhood lead testing make statistical sense? Jonathan Auerbach, Breck Baldwin. Columbia University  Abstract  Video\n\n4:00pm-4:50pm Lauren Kennedy Out of Sample Prediction and the Quest for Generalization  Video"
  },
  {
    "objectID": "learn-stan/stancon-talks.html",
    "href": "learn-stan/stancon-talks.html",
    "title": "StanCon Talks",
    "section": "",
    "text": "Location & Date: Oxford University, England – September 9-13, 2024\nProgram\nRecorded Talks: YouTube playlist\nTutorials (not recorded)\n\nIntroduction to Stan – Richard McElreath\nModel selection – Aki Vehtari, Noa Kallioinen, and Teemu Säilynoja\nBayesian hierarchical models in Stan – Sean Pinkney\nBayesian optmization with Stan – Anna Riha and Elizaveta Semenova\nBiodiversity modeling and forecasting – Will Pearse\nInfectious disease modeling in Stan – Juliette Unwin\n\nOrganizers: Charles Margossian, Will Pearse,"
  },
  {
    "objectID": "learn-stan/stancon-talks.html#stancon-2024-oxford",
    "href": "learn-stan/stancon-talks.html#stancon-2024-oxford",
    "title": "StanCon Talks",
    "section": "",
    "text": "Location & Date: Oxford University, England – September 9-13, 2024\nProgram\nRecorded Talks: YouTube playlist\nTutorials (not recorded)\n\nIntroduction to Stan – Richard McElreath\nModel selection – Aki Vehtari, Noa Kallioinen, and Teemu Säilynoja\nBayesian hierarchical models in Stan – Sean Pinkney\nBayesian optmization with Stan – Anna Riha and Elizaveta Semenova\nBiodiversity modeling and forecasting – Will Pearse\nInfectious disease modeling in Stan – Juliette Unwin\n\nOrganizers: Charles Margossian, Will Pearse,"
  },
  {
    "objectID": "learn-stan/stancon-talks.html#stancon-2023-st.-louis",
    "href": "learn-stan/stancon-talks.html#stancon-2023-st.-louis",
    "title": "StanCon Talks",
    "section": "StanCon 2023 St. Louis",
    "text": "StanCon 2023 St. Louis\n\nLocation & Date: Washington University, USA – June 20-23, 2023\nProgram\nGitHub repository of slides and course materials from StanCon 2023: https://github.com/stan-dev/stancon2023\nTutorials\n\nFundamentals of Stan – Charles Margossian\nBayesian workflow illustrated using BRMS – Mitzi Morris\nHierarchical models in Stan: varieties, optimizations & nuances – Mike Lawrence\nBuilding a GPT in Stan – Daniel Lee\nCognitive diagnostic models in R and Stan – Jake Thompson\nAdvances of model assessment, selection, and inference after model selection – Andrew Johnson\n\nOrganizers: Charles Margossian, Debashis Mondal, Yi Zhang, Eric Ward"
  },
  {
    "objectID": "learn-stan/stancon-talks.html#stancon-2020-global",
    "href": "learn-stan/stancon-talks.html#stancon-2020-global",
    "title": "StanCon Talks",
    "section": "StanCon 2020 Global",
    "text": "StanCon 2020 Global\n\nLocation & Date: Online, 24 hour event, August 13, 2020\nProgram\nRecorded StanCon 2020 Videos on YouTube\n\nSession 1\nSession 2\nSession 3\nAll videos\n\nOrganizers: Susana Marquez, Daniel Lee, Kelli Cassidy, Simon Maskell"
  },
  {
    "objectID": "learn-stan/stancon-talks.html#stancon-2019-cambridge",
    "href": "learn-stan/stancon-talks.html#stancon-2019-cambridge",
    "title": "StanCon Talks",
    "section": "StanCon 2019 Cambridge",
    "text": "StanCon 2019 Cambridge\n\nLocation & Date: University of Cambridge – August 20-23, 2019\nProgram\nRecorded Talks: YouTube playlist\nTutorials (not recorded)\n\nPopulation and ODE-based models using Stan and Torsten – Charles Margossian & Yi Zhang\nHierarchical Modeling with Stan – Ben Goodrich\nModel assessment and selection – Aki Vehtari\nA Dive into Stan’s C++ Model Concept – Daniel Lee\nIntroduction to Stan for Programmers – Jonathan Auerbach & Breck Baldwin\nBasics of Bayesian inference and Stan – Jonah Gabry & Lauren Kennedy\n\nOrganizers: University of Cambridge"
  },
  {
    "objectID": "learn-stan/stancon-talks.html#stancon-2018-helsinki",
    "href": "learn-stan/stancon-talks.html#stancon-2018-helsinki",
    "title": "StanCon Talks",
    "section": "StanCon 2018 Helsinki",
    "text": "StanCon 2018 Helsinki\n\nGitHub Repo for StanCon 2018 Helsinki\nRecorded Talks: YouTube playlist\nTutorials:\n\nBasics of Bayesian inference and Stan – Jonah Gabry & Lauren Kennedy\nHierarchical models – Ben Goodrich\nStan C++ development: adding a new function to Stan – Bob Carpenter, Sean Talts & Mitzi Morris\nOrdinary differential equation (ODE) models in Stan – Daniel Lee\nProductization of Stan – Eric Novik\nModel assessment and selection – Aki Vehtari\n\nLocation & Date: Aalto University, Helsinki, Finland – August 29-31, 2018\nOrganizers: Aalto University"
  },
  {
    "objectID": "learn-stan/stancon-talks.html#stancon-2018-asilomar",
    "href": "learn-stan/stancon-talks.html#stancon-2018-asilomar",
    "title": "StanCon Talks",
    "section": "StanCon 2018 Asilomar",
    "text": "StanCon 2018 Asilomar\n\nGitHub Repo for StanCon 2018 Asilomar\nRecorded Talks: YouTube playlist\nTutorials (not recorded)\n\nIntroduction to Stan – Jonah Sol Gabry, Mitzi Morris & Sean Talts\nExecutive decision making the Bayesian way – Jonathan Auerback & Eric Novik\nAdvanced Hierarchical Models in Stan – Ben Goodrich\nModel assessment, selection and inference after model selection – Aki Vehtari\nHow to develop for Stan at the C++ level – Charles Margossian\nA Dive into Stan’s C++ Model Concept – Daniel Lee\n\nLocation & Date: Asilomar Conference Center, Pacific Grove, California, USA – Jan 10-12, 2018\nOrganizers: Columbia University"
  },
  {
    "objectID": "learn-stan/stancon-talks.html#stancon-2017-new-york-city",
    "href": "learn-stan/stancon-talks.html#stancon-2017-new-york-city",
    "title": "StanCon Talks",
    "section": "StanCon 2017 New York City",
    "text": "StanCon 2017 New York City\n\nProgram\nRecorded Talks: YouTube playlist\nGithub Repo with Contributed Talks\nLocation & Date: Columbia University, New York, USA - Jan 17, 2017\nOrganizers: Columbia University"
  },
  {
    "objectID": "learn-stan/field-guides.html",
    "href": "learn-stan/field-guides.html",
    "title": "Domain-Specific Resources",
    "section": "",
    "text": "These guides provide applied researchers with curated lists of tutorials, case studies, and resources which contain Stan implementations of the most commonly used models in their domain. If you would like to contribute one for your field, see this Discourse post: Fostering Stan user communities through domain-specific resource pages\n\n\n\nTopics: Item Response Theory, Cognitive Diagnosis Models, Multilevel Modeling\nMaintainer: Sofia Rabe-Hesketh\n\n\n\n\n\nTopics: Ecological times series models, population models, predator-prey dynamics, species site-occupancy models.\nMaintainer: Vianey Leos Barajas\n\n\n\n\n\nTopics: Disease transmission (SIR models), disease mapping (ICAR, BYM models), survival analysis, longitudinal data.\nMaintainer: Léo Grinsztajn\n\n\n\n\n\nCognitive Science and Neuroscience papers which use Stan, BRMS, or RStanArm.\nMaintainer: Bruno Nicenboim"
  },
  {
    "objectID": "learn-stan/field-guides.html#field-guides",
    "href": "learn-stan/field-guides.html#field-guides",
    "title": "Domain-Specific Resources",
    "section": "",
    "text": "These guides provide applied researchers with curated lists of tutorials, case studies, and resources which contain Stan implementations of the most commonly used models in their domain. If you would like to contribute one for your field, see this Discourse post: Fostering Stan user communities through domain-specific resource pages\n\n\n\nTopics: Item Response Theory, Cognitive Diagnosis Models, Multilevel Modeling\nMaintainer: Sofia Rabe-Hesketh\n\n\n\n\n\nTopics: Ecological times series models, population models, predator-prey dynamics, species site-occupancy models.\nMaintainer: Vianey Leos Barajas\n\n\n\n\n\nTopics: Disease transmission (SIR models), disease mapping (ICAR, BYM models), survival analysis, longitudinal data.\nMaintainer: Léo Grinsztajn\n\n\n\n\n\nCognitive Science and Neuroscience papers which use Stan, BRMS, or RStanArm.\nMaintainer: Bruno Nicenboim"
  },
  {
    "objectID": "learn-stan/field-guides.html#stanconnect-sessions",
    "href": "learn-stan/field-guides.html#stanconnect-sessions",
    "title": "Domain-Specific Resources",
    "section": "StanConnect Sessions",
    "text": "StanConnect Sessions\nStanConnect is a virtual miniseries which consists of 3-hour meetings/mini-symposia where each meeting is like “session” of an organized conference. This series was started in 2021 and reprised in 2022. Future StanConnect series will be announced on Discourse.\n\nStan Through Space and Time (2022)\nA half-day event showcasing the use of Stan in spatial statistics and for modeling time series data.\n\nDate: October 31, 2022\nGitHub repository of slides and materials: https://github.com/stan-dev/connect22-space-time\nProgram:\n\nTime and tide wait for no one: spatio-temporal modelling in river networks - Edgar Santos Fernandez\nSpatio-temporal modelling of mosquitoes vector and its environmental drivers in Hong Kong - Stan Yip\nRobust non-Gaussian models and how to fit them in Stan - Rafael Cabral\nA space-time extension of the Poisson auto-regression to model Covid-19 cases at the England local authorities level - Pierfrancesco Alaimo Di Loro\nFitting spatio-temporal geostatistical models in Stan using the bmstdr R package - Sujit Sahu\ntipsae: Tools for Handling Indices and Proportions in Small Area Estimation - Silvia De Nicolo\ngeostan: An R package for Bayesian spatial analysis - Connor Donegan\nStructure induced by a multiple membership transformation on the conditional autoregressive model - Marco Gramatica\nA Bayesian hierarchical model for disease mapping that accounts for scaling and heavy-tailed latent effects - Victoire Michal\nBayesian latent spatial autoregressive growth modeling - Zachary Roman\n\nAbstracts\nOrganizer: James Hogg\n\n\n\nCognitive Science and Neuroscience (2021)\n\nDate: November 19, 2021\nRecorded Talks: YouTube\nProgram:\n\nResolving the multiple testing issue in neuroimaging through Bayesian multilevel modeling - Gang Chen\n\nImplementation of the Diffusion Decision Model with Across-Trial Variability in the Drift Rate - Kendal Foster and Henrik Singmann\n\nIt’s complicated: Some observations on the nuanced constraints of the multivariate normal in high dimensions - Mike Lawrence\n\nUsing computational modeling parameters to measure working memory processes - Jan Göttmann\n\n\nAbstracts\nOrganizer: Bruno Nicenboim\n\n\n\nBiostats (2021)\n\nDate: October 19, 2021\nRecorded Talks: YouTube\nGitHub repository of slides and materials: https://github.com/maxbiostat/StanConnect2021_Biostatistics\nProgram:\n\nCoding in Stan: the BYM2 model for disconnected graphs  Mitzi Morris\nNormalized power prior models in Stan  Ethan Alt\nSummarising enzyme information from online databases using Stan and Arviz,   Teddy Groves\nAutomated kinetic modelling in Stan and its application to the methionine cycle  Nicholas Cowie\nUsing Hidden Markov Models as a complement/alternative to survival modelsMartin Modrák\n\nOrganizer: Luiz Max Carvalho, PhD - Getúlio Vargas Foundation\n\n\n\nEcology, models for biological survey data (2021)\nA 2-day event showcasing applications of Stan for ecological analyses\n\nDay 1: September 30, 2021\nDay 1 Recorded Talks: YouTube\nProgram Day 1:\n\nUsing Stan to build better community - Ara Winter\nUsing Stan to diagnose and fit high-dimensional multispecies abundance models - Harold Eyster\n250000 parameters: the story of an occupancy model for Colombia’s birdlife in Stan - Jacob Socolar\nMLOps in a Bayesian workflow: tracking experiments with MLFlow - Maxwell Joseph\n\nDay 2: October 4, 2021\nProgram Day 2:\nDay 2 Recorded Talks: YouTube\n\nEvolution of habitat use and coexistence under intraguild predation: a principled Bayesian approach - Josh Goldberg\nDrift algae controls the consumption of kelp: using data from in-situ subtidal experimentation and ordinary differential equations to mechanistically model the sea urchin behavioral switch - Zach Randell\nLinking the SPDE method with Stan - Joaquin Cavieres\nUsing Stan to characterize large-scale morphological change in North American birds - Casey Youngflesh\nFitting hidden Markov models to ecological time series data in Stan - Vianey Leos Barajas\n\nOrganizer: Jacob B. Socolar, Cornell Lab of Ornithology\nPanelist Day 1: Vianey Leos Barajas: Assistant Professor, University of Toronto, Department of Statistical Sciences"
  },
  {
    "objectID": "tools/tools.html",
    "href": "tools/tools.html",
    "title": "Stan Toolkit",
    "section": "",
    "text": "A curated collection of tools and interfaces to help you work effectively with Stan across various programming environments and stages of your modeling workflow."
  },
  {
    "objectID": "tools/tools.html#language-specific-stan-interfaces",
    "href": "tools/tools.html#language-specific-stan-interfaces",
    "title": "Stan Toolkit",
    "section": "Language-Specific Stan Interfaces",
    "text": "Language-Specific Stan Interfaces\nWrite, compile, and run Stan models directly within your programming environment.\n\n\n\n\n\n\n\n\nLanguage\nTool\nDescription\n\n\n\n\nR\nCmdStanR\nInterface to Stan for R, based on CmdStan. Recommended interface for R users.\n\n\nPython\nCmdStanPy\nInterface to Stan for Python, based on CmdStan. Recommended interface for Python users.\n\n\nWeb\nStan Playground\nBrowser-based editor and runtime environment for Stan models. Highly recommended for new users.\n\n\nJulia\nStan.jl\nInterface to Stan for Julia users.\n\n\nMATLAB\nMatlabStan\nInterface to Stan for MATLAB users.\n\n\nShell\nCmdStan\nCommand-line interface to Stan, usable from any shell environment.\n\n\nR\nRStan\nLegacy R interface to Stan. (For new projects, consider using CmdStanR.)\n\n\nPython\nPyStan\nLegacy Python interface to Stan. (For new projects, consider using CmdStanPy.)\n\n\n\nFor detailed installation instructions see Getting Started."
  },
  {
    "objectID": "tools/tools.html#high-level-modeling-interfaces",
    "href": "tools/tools.html#high-level-modeling-interfaces",
    "title": "Stan Toolkit",
    "section": "High-Level Modeling Interfaces",
    "text": "High-Level Modeling Interfaces\nSimplify model specification in R.\n\n\n\n\n\n\n\n\nLanguage\nTool\nDescription\n\n\n\n\nR\nbrms\nUse extended lme4-like formula syntax to specify and fit multivariate and multilevel models in Stan. (Requires CmdStanR and C++ compiler.)\n\n\nR\nrstanarm\nProvides stable, efficient Stan versions of R model-fitting packages. Installs easily from CRAN, no C++ compiler needed."
  },
  {
    "objectID": "tools/tools.html#visualization-diagnostics-and-validation-tools",
    "href": "tools/tools.html#visualization-diagnostics-and-validation-tools",
    "title": "Stan Toolkit",
    "section": "Visualization, Diagnostics, and Validation Tools",
    "text": "Visualization, Diagnostics, and Validation Tools\nValidate, visualize, and compare fitted models to ensure robust results.\n\n\n\n\n\n\n\n\nLanguage\nTool\nDescription\n\n\n\n\nR\nbayesplot\nPlotting functions for posterior analysis, diagnostics, and model checking.\n\n\nR\nloo\nEfficient leave-one-out cross-validation and WAIC for Bayesian models.\n\n\nR\nposterior\nTools for working with posterior distributions.\n\n\nR\nprojpred\nProjection predictive variable selection for Bayesian models.\n\n\nPython\nArviZ\nExploratory analysis of Bayesian models with extensive visualization capabilities.\n\n\nJulia\nArviZ.jl\nJulia interface to ArviZ for Bayesian analysis.\n\n\nWeb\nMCMC Monitor\nWeb-based tool for monitoring MCMC diagnostics."
  },
  {
    "objectID": "tools/tools.html#developer-tools-and-apis",
    "href": "tools/tools.html#developer-tools-and-apis",
    "title": "Stan Toolkit",
    "section": "Developer Tools and APIs",
    "text": "Developer Tools and APIs\nAccess Stan’s computational backend for advanced applications and development.\n\n\n\n\n\n\n\n\nLanguage\nTool\nDescription\n\n\n\n\nC++\nStan Math Library\nAutomatic differentiation and mathematical functions used by Stan.\n\n\nMultiple Languages\nBridgeStan\nLibrary providing bindings to a model’s log densities, gradients, and more for C++, Python, Julia, R, and Rust.\n\n\nR\nrstantools\nTools for developers of R packages interfacing with Stan."
  },
  {
    "objectID": "tools/tools.html#editor-and-ide-support",
    "href": "tools/tools.html#editor-and-ide-support",
    "title": "Stan Toolkit",
    "section": "Editor and IDE Support",
    "text": "Editor and IDE Support\nEnhance your coding experience with Stan language support in your favorite editor.\n\n\n\n\n\n\n\n\nEditor/IDE\nTool\nDescription\n\n\n\n\nRStudio\nBuilt-in Support\nRStudio 1.2+ includes Stan syntax highlighting and code snippets. (Source code)\n\n\nVisual Studio Code\nStan VSCode Extension\nStan language support with syntax highlighting, autocompletion, and snippets.\n\n\nEmacs\nstan-mode\nMajor mode for Stan with syntax highlighting and indentation.\n\n\nVim\nstan-vim\nSyntax highlighting, indentation, and code folding for Stan in Vim.\n\n\nAtom\nlanguage-stan\nStan language support in Atom editor.\n\n\nSublime Text\nSublimeStan\nSyntax highlighting for Stan in Sublime Text.\n\n\nJupyterLab\njupyterlab-stan-highlight\nSyntax highlighting for Stan code blocks in JupyterLab.\n\n\nJavascript\nPrism  Highlight.js\nLightweight syntax highlighting library - (Source code).  Syntax highlighter written in javascript - (Source code)\n\n\nMarkdown Editors\nPandoc  Pygments\nStan syntax highlighting for document formats. (Source code)Python highlighter for Stan code blocks (Source code)\n\n\nLaTeX\nlstbayes\nLaTeX listings for Stan syntax highlighting."
  },
  {
    "objectID": "learn-stan/stancon/StanConnect2022_space_time.html",
    "href": "learn-stan/stancon/StanConnect2022_space_time.html",
    "title": "StanConnect 2022: Stan Through Space and Time",
    "section": "",
    "text": "StanConnect 2022: Stan Through Space and Time\nSpeakers and topics\nEdgar Santos Fernandez Time and tide wait for no one: spatio-temporal modelling in river networks Abstract:\nSpatio-temporal models are widely used in many research areas including ecology and conservation. The recent proliferation of the use of in-situ sensors in streams and rivers supports space-time water quality modelling and monitoring in near real-time. In this presentation, we introduce a new family of Bayesian spatio-temporal models for river networks, in which spatial dependence is established based on stream distance and flow connectivity, and temporal autocorrelation is incorporated using vector autoregression approaches. We have developed several variations of these models within a Bayesian framework which have led to the creation of an R package (SSNbayes). Our results show that the proposed models perform well in terms of out-of-sample performance measures.\nBio:\nDr. Santos-Fernandez works on the development of statistical methodology across many domains such as ecology and conservation, citizen science, risk assessment and sports analytics. This includes advancing sampling techniques, spatio-temporal modelling, multivariate statistics, and anomaly detection.\nHe is currently working on spatio-temporal applications in river networks.\nMore details and recent publications can be found here: https://www.researchgate.net/profile/Edgar-Santos-Fernandez\nStan Yip Spatio-temporal modelling of mosquitoes vector and its environmental drivers in Hong Kong Abstract:\nIn this talk, we present an application of a spatio-temporal beta regression model in modelling mosquito vectors implemented in Stan language. The mosquito abundance indices, namely ovitrap and gravitrap indices are captured through a beta distribution model with support from zero to one. A hurdle model extension to this framework is also discussed.\nBio:\nDr Yip is a researcher in various areas in statistical applications primarily environmental sciences and climatology. Prior to his role in the Hong Kong Polytechnic University, he has spent a few years in multiple R&D roles in industry before returning to academia. He was a research scientist in National Centre for Atmospheric Science, a research associate in University of Exeter, a junior member of Isaac Newton Institute for Mathematical Sciences in Cambridge and a visiting scholar in Duke University.\nRafael Cabral Robust non-Gaussian models and how to fit them in Stan Abstract:\nTraditionally the excitation noise of spatial and temporal models is Gaussian. However, real-world data may not be Gaussian in nature, and it is well known that outliers can adversely affect the inferences and predictions made from a Gaussian model. In this talk, I will present a generic and robust class of non-Gaussian models that leads to more robust estimates and better predictions. If you already have a Gaussian model implemented in Stan you will only need to change one line of code!\nBio:\nMy name is Rafael and I am PhD candidate at KAUST, Saudi Arabia, being supervised by Profs. Haavard Rue, and David Bolin. My PhD research revolves around building more flexible, robust, and computationally efficient modeling frameworks for spatial and temporal data. I’ve worked with Gaussian and non-Gaussian processes, model criticism and robustness, and approximate inference with Stan, INLA, and variational inference.\nPierfrancesco Alaimo Di Loro A space-time extension of the Poisson auto-regression to model Covid-19 cases at the England local authorities level Abstract:\nThe incidence of an infectious disease is one of the main indicators to describe the evolution of an epidemic process in a population. Understanding its pattern is key to addressing public health policies and verifying their effectiveness.\nHere, we propose a space-time extension of the Poisson auto-regression to model the local incidences collected over different areas. We set up a generalized linear framework to link the auto-regressive coefficient and the baseline rate to observed covariates and space-time CAR-AR Leroux random effects.\nThe estimation is carried out in a Bayesian Framework through STAN. The fit of such a complex model requires adopting efficient strategies to speed up the likelihood evaluation and reach convergence in due time.\nWe model the number of weekly COVID-19 cases recorded in 313 English districts during the second and third waves of the COVID-19 pandemic. We consider two alternative sets of observed covariates: the level of local restriction currently in place; the value of various Google mobility indices. We first verify the convergence of the estimation mechanism and the ability of the model to recover the true parameters in an extensive simulation study. Then, we fit the model and simpler versions of it on the observed data. The full model outplays all others according to multiple metrics. It allows quantifying the relative importance of previous lags and evaluating the relative importance of the hidden cases across space and time.\nBio:\nI am a Junior Assistant Professor at the Dpt. GEPLI of LUMSA University and collaborator with the S3RI institute of the University of Southampton. My research interests concern the study of spatial and spatio-temporal phenomena, with a particular focus on the Bayesian Hierarchical Modeling of large geo-referenced data.\nSujit Sahu Fitting spatio-temporal geostatistical models in Stan using the bmstdr R package. Abstract:\nIn this talk I present the recently published R package bmstdr that is able to fit several Bayesian spatial and spatio-temporal models. Point referenced data are modeled using Gaussian processes and Gaussian error distributions. Two model fitting engines: Bspatial for spatial only point referenced data and Bsptime for spatio-temporal data are included in the package. Both of these engines admit “Stan” as one of the package options among other possibilities such as spBayes, spTimer, spTDyn and INLA. A third model fitting function, Bmoving_sptime, is provided for fitting irregularly observed spatio-temporal data possibly from a set of moving sensors.\nThe user of bmstdr is afforded the flexibility to name particular rows of their input data frame for validation purposes.\nThe package allows quick comparison of models using both model choice criteria, such as DIC and WAIC, and K-fold cross-validation without much programming effort. Familiar linear model fit exploration tools and diagnostic plots are included through the S3 methods such as summary, residuals and plot implemented for the three bmstdr functions. Our illustrations show that compared to some other packages Stan fitted spatio-temporal models validate better, and also perform better according to some model choice criteria such as the WAIC.\nBio:\nSujit Sahu is a Professor of Statistics at the University of Southampton. He is the author of the book Bayesian modeling of spatio-temporal data with R published by Chapman and Hall/CRC Press.\nPackage site: https://cran.r-project.org/web/packages/bmstdr/vignettes/bmstdr-vig_bookdown.html\nSilvia De Nicolo tipsae: Tools for Handling Indices and Proportions in Small Area Estimation Abstract:\nThe tipsae package implements a set of small area estimation tools for mapping proportions and indicators defined on the unit interval. It provides for small area models defined at area level, including the classical Beta regression, Zero and/or One Inflated Beta and Flexible Beta ones. The models, developed within a Bayesian framework, are estimated through Stan language, allowing fast estimation and customized parallel computing. To account for possible dependency structure in the data, we enable the inclusion of spatial and/or temporal random effects in the linear predictor by means of Intrinsic Conditional Auto-Regressive and Random Walk priors. The additional features of the tipsae package, such as diagnostics, visualization and exporting functions as well as variance smoothing and benchmarking functions, improve the user experience through the entire process of estimation, validation and outcome presentation. A Shiny application with a user-friendly interface further eases the implementation of Bayesian models for small area analysis.\nBio:\nPost-Doctoral Fellow at the University of Bologna, her main research interests concern Bayesian hierarchical models, small area estimation and their application to inequality and poverty measurement.\nConnor Donegan geostan: An R package for Bayesian spatial analysis Abstract:\nThis presentation will introduce geostan, an R package that provides access to pre-built Stan models and other functions for analyzing spatial data. The project aims to support and facilitate a full spatial analysis workflow, from exploratory analysis to modeling and model evaluation. A unique feature of the package is its spatial measurement error models, which enable researchers to incorporate data quality information from error-laden, survey-based covariates. In addition to providing access to a variety of pre-built models (GLMs, CAR, BYM, SAR, ESF), geostan provides tools for building custom, computationally efficient spatial models in Stan. A geostan workflow will be illustrated through an analysis of small-area colorectal cancer incidence in Texas metropolitan areas.\nBio:\nConnor Donegan is a doctoral candidate in Geospatial Information Sciences at The University of Texas at Dallas, and a research assistant in the Peter O’Donnell Jr. School of Public Health at UT Southwestern Medical Center. He studies health geography, spatial statistics, and epistemology.\nMarco Gramatica Structure induced by a multiple membership transformation on the conditional autoregressive model Abstract:\nThe usual context for disease mapping is to model data aggregated at the areal level. In some contexts, however, (e.g. residential histories, general practitioner catchment areas) the data are not recorded on a particular spatial framework, but it is possible to specify spatial random effects, or covariate effects, at the areal level, by using a multiple membership principle (MM). In fact, both Petrof (2020) and Gramatica (2021) use a weighted average of conditional autoregressive (CAR) spatial random effects to embed spatial information for a spatially-misaligned outcome and estimate relative risk for both frameworks (areas and memberships). In this talk we investigate the application of the MM principle to the CAR prior in terms of its parameterisation, properness and identifiability. We carry out simulations involving different numbers of memberships as compared to number of areas and assess impact of this on estimating of CAR parameters and relative risks. Results show that overall posterior samples are well calibrated for both frameworks across all simulation scenarios. Finally, we present the results of an application of the MM modelling strategy to diabetes prevalence data in South London.\nBio:\nMarco Gramatica has just completed his PhD with a thesis on Bayesian modelling of spatially misaligned data. His research focused on the use of CAR priors and Multiple Membership to jointly model data recorded on different spatial frameworks. He is now a Postdoctoral Research Assistant at Queen Mary University of London.\nVictoire Michal A Bayesian hierarchical model for disease mapping that accounts for scaling and heavy-tailed latent effects Abstract:\nIn disease mapping, we estimate the relative risk of a disease across different areas within a region of interest. The number of cases in an area is often modelled through a Poisson distribution with mean given by the product between an offset and the logarithm of the relative risk of the disease. The Besag, York and Mollié model, commonly used to account for potential overdispersion and a spatial correlation structure among the counts, does not accommodate outliers. An area may be one of two types of outliers: it may be an outlier in the usual sense, exhibiting an extreme disease risk, or it may be a spatial outlier. Spatial outliers refer to risks that are outliers with respect to their neighbors. We build on the Bayesian hierarchical model proposed by Riebler et al. (2016) and assume a scale mixture structure wherein the variance of the latent process changes across areas and allows for outlier identification. We compare our approach with that proposed by Congdon (2017), in an analysis of cases of Zika during the 2015-2016 epidemic in Rio de Janeiro. This is joint work with Laís Picinini Freitas (Université de Montréal) and Alexandra M. Schmidt (McGill University).\nBio:\nVictoire is a PhD student in the Biostatistics graduate program at McGill University. She studies Spatial Statistics and Disease Mapping to model the cases of Zika in Rio de Janeiro as well as Small Area Estimation and Record Linkage to estimate the household consumption in Ghana at a fine aggregation level. She holds a Bachelor’s degree in Mathematics and a Master’s degree in Statistics, both from the University of Montreal.\nRachary Roman Bayesian latent spatial autoregressive growth modeling. Abstract:\nStructural Equation Models (SEM) are widely used in behavioral research for measuring and testing multi-faceted constructs. The integration of spatial models to behavioral phenomena particularly in psychology has been limited. This in part may be due to the requirements for observed variables that traditional spatial approaches require. In this talk I will present a recent adaptation I developed to accommodate spatial autoregressive effects with a common latent variable approach, Latent Growth Modeling (LGM). This approach can be seen as a latent parameterization of mixed effects models with the added flexibility of the latent variable framework. I will emphasize the MCMC application written in Stan, an example applied to German Covid-19 data will also be presented.\nBio:\nDr. Zachary Roman is a postdoctoral researcher in the psychology department at the University of Zurich, he is also affiliated with the Method Center at the University of Tuebingen. Zachary completed his Ph.D. in quantitative psychology at the University of Kansas in 2019. His research interests include the applications of spatial / social network autoregressive approaches in the behavioral sciences, specifically focused on methodological developments in this area.\n\n\n\n\n Back to top"
  },
  {
    "objectID": "install/install.html",
    "href": "install/install.html",
    "title": "Getting Started",
    "section": "",
    "text": "To analyze your data with Stan, you can either"
  },
  {
    "objectID": "install/install.html#sec-install",
    "href": "install/install.html#sec-install",
    "title": "Getting Started",
    "section": "Download and Install Stan",
    "text": "Download and Install Stan\nTo compile and run Stan models directly from within R, Python, or Julia, select your OS, programming language interface, and preferred installation method in the grid below. For other programming environments, skip to Other Programming Environments\n\n\n\n\n\n\nPrerequisites\n\n\n\nStan requires a C++17 compiler and some build utilities.. The conda option of certain packages can install these for you, otherwise these are bundled together by Rtools.\n\n\nStan requires a C++17 compiler. The conda option of certain packages can install this for you, or we recommend to install Xcode from the App Store and then run xcode-select --install.\n\n\nStan requires a C++17 compiler. The conda option of certain packages can install this for you, or on .deb based distros, sudo apt-get install build-essential will install what you need.\n\n\n\n\n\nHow to Install\n\n\n\nPlease select interface and preferred package manager.\n\n\n\nRun pip install cmdstanpy. Then, in Python, run import cmdstanpy; cmdstanpy.install_cmdstan() or follow the manual installation instructions for CmdStan.\nFor more information, see the CmdStanPy documentation.\n\n\nRun conda install -c conda-forge cmdstanpy.\nNote: this will also install CmdStan and any system prerequisites.\n\n\nRun pip install -e git+https://github.com/stan-dev/cmdstanpy@develop#egg=cmdstanpy. Then, in Python, run import cmdstanpy; cmdstanpy.install_cmdstan() or follow the manual installation instructions for CmdStan.\nFor more information, see the CmdStanPy documentation.\n\n\n\nIn R, run install.packages(\"cmdstanr\", repos = c('https://stan-dev.r-universe.dev', getOption(\"repos\"))). Then run cmdstanr::install_cmdstan() or follow the manual installation instructions for CmdStan.\nFor more information, see the CmdStanR documentation\n\n\nRun conda install -c conda-forge r-cmdstanr.\nNote: this will also install CmdStan and any system prerequisites.\n\n\nIn R, run remotes::install_github(\"stan-dev/cmdstanr\").\nThen run cmdstanr::install_cmdstan() or follow the manual installation instructions for CmdStan.\nFor more information, see the CmdStanR documentation\n\n\n\nDownload a release from GitHub: https://github.com/stan-dev/cmdstan/releases.\nThen follow these instructions to build CmdStan.\n\n\nRun conda install -c conda-forge cmdstan.\nNote: this will also install CmdStan and any system prerequisites.\n\n\nRun git clone https://github.com/stan-dev/cmdstan.git --recursive\nThis will download the source code from the current development branch of CmdStan into a directory named cmdstan, along with the submodules for core Stan code and the Stan math library.\nThen follow these instructions to build CmdStan.\n\n\n\nIn R, run install.packages(\"rstan\")\nFor more information, see the RStan Getting Started wiki\n\n\nIn R, run install.packages(\"rstan\", repos = c('https://stan-dev.r-universe.dev', getOption(\"repos\"))).\nFor more information, see the RStan Getting Started wiki\n\n\nRun conda install -c conda-forge r-rstan.\nNote: this will also install any system prerequisites.\n\n\nremotes::install_github(“stan-dev/rstan”, ref = “develop”, subdir = “rstan/rstan”)\nFor more information, see the RStan wiki page Installing RStan from Source\n\n\n\nTo install Stan.jl e.g. in the Julia REPL: ] add Stan, then use Conda.jl or conda to install CmdStan.\nSee Stan.jl documentation for further details.\n\n\nRun https://github.com/StanJulia/Stan.jl.git, then follow instructions in the README file.\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nConda simplifies the installation process by ensuring that all required libraries and tools are compatible with each other and is available for Linux, Mac, and Windows platforms.\nYou can either install miniconda, a free, minimal installer for conda or you can get the full Anaconda system which provides graphical installer wizards for MacOS and Windows users.\nJulia users can install Conda.jl.\n\n\n\nOther Programming Environments\n\n\n\n\n\n\n\n\nLanguage\nTool\nDescription\n\n\n\n\nR, Python\nGoogle Colab\nPrebuilt CmdStan binaries for Google Colab are available from the GitHub CmdStan releases page. Installing these binaries at the start of a Colab session is much faster than installing CmdStan during a Colab session.\n\n\nMathematica\nMathematicaStan\nStan interface for Mathematica. Available from its GitHub repository.\n\n\nMATLAB\nMatlabStan\nInstallation instructions available on the MatlabStan wiki.\n\n\nPython\nPyStan\nAvailable via pip. Run command: python -m pip install pystan.\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nAs of Release 3.10.0, PyStan is no longer being actively supported."
  },
  {
    "objectID": "install/install.html#prerequisite-c17-toolchain",
    "href": "install/install.html#prerequisite-c17-toolchain",
    "title": "Getting Started",
    "section": "Prerequisite: C++17 toolchain",
    "text": "Prerequisite: C++17 toolchain\nStan models are specified using the Stan language which are then compiled to executable programs that can be run on your data to perform inference and make predictions. To use Stan from within your preferred programming environment, you need a C++ toolchain comprised of a C++17 compiler and the GNU Make utility.\n\nOn Linux, these are bundled into the meta-package build-essential. To install, run command:\nsudo apt-get install build-essential\nOn Mac, the Clang compiler and GNU Make are included with Xcode, the Apple toolset for software developers. Install Xcode from the App Store and then run command:\nxcode-select --install\n\n\nOn Windows 10, there are two ways to get a Stan-compatible C++ toolchain:\n\nUse the conda installer for CmdStan, CmdStanPy or CmdStanR or RStan, since these packages all include the required toolchain.\nGet Rtools which includes a C++17 compiler, GNU Make for windows, and a few Unix utilities.\nCmdStanR users can call the internal function cmdstanr:::install_toolchain.\nCmdStanPy provides both the function cmdstanpy::get_cxx_toolchain and command line script get_cxx_toolchain."
  },
  {
    "objectID": "install/install.html#local-cmdstan-installations-for-cmdstanpy-cmdstanr-and-stan.jl",
    "href": "install/install.html#local-cmdstan-installations-for-cmdstanpy-cmdstanr-and-stan.jl",
    "title": "Getting Started",
    "section": "Local CmdStan installations for CmdStanPy, CmdStanR, and Stan.jl",
    "text": "Local CmdStan installations for CmdStanPy, CmdStanR, and Stan.jl\nCmdStanPy, CmdStanR, and Stan.jl and require a local CmdStan installation. Both CmdStanPy and CmdStanR provide method install_cmdstan to do this from within Python or R; and CmdStanPy also provides this as a command-line function. See the online documentation:\n\nCmdStanPy: install_cmdstan function\nCmdStanR: install_cmdstan function\nStan.jl build instructions\n\nThe default installation location is in the user’s home directory and is named .cmdstan (a hidden directory). This directory contains one or more versions of CmdStan.\nBoth CmdStanPy and CmdStanR provide the following functions:\n\nrebuild_cmdstan - rebuild the specified release. On Mac, often required after an Xcode update.\nshow_versions - shows all installed CmdStan versions\ncmdstan_path - shows which version of CmdStan is being used\nset_cmdstan_path - specify which version of CmdStan to use."
  },
  {
    "objectID": "install/install.html#troubleshooting-the-install",
    "href": "install/install.html#troubleshooting-the-install",
    "title": "Getting Started",
    "section": "Troubleshooting the Install",
    "text": "Troubleshooting the Install\nTo help troubleshoot problems that arise when trying to use Stan, we provide the following summary of the chain of events in conditioning a model on data and doing inference:\n\nCompile model\n\nStan compiler translates Stan file to C++ file\nC++ file is compiled to executable program, via GNU Make\n\nRun inference algorithm\n\nInterfaces run compiled executable program\nCompiled executable generates per-chain outputs\n\n\nIf the program contains syntax errors, these will be caught and reported by the Stan compiler (program stanc). If the Stan program is successfully translated to C++, then it should compile; error messages from the C++ compiler indicate a problem with the C++ toolchain.\nIf a model fails to run or appears to run slowly, this is a strong indication that the model is poorly specified given the data. Consult the Stan User’s Guide or search the Stan Forums on Discourse\nCommon Points of failure; how to address them.\n\nSoftware download failed.\n\nworkaround: check internet connectivity, disk space, and file permissions\n\nC++ components fail to compile\n\nWorkaround: we highly recommend installing using conda to create a clean environment for Stan and its toolchain.\n\nStan model fails to compile with error message about a ““.(PCH file)()\n\nFix: for CmdStan based systems, rebuild CmdStan.\n\n\nSee CmdStan Guide section Troubleshooting the Installation for further details."
  },
  {
    "objectID": "install/install.html#high-level-stan-interfaces",
    "href": "install/install.html#high-level-stan-interfaces",
    "title": "Getting Started",
    "section": "High-level Stan Interfaces",
    "text": "High-level Stan Interfaces\n\n\n\n\n\n\n\n\nLanguage\nTool\nDescription\n\n\n\n\nR\nbrms\nUse extended lme4-like formula syntax to specify and fit multivariate and multilevel models in Stan. (Requires CmdStanR and C++ compiler.)\n\n\nR\nRStanArm\nProvides stable, efficient Stan versions of R model-fitting packages. (Stan models are pre-compiled, no C++ compiler needed.)\n\n\nR\nRethinking\nAccompanies the book and course materials for Statistical Rethinking, 2nd Ed by Richard McElreath. (Requires CmdStanR and C++ compiler.)"
  },
  {
    "objectID": "install/install.html#introductory-notebooks-vignettes-and-tutorials",
    "href": "install/install.html#introductory-notebooks-vignettes-and-tutorials",
    "title": "Getting Started",
    "section": "Introductory Notebooks,  Vignettes,  and Tutorials",
    "text": "Introductory Notebooks,  Vignettes,  and Tutorials\n\n\n\n\n\n\n\nInterface\nTitle\n\n\n\n\nCmdStanPy\nCmdStanPy “Hello, World!”Getting Started with Bayesian Statistics using Stan and PythonMultilevel regression modeling with CmdStanPy and plotnine\n\n\nCmdStanR\nGetting Started with CmdStanRStanCon2023/Stan_tutorial.ipynb\n\n\nJulia\nStan.jl Examples\n\n\nGoogle Colab\nStan Notebooks in the Cloud\n\n\n\nFor more learning resources, see the Tutorials, Publications and Stan Case Studies pages."
  },
  {
    "objectID": "learn-stan/case-studies.html",
    "href": "learn-stan/case-studies.html",
    "title": "Stan Case Studies",
    "section": "",
    "text": "The case studies on this page are intended to reflect best practices in Bayesian methodology and Stan programming. We aim to keep them current with the latest version of the Stan language, but there may be times when case studies need updating to reflect the latest Stan features and syntax."
  },
  {
    "objectID": "learn-stan/case-studies.html#volume-10-2023",
    "href": "learn-stan/case-studies.html#volume-10-2023",
    "title": "Stan Case Studies",
    "section": "Volume 10 (2023)",
    "text": "Volume 10 (2023)\n\nInstrumental Variables Analysis of Randomized Experiments with One-Sided Noncompliance\nIn this document, we demonstrate how to implement Bayesian inference for causal effects in randomized experiments with one-sided noncompliance using Stan. Specifically, we aim to replicate the analysis presented in Imbens and Rubin (1997). We present Stan models with and without the exclusion restriction assumption, showcasing a significant advantage of the Bayesian model-based approach.\nView HTML (link opens in new tab)\n\nAuthors\n\nJoonHo Lee, Avi Feller, Sophia Rabe-Hesketh\n\nKeywords\n\ncausal inference, instrumental variables analysis, one-sided compliance, principal stratification\n\nSource Repository\n\nexample-models/education/causal_iv_one-sided (GitHub)\n\nDependencies\n\ntidyverse, rstan, bayesplot, patchwork\n\nLicense\n\nBSD (3 clause), CC-BY\n\n\n\n\nBayesian Structural Equation Modeling using blavaan\nIn this case study, we fit Bayesian structural equation models (SEM) using Hamiltonian Monte Carlo sampling in Stan-powered R package blavaan and illustrate how to use confirmtory factor analysis and latent growth curve modeling as SEM’s special cases. We also compared the estimates from blavaan with its frequentist counterpart using lavaan.\nView HTML (Link opens in new tab)\n\nAuthors\n\nFeng Ji, Xingyao Xiao, Aybolek Amanmyradova, Sophia Rabe-Hesketh\n\nKeywords\n\nStructural Equation Modeling (SEM), Lavant Variable Modeling, Latent Growth Curve Models, Confirmatory Factor Analysis (CFA), Growth Curve Modeling, Bayesian Model Evaluation\n\nSource Repository\n\nexample-models/education/sem (GitHub)\n\nDependencies\n\nblavaan, lavaan, rstan, MASS, mvtnorm, tidyverse, semPlot, magrittr, lavaan.survey\n\nLicense\n\nBSD (3 clause), CC-BY"
  },
  {
    "objectID": "learn-stan/case-studies.html#volume-9-2022",
    "href": "learn-stan/case-studies.html#volume-9-2022",
    "title": "Stan Case Studies",
    "section": "Volume 9 (2022)",
    "text": "Volume 9 (2022)\n\nMultilevel regression modeling with CmdStanPy and plotnine\nThis notebook is a short introduction to multilevel regression modeling using the CmdStanPyinterface and plotnine, a Python implementation of a grammar of graphics based on ggplot2.\nView(HTML)\n\nAuthors\n\nMitzi Morris\n\nKeywords\n\nPython, CmdStanPy, plotnine, hierarchical/multilevel modeling, linear regression, posterior predictive checks, radon\n\nSource Repository\n\nexample-models/jupyter/radon (GitHub)\n\nDependencies\n\ncmdstanpy, numpy, pandas, matplotlib, plotnine, jupyter\n\nLicense\n\nBSD (3 clause), CC-BY\n\n\n\n\nHoloML in Stan: Low-photon Image Reconstruction\nIn this case study, we perform image reconstruction in Stan by implementing the HoloML phase retrieval model and then solving the inverse problem with optimization. This case study requires Stan 2.30 or greater in order to use the Fourier transform functions added in that version.\nView(HTML)\n\nAuthors\n\nBrian Ward, Bob Carpenter, and David Barmherzig\n\nKeywords\n\nimage reconstruction, phase retrieval, Fourier transforms, deconvolution\n\nSource Repository\n\nWardBrian/holoml-in-stan (GitHub)\n\nDependencies\n\ncmdstanpy, numpy, matplotlib, scipy, jupyter\n\nLicense\n\nBSD (3 clause), CC-BY"
  },
  {
    "objectID": "learn-stan/case-studies.html#volume-8-2021",
    "href": "learn-stan/case-studies.html#volume-8-2021",
    "title": "Stan Case Studies",
    "section": "Volume 8 (2021)",
    "text": "Volume 8 (2021)\n\nBayesian Latent Class Models and Handling of Label Switching\nIn this case study, we fit the Bayesian latent class model using Hamiltonian Monte Carlo sampling and Variational Bayes in Stan and illustrate the issue of label switching and its treatment with simulated and empirical data.\nView(HTML)\n\nAuthors\n\nFeng Ji, Aybolek Amanmyradova, Sophia Rabe-Hesketh\n\nKeywords\n\nlatent class models, label-switching, post-hoc relabeling, variational Bayes\n\nSource Repository\n\nexample-models/education/latent_class (GitHub)\n\nDependencies\n\nlabel.switching, rstan, magrittr, knitr, poLCA\n\nLicense\n\nBSD (3 clause), CC-BY"
  },
  {
    "objectID": "learn-stan/case-studies.html#volume-7-2020",
    "href": "learn-stan/case-studies.html#volume-7-2020",
    "title": "Stan Case Studies",
    "section": "Volume 7 (2020)",
    "text": "Volume 7 (2020)\n\nBayesian model of planetary motion: exploring ideas for a modeling workflow when dealing with ordinary differential equations and multimodality\nThe Bayesian model of planetary motion is a simple but powerful example that illustrates important concepts, as well as gaps, in prescribed modeling workflows. Our focus is on Bayesian inference using Markov chains Monte Carlo for a model based on an ordinary differential equations (ODE). Our example presents unexpected multimodality, causing our inference to be unreliable and what is more, dramatically slowing down our ODE integrators. What do we do when our chains do not mix and do not forget their starting points? Reasoning about the computational statistics at hand and the physics of the modeled phenomenon, we diagnose how the modes arise and how to improve our inference. Our process for fitting the model is iterative, starting with a simplification and building the model back up, and makes extensive use of visualization.\nView(HTML)\n\nAuthors\n\nCharles Margossian and Andrew Gelman\n\nKeywords\n\nordinary differential equations, multimodality, classical mechanics\n\nSource Repository\n\nexample-models/knitr/planetary_motion (GitHub)\n\nDependencies\n\nCmdStanR, posterior, ggplot2, dplyr, plyr, tidyr, boot, latex2exp\n\nLicense\n\nBSD (3 clause), CC-BY\n\n\n\n\nHMM Interface Example\nCmdstan 2.24 introduces a new interface for working with Hidden Markov Models (HMMs). This is an example of how to use that interface.\nView(HTML)\n\nAuthors\n\nBen Bales\n\nKeywords\n\nHidden Markov Models, HMMs, cmdstanr, Stan programming\n\nSource Repository\n\nexample-models/knitr/hmm-example (GitHub)\n\nDependencies\n\nCmdStanR, tidyverse, ggplot2, posterior\n\nLicense\n\nBSD (3 clause), CC-BY\n\n\n\n\nSpatial models for plant neighborhood dynamics in Stan\nIn this case study, we demonstrate how Stan’s segment function can speed computation on sparse matrices of pairwise neighbors in plant-plant interaction models. In addition, we present solutions to common problems of fitting neighborhood models with hierarchical effects, including a comparison of centered vs. non-centered parameterizations.\nView(HTML)\n\nAuthors\n\nCristina Barber, Andrii Zaiats, Cara Applestein and T.Trevor Caughlin\n\nKeywords\n\nplants, neighbor interactions, sparse matrix, segment function\n\nSource Repository\n\nCristinabarber/Neighbor_Interactions (GitHub)\n\nR Package Dependencies\n\nrstan\n\nLicense\n\nBSD (3 clause), CC BY NC\n\n\n\n\nPredicting Engine Failure with Hierarchical Gaussian Process\nThis gaussian process case study is an extension of the StanCon talk “Failure prediction in hierarchical equipment system: spline fitting naval ship failure”. Many comparison criteria exist, but in terms of prediction accuracy, the gaussian process model outperformed the spline model. However, this accuracy comes at a cost of a more detailed and iterative checking process. This case study shows how identification and underfitting problems diagnosed from pushforward and predictive checks are addressed through reparameterization and adding variables. Basically, our data is highly unbalanced per category with lots of missing data. Also, due to the hierarchical structure of the system, such as shared engine types, the hierarchical model is applicable. For a detailed explanation of the data and spline model, please refer to this notebook.\nView(HTML)\n\nAuthor\n\nHyunji Moon, Jungin Choi\n\nKeywords\n\nHierarchical Gaussian process, Bayesian workflow\n\nSource Repository\n\nexample-models/knitr/gaussian-process (GitHub)\n\nDependencies\n\nCmdStanR, Rstan\n\nLicense\n\nBSD (3 clause), CC-BY\n\n\n\n\nUpgrading to the new ODE interface\nCmdstan 2.24 introduces a new ODE interface intended to make it easier to specify the ODE system function. This document should serve as an overview of the interface changes as well as a tutorial for converting code written with the old ODE interface.\nView(HTML)\n\nAuthors\n\nBen Bales, Sebastian Weber\n\nKeywords\n\nordinary differential equations, cmdstanr, Stan programming\n\nSource Repository\n\nexample-models/knitr/convert-odes (GitHub)\n\nDependencies\n\nCmdStanR\n\nLicense\n\nBSD (3 clause), CC-BY\n\n\n\n\nBayesian Workflow for disease transmission modeling in Stan\nThis tutorial shows how to build, fit, and criticize disease transmission models in Stan, and should be useful to researchers interested in modeling the COVID-19 outbreak and doing Bayesian inference. Bayesian modeling provides a principled way to quantify uncertainty and incorporate prior knowledge into the model. What is more, Stan’s main inference engine, Hamiltonian Monte Carlo sampling, is amiable to diagnostics, which means we can verify whether our inference is reliable. Stan is an expressive probabilistic programing language that abstracts the inference and allows users to focus on the modeling. The resulting code is readable and easily extensible, which makes the modeler’s work more transparent and flexible. In this tutorial, we demonstrate with a simple Susceptible-Infected-Recovered (SIR) model how to formulate, fit, and diagnose a compartmental model in Stan. We also introduce more advanced topics which can help practitioners fit sophisticated models; notably, how to use simulations to probe our model and our priors, and computational techniques to scale ODE-based models.\nView(HTML)\n\nAuthors\n\nLeo Grinsztajn, Elizaveta Semenova, Charles C. Margossian, and Julien Riou\n\nKeywords\n\nDisease transmission, Compartment models, Ordinary Differential Equations, Bayesian Workflow\n\nSource Repository\n\ncharlesm93/disease_transmission_workflow (GitHub)\n\nDependencies\n\nRStan\n\nLicense\n\nBSD (3 clause), CC-BY\n\n\n\n\nReduce Sum Example: parallelization of a single chain across multiple cores\nStan 2.23 introduced reduce_sum, a new way to parallelize the execution of a single Stan chain across multiple cores. This introduction copies directly from Richard McElreath’s Multithreading and Map-Reduce in Stan 2.18.0: A Minimal Example\nView(HTML)\n\nAuthor\n\nBen Bales\n\nKeywords\n\nwithin-chain parallel computation, cmdstanr, Stan programming\n\nSource Repository\n\nexample-models/knitr/reduce-sum (GitHub)\n\nDependencies\n\nCmdStanR\n\nLicense\n\nBSD (3 clause), CC-BY\n\n\n\n\nStan Notebooks in the Cloud\nThis report shows you how to author a Jupyter Notebook for your Stan model and data so that anyone with a modern web browser and a Google account can run your analysis with Google Colaboratory free cloud servers. It shows you how to quickly set up a Stan installation in the cloud and introduces two lightweight interfaces: CmdStanR and CmdStanPy.\nView(HTML)\n\nAuthor\n\nMitzi Morris\n\nKeywords\n\nJupyter, Google Colab, teaching Stan, online classroom, cloud computing\n\nSource Repository\n\nexample-models/knitr/cloud-compute-2020 (GitHub)\n\nDependencies\n\ninternet connection, Google account\n\nLicense\n\nBSD (3 clause), CC-BY"
  },
  {
    "objectID": "learn-stan/case-studies.html#volume-6-2019",
    "href": "learn-stan/case-studies.html#volume-6-2019",
    "title": "Stan Case Studies",
    "section": "Volume 6 (2019)",
    "text": "Volume 6 (2019)\n\nModel-based Inference for Causal Effects in Completely Randomized Experiments\nIn this document, we discuss the implementation of Bayesian model-based inference for causal effects in Stan. We start by providing an introduction to the Bayesian inferential framework by analyzing a simulated dataset generated under unconfounded treatment assignment. Then we analyze an example dataset obtained from a completely randomized experiment focusing on the specification of the joint distribution of the potential outcomes.\nView(HTML)\n\nAuthor\n\nJoonHo Lee, Avi Feller and Sophia Rabe-Hesketh\n\nKeywords\n\ncausal inference, completely randomized experiments\n\nSource Repository\n\nexample-models/education/causal_rct\n\nR Package Dependencies\n\nrstan, rstanarm, bayesplot, tidyverse, gridExtra, Matching\n\nLicense\n\nBSD (3 clause), CC-BY\n\n\n\n\nTagging Basketball Events with HMM in Stan\nThis case study shows how we can apply Bayesian inference to Hidden Markov Models (HMMs) using Stan to extract useful information from basketball player tracking data. Specifically we show how to tag drive events and how to determine defensive assignment. Before diving into basketball data we show how to fit an HMM in Stan using a simple example. This should help build some intuition for those who are unfamiliar with HMMs and will also show how to specify an HMM using Stan.\nView(HTML)\n\nAuthor\n\nImad Ali\n\nKeywords\n\nhidden markov models, sports\n\nSource Repository\n\nimadmali/bball-hmm (GitHub)\n\nR Package Dependencies\n\nrstan, bayesplot, dplyr\n\nLicense\n\nBSD (3 clause), CC-BY-NC\n\n\n\n\nModel building and expansion for golf putting\nIn this case study, we use Stan to build a series of models to estimate the probability of a successful putt using data from professional golfers. We fit and check the fit of a series of models, demonstrating the benefits of modeling based on substantive (rather than purely statistical) principles. We successfully fit to a small dataset and then have to expand the model to fit a new, larger dataset. We use weakly informative priors and a model-misfit error term to enable the fit.\nView(HTML)\n\nAuthor\n\nAndrew Gelman\n\nKeywords\n\nnonlinear regression, sports\n\nSource Repository\n\nexample-models/knitr/golf (GitHub)\n\nR Package Dependencies\n\nrstan\n\nLicense\n\nBSD (3 clause), CC-BY\n\n\n\n\nA Dyadic Item Response Theory Model: Stan Case Study\nIn this case study, we use Stan to fit the Dyadic Item Response Theory (dIRT) model proposed by (Gin et al. 2019) to measure interactions between pairs of individuals when the responses to items represent the actions/behaviors/perceptions of an individual (called the ‘actor’) made within the context of a dyad formed with another individual (called the ‘partner’). The dIRT model is fit using Stan (version 2.18.1) in R via the rstan package.\nView(HTML)\n\nAuthor\n\nNicholas Sim, Brian Gin, Anders Skrondal and Sophia Rabe-Hesketh\n\nKeywords\n\nitem response theory, social relations model, dyadic data\n\nSource Repository\n\nexample-models/education/dyadic_irt_model (GitHub)\n\nR Package Dependencies\n\nrstan, tidyverse\n\nLicense\n\nBSD (3 clause), CC-BY"
  },
  {
    "objectID": "learn-stan/case-studies.html#volume-5-2018",
    "href": "learn-stan/case-studies.html#volume-5-2018",
    "title": "Stan Case Studies",
    "section": "Volume 5 (2018)",
    "text": "Volume 5 (2018)\n\nMultilevel Linear Models using Rstanarm\nIn this tutorial, we illustrate how to fit a multilevel linear model within a full Bayesian framework using rstanarm. This tutorial is aimed primarily at educational researchers who have used lme4 in R to fit models to their data and who may be interested in learning how to fit Bayesian multilevel models. However, for readers who have not used lme4 before, we briefly review the use of the package for fitting multilevel models.\nView(HTML)\n\nAuthor\n\nJoonHo Lee, Nicholas Sim, Feng Ji, and Sophia Rabe-Hesketh\n\nKeywords\n\neducation, rstanarm, multilevel models, linear mixed models, hierarchical linear models\n\nSource Repository\n\nexample-models/education/tutorial_rstanarm (GitHub)\n\nR Package Dependencies\n\nrstanarm, mlmRev, ggplot2, lme4\n\nLicense\n\nBSD (3 clause), CC-BY\n\n\n\n\nPredator-Prey Population Dynamics: the Lotka-Volterra model in Stan\nLotka (1925) and Volterra (1926) formulated parametric differential equations that characterize the oscillating populations of predators and prey. A statistical model to account for measurement error and unexplained variation uses the deterministic solutions to the Lotka-Volterra equations as expected population sizes. Stan is used to encode the statistical model and perform full Bayesian inference to solve the inverse problem of inferring parameters from noisy data. The model is fit to Canadian lynx and snowshoe hare populations between 1900 and 1920, based on the number of pelts collected annually by the Hudson’s Bay Company. Posterior predictive checks for replicated data show the model fits this data well. Full Bayesian inference may be used to estimate future (or past) populations.\nView(HTML)\n\nAuthor\n\nBob Carpenter\n\nKeywords\n\npopulation dynamics, Lotka-Volterra equations, differential equations, posterior predictive checks\n\nSource Repository\n\nstan-dev/example-models/knitr/lotka-volterra (GitHub)\n\nR Package Dependencies\n\nrstan, &gt;ggplot2, gridExtra, knitr, reshape, tufte\n\nLicense\n\nCode: BSD (3 clause), Text: CC BY-NC 4.0\n\n\n\n\nNearest neighbor Gaussian process (NNGP) models in Stan\nNearest neighbor Gaussian process (NNGP) based models is a family of highly scalable Gaussian processes based models. In brief, NNGP extends the Vecchia’s approximation (Vecchia 1988) to a process using conditional independence given information from neighboring locations. This case study shows how to express and fit these models in Stan.\nView(HTML)\n\nAuthor\n\nLu Zhang\n\nKeywords\n\nGaussian process, nearest neighbor Gaussian process, spatial models, latent process, regression\n\nSource Repository\n\nLuZhangstat/NNGP_STAN (GitHub)\n\nR Package Dependencies\n\nrstan\n\nLicense\n\nCode: BSD (3 clause), Text: CC BY-NC 4.0"
  },
  {
    "objectID": "learn-stan/case-studies.html#volume-4-2017",
    "href": "learn-stan/case-studies.html#volume-4-2017",
    "title": "Stan Case Studies",
    "section": "Volume 4 (2017)",
    "text": "Volume 4 (2017)\n\nExtreme value analysis and user defined probability functions in Stan\nThis notebook demonstrates how to implement user defined probability functions in Stan language. As an example I use the generalized Pareto distribution (GPD) to model geomagnetic storm data from the World Data Center for Geomagnetism.\nView(HTML)\n\nAuthor\n\nAki Vehtari\n\nKeywords\n\nextreme value analysis, generalized Pareto distribution, user defined probability functions\n\nSource Repository\n\navehtari/BDA_R_demos/demos_rstan/gpareto_functions (GitHub)\n\nR Package Dependencies\n\nrstan, bayesplot, loo, ggplot2, tidyr, dplyr, extraDistr, gridExtra\n\nLicense\n\nCode: BSD (3 clause), Text: CC BY-NC 4.0\n\n\n\n\nModelling Loss Curves in Insurance with RStan\nLoss curves are a standard actuarial technique for helping insurance companies assess the amount of reserve capital they need to keep on hand to cover claims from a line of business. Claims made and reported for a given accounting period are tracked separately over time. This enables the use of historical patterns of claim development to predict expected total claims for newer policies.\nWe model the growth of the losses in each accounting period as an increasing function of time, and use the model to estimate the parameters which determine the shape and form of this growth. We also use the sampler to estimate the values of the “ultimate loss ratio”, i.e. the ratio of the total claims on an accounting period to the total premium received to write those policies. We treat each accounting period as a cohort.\nView(HTML)\n\nAuthor\n\nMick Cooney\n\nKeywords\n\nactuarial science, loss curves, insurance, ultimate loss ratio, hierarchical model\n\nSource Repository\n\nkaybenleroll/stancasestudy_losscurves (GitHub)\n\nR Package Dependencies\n\nrstan, bayesplot, tidyverse, scales, cowplot\n\nLicense\n\nCode: BSD (3 clause), Text: CC BY-NC 4.0\n\n\n\n\nSplines in Stan\nIn this document, we discuss the implementation of splines in Stan. We start by providing a brief introduction to splines and then explain how they can be implemented in Stan. We also discuss a novel prior that alleviates some of the practical challenges of spline models.\nView(HTML)\n\nAuthor\n\nMilad Kharratzadeh\n\nKeywords\n\nB-splines, piecewise regression, knots, priors\n\nSource Repository\n\nmilkha/Splines_in_Stan (GitHub)\n\nR Package Dependencies\n\nrstan, splines\n\nLicense\n\nCode: BSD (3 clause), Text: CC BY-NC 4.0\n\n\n\n\nSpatial Models in Stan: Intrinsic Auto-Regressive Models for Areal Data\nThis case study shows how to efficiently encode and compute an Intrinsic Conditional Auto-Regressive (ICAR) model in Stan. When data has a neighborhood structure, ICAR models provide spatial smoothing by averaging measurements of directly adjoining regions. The Besag, York, and Mollié (BYM) model is a Poisson GLM which includes both an ICAR component and an ordinary random-effects component for non-spatial heterogeneity. We compare two variants of the BYM model and fit two datasets taken from epidemiological studies over 56 and 700 regions, respectively.\nView(HTML)\n\nAuthor\n\nMitzi Morris\n\nKeywords\n\nspatial modeling, CAR, ICAR, INLA, OpenBUGS, hierarchical models\n\nSource Repository\n\nstan-dev/example-models (GitHub)\n\nR Package Dependencies\n\ncmdstanr, ggplot2, broom, reshape2, dplyr, maptools, spdep, R-INLA, R2OpenBugs\n\nLicense\n\nCode: BSD (3 clause), Text: CC BY-NC 4.0\n\n\n\n\nThe QR Decomposition for Regression Models\nThis case study reviews the QR decomposition, a technique for decorrelating covariates and, consequently, the resulting posterior distribution in regression models.\nView(HTML)\n\nAuthor\n\nMichael Betancourt\n\nKeywords\n\nMarkov chain Monte Carlo, regression, RStan\n\nSource Repository\n\nbetanalpha/knitr_case_studies/qr_regression (GitHub)\n\nR Package Dependencies\n\nrstan, knitr.\n\nLicense\n\nCode: BSD (3 clause), Text: CC BY-NC 4.0\n\n\n\n\nRobust RStan Workflow\nThis case study demonstrates the recommended RStan workflow for ensuring robust inferences with the default dynamic Hamiltonian Monte Carlo algorithm.\nView(HTML)\n\nAuthor\n\nMichael Betancourt\n\nKeywords\n\nMarkov chain Monte Carlo, Hamiltonian Monte Carlo, divergences, RStan\n\nSource Repository\n\nbetanalpha/knitr_case_studies/rstan_workflow (GitHub)\n\nR Package Dependencies\n\nrstan, knitr.\n\nLicense\n\nCode: BSD (3 clause), Text: CC BY-NC 4.0\n\n\n\n\nRobust PyStan Workflow\nThis case study demonstrates the recommended PyStan workflow for ensuring robust inferences with the default dynamic Hamiltonian Monte Carlo algorithm.\nView(HTML)\n\nAuthor\n\nMichael Betancourt\n\nKeywords\n\nMarkov chain Monte Carlo, Hamiltonian Monte Carlo, divergences, PyStan\n\nSource Repository\n\nbetanalpha/jupyter_case_studies/pystan_workflow (GitHub)\n\nPython Package Dependencies\n\nrstan, pystan, pickle, numpy, md5.\n\nLicense\n\nCode: BSD (3 clause), Text: CC BY-NC 4.0\n\n\n\n\nTypical Sets and the Curse of Dimensionality\nThis case study illustrates the so-called “curse of dimensionality” using simple examples based on simulation to show that all points are far away in high dimensions and that the mode is an atypical draw from a multivariate normal. The information-theoretic concept of typical set is illustrated with both discrete and continuous cases, which show that probability mass is a product of volume and density (or count and mass in the discrete case). It also illustrates Monte Carlo methods and relates distance to the log density of the normal distribution and the chi-squared distribution.\nView R version (HTML)\n\nAuthors\n\nBob Carpenter\n\nKeywords\n\nprobability mass, typical sets, concentration of measure, Monte Carlo methods\n\nSource Repository (R)\n\nstan-dev/example-models/knitr/curse-dims (GitHub)\n\nR Package Dependencies\n\nggplot2\n\nLicense\n\nCode: BSD (3 clause), Text: CC BY-NC 4.0\n\n\nView Python version (HTML)\n\nAuthor (Python translation)\n\nAravind S (Python translation)\n\nSource Repository (Python)\n\nAravinds-ds/Stan-Code/python notebooks/curse_dims (GitHub)\n\nPython Package Dependencies\n\nnumpy, scipy, pandas, matplotlib, collections, sys\n\nLicense\n\nCode: BSD (3 clause), Text: CC BY-NC 4.0\n\n\n\n\nDiagnosing Biased Inference with Divergences\nThis case study discusses the subtleties of accurate Markov chain Monte Carlo estimation and how divergences can be used to identify biased estimation in practice.\nView(HTML)\n\nAuthor\n\nMichael Betancourt\n\nKeywords\n\nMarkov chain Monte Carlo, Hamiltonian Monte Carlo, divergences, RStan\n\nSource Repository\n\nbetanalpha/knitr_case_studies/divergences_and_bias (GitHub)\n\nR Package Dependencies\n\nrstan, knitr.\n\nLicense\n\nCode: BSD (3 clause), Text: CC BY-NC 4.0\n\n\n\n\nIdentifying Bayesian Mixture Models\nThis case study discusses the common pathologies of Bayesian mixture models as well as some strategies for identifying and overcoming them.\nView(HTML)\n\nAuthor\n\nMichael Betancourt\n\nKeywords\n\nMarkov chain Monte Carlo, Hamiltonian Monte Carlo, mixture models, multimodal models, RStan\n\nSource Repository\n\nbetanalpha/knitr_case_studies/identifying_mixture_models (GitHub)\n\nR Package Dependencies\n\nrstan, knitr.\n\nLicense\n\nCode: BSD (3 clause), Text: CC BY-NC 4.0\n\n\n\n\nHow the Shape of a Weakly Informative Prior Affects Inferences\nThis case study reviews the basics of weakly-informative priors and how the choice of a specific shape of such a prior affects the resulting posterior distribution.\nView(HTML)\n\nAuthor\n\nMichael Betancourt\n\nKeywords\n\nMarkov chain Monte Carlo, Hamiltonian Monte Carlo, priors, weakly-informative priors, RStan\n\nSource Repository\n\nbetanalpha/knitr_case_studies/weakly_informative_shapes (GitHub)\n\nR Package Dependencies\n\nrstan, knitr.\n\nLicense\n\nCode: BSD (3 clause), Text: CC BY-NC 4.0"
  },
  {
    "objectID": "learn-stan/case-studies.html#volume-3-2016",
    "href": "learn-stan/case-studies.html#volume-3-2016",
    "title": "Stan Case Studies",
    "section": "Volume 3 (2016)",
    "text": "Volume 3 (2016)\n\nExact Sparse CAR Models in Stan\nThis document details sparse exact conditional autoregressive (CAR) models in Stan as an extension of previous work on approximate sparse CAR models in Stan. Sparse representations seem to give order of magnitude efficiency gains, scaling better for large spatial data sets.\nView(HTML)\n\nAuthor\n\nMax Joseph\n\nKeywords\n\nconditional autoregressive (CAR), independent autoregressive (IAR), sparsity, spatial random effects, maps\n\nSource Repository\n\nmbjoseph/CARstan(GitHub)\n\nR Package Dependencies\n\nrstan, dplyr, ggmcmc, knitr, maptools, rgeos, spdep.\n\nLicense\n\nBSD (3 clause), CC-BY\n\n\n\n\nA Primer on Bayesian Multilevel Modeling using PyStan\nThis case study replicates the analysis of home radon levels using hierarchical models of Lin, Gelman, Price, and Kurtz (1999). It illustrates how to generalize linear regressions to hierarchical models with group-level predictors and how to compare predictive inferences and evaluate model fits. Along the way it shows how to get data into Stan using pandas, how to sample using PyStan, and how to visualize the results using Seaborn.\nView(HTML)\n\nAuthor\n\nChris Fonnesbeck\n\nKeywords\n\nhierarchical/multilevel modeling, linear regression, model comparison, predictive inference, radon\n\nSource Repository\n\nfonnesbeck/stan_workshop_2016 (GitHub)\n\nPython Package Dependencies\n\npystan, numpy, pandas, matplotlib, seaborn\n\nLicense\n\nApache 2.0 (code), CC-BY 3 (text)\n\n\n\n\nThe Impact of Reparameterization on Point Estimates\nWhen changing variables, a Jacobian adjustment needs to be provided to account for the rate of change of the transform. Applying the adjustment ensures that inferences that are based on expectations over the posterior are invariant under reparameterizations. In contrast, the posterior mode changes as a result of the reparameterization. In this note, we use Stan to code a repeated binary trial model parameterized by chance of success, along with its reparameterization in terms of log odds in order to demonstrate the effect of the Jacobian adjustment on the Bayesian posterior and the posterior mode. We contrast the posterior mode to the maximum likelihood estimate, which, like the Bayesian estimates, is invariant under reparameterization. Along the way, we derive the logistic distribution by transforming a uniformly distributed variable.\nView(HTML)\n\nAuthor\n\nBob Carpenter\n\nKeywords\n\nMLE, Bayesian posterior, reparameterization, Jacobian, binomial\n\nSource Repository\n\nexample-models/knitr/mle-params (GitHub)\n\nR Package Dependencies\n\nrstan\n\nLicense\n\nBSD (3 clause), CC-BY\n\n\n\n\nHierarchical Two-Parameter Logistic Item Response Model\nThis case study documents a Stan model for the two-parameter logistic model (2PL) with hierarchical priors. A brief simulation indicates that the Stan model successfully recovers the generating parameters. An example using a grade 12 science assessment is provided.\nView(HTML)\n\nAuthor\n\nDaniel C. Furr\n\nKeywords\n\neducation, item response theory, two-parameter logistic model, hierarchical priors\n\nSource Repository\n\nexample-models/education/hierarchical_2pl (GitHub)\n\nR Package Dependencies\n\nrstan, ggplot2, mirt\n\nLicense\n\nBSD (3 clause), CC-BY\n\n\n\n\nRating Scale and Generalized Rating Scale Models with Latent Regression\nThis case study documents a Stan model for the rating scale model (RSM) and the generalized rating scale model (GRSM) with latent regression. The latent regression portion of the models may be restricted to an intercept only, yielding a standard RSM or GRSM. A brief simulation indicates that the Stan models successfully recover the generating parameters. An example using a survey of public perceptions of science and technology is provided.\nView(HTML)\n\nAuthors\n\nDaniel C. Furr\n\nKeywords\n\neducation, item response theory, rating scale model, generalized rating scale model\n\nSource Repository\n\nexample-models/education/rsm_and_grsm (GitHub)\n\nR Package Dependencies\n\nrstan, edstan, ggplot2, ltm\n\nLicense\n\nBSD (3 clause), CC-BY\n\n\n\n\nPartial Credit and Generalized Partial Credit Models with Latent Regression\nThis case study documents a Stan model for the partial credit model (PCM) and the generalized partial credit model (GPCM) with latent regression. The latent regression portion of the models may be restricted to an intercept only, yielding a standard PCM or GPCM. A brief simulation indicates that the Stan models successfully recover the generating parameters. An example using the TIMSS 2011 mathematics assessment is provided\nView(HTML)\n\nAuthors\n\nDaniel C. Furr\n\nKeywords\n\neducation, item response theory, partial credit model, generalized partial credit model\n\nSource Repository\n\nexample-models/education/pcm_and_gpcm (GitHub)\n\nR Package Dependencies\n\nrstan, edstan, ggplot2, TAM\n\nLicense\n\nBSD (3 clause), CC-BY\n\n\n\n\nRasch and Two-Parameter Logistic Item Response Models with Latent Regression\nThis case study documents Stan models for the Rasch and two-parameter logistic models with latent regression. The latent regression portion of the models may be restricted to an intercept only, yielding standard versions of the models. Simulations indicate that the two models successfully recover generating parameters. An example using a grade 12 science assessment is provided.\nView(HTML)\n\nAuthors\n\nDaniel C. Furr\n\nKeywords\n\neducation, item response theory, rasch model, two-parameter logistic model\n\nSource Repository\n\nexample-models/education/rasch_and_2pl.html (GitHub)\n\nR Package Dependencies\n\nrstan, edstan, ggplot2, TAM\n\nLicense\n\nBSD (3 clause), CC-BY\n\n\n\n\nTwo-Parameter Logistic Item Response Model\nThis tutorial introduces the R package edstan for estimating two-parameter logistic item response models using Stan without knowing the Stan language. Subsequently, the tutorial explains how the model can be expressed in the Stan language and fit using the rstan package. Specification of prior distributions and assessment of convergence are discussed. Using the Stan language directly has the advantage that it becomes quite easy to extend the model, and this is demonstrated by adding a latent regression and differential item functioning to the model. Posterior predictive model checking is also demonstrated.\nView(HTML)\n\nAuthor\n\nDaniel C. Furr, Seung Yeon Lee, Joon-Ho Lee, and Sophia Rabe-Hesketh\n\nKeywords\n\neducation, item response theory, two-parameter logistic model\n\nSource Repository\n\nexample-models/education/tutorial_twopl (GitHub)\n\nR Package Dependencies\n\nrstan, reshape2, ggplot2, gridExtra, devtools, edstan\n\nLicense\n\nBSD (3 clause), CC-BY\n\n\n\n\nCognitive Diagnosis Model: DINA model with independent attributes\nThis case study documents a Stan model for the DINA model with independent attributes. A Simulation indicates that the Stan model successfully recovers the generating parameters and predicts respondents’ attribute mastery. A Stan model with no structure of the attributes is also discussed and applied to the simulated data. An example using a subset of the fraction subtraction data is provided.\nView(HTML)\n\nAuthor\n\nSeung Yeon Lee\n\nKeywords\n\neducation, cognitive diagnosis model, diagnostic classification model, attribute mastery, DINA\n\nSource Repository\n\nexample-models/education/dina_independent (GitHub)\n\nR Package Dependencies\n\nrstan, ggplot2, CDM\n\nLicense\n\nBSD (3 clause), CC-BY\n\n\n\n\nPooling with Hierarchical Models for Repeated Binary Trials\nThis note illustrates the effects on posterior inference of pooling data (aka sharing strength) across items for repeated binary trial data. It provides Stan models and R code to fit and check predictive models for three situations: (a) complete pooling, which assumes each item is the same, (b) no pooling, which assumes the items are unrelated, and (c) partial pooling, where the similarity among the items is estimated. We consider two hierarchical models to estimate the partial pooling, one with a beta prior on chance of success and another with a normal prior on the log odds of success. The note explains with working examples how to (i) fit models in RStan and plot the results in R using ggplot2, (ii) estimate event probabilities, (iii) evaluate posterior predictive densities to evaluate model predictions on held-out data, (iv) rank items by chance of success, (v) perform multiple comparisons in several settings, (vi) replicate new data for posterior p-values, and (vii) perform graphical posterior predictive checks.\nView(HTML)\n\nAuthor\n\nBob Carpenter\n\nKeywords\n\nbinary trials, pooling, hierarchical models, baseball, epidemiology, prediction, posterior predictive checks\n\nSource Repository\n\nexample-models/knitr/pool-binary-trials (GitHub)\n\nR Package Dependencies\n\nrstan, ggplot2, rmarkdown\n\nLicense\n\nBSD (3 clause), CC-BY\n\n\n\nRStanARM version\nThere is also a version of this case study in which all models are fit using the RStanARM interface. Many of the visualizations are also created using RStanARM’s plotting functions.\nView RStanARM version(HTML)\n\nAuthor\n\nBob Carpenter, Jonah Gabry, Ben Goodrich"
  },
  {
    "objectID": "learn-stan/case-studies.html#volume-2-2015",
    "href": "learn-stan/case-studies.html#volume-2-2015",
    "title": "Stan Case Studies",
    "section": "Volume 2 (2015)",
    "text": "Volume 2 (2015)\n\nMultiple Species-Site Occupancy Model\nThis case study replicates the analysis and output graphs of Dorazio et al. (2006) noisy-measurement occupancy model for multiple species abundance of butterflies. Going beyond the paper, the supercommunity assumptions are tested to show they are invariant to sizing, and posterior predictive checks are provided.\nView(HTML)\n\nAuthor\n\nBob Carpenter\n\nKeywords\n\necology, occupancy, species abundance, supercommunity, posterior predictive check\n\nSource Repository\n\nexample-models/knitr/dorazio-royle-occupancy (GitHub)\n\nLicense\n\nBSD (3 clause), CC-BY\n\nR Package Dependencies\n\nrstan, ggplot2, rmarkdown"
  },
  {
    "objectID": "learn-stan/case-studies.html#volume-1-2014",
    "href": "learn-stan/case-studies.html#volume-1-2014",
    "title": "Stan Case Studies",
    "section": "Volume 1 (2014)",
    "text": "Volume 1 (2014)\n\nSoil Carbon Modeling with RStan\nThis case study provides ordinary differential equation-based compartment models of soil carbon flux, with experimental data fitted with unknown initial compartment balance and noisy CO2 measurements. Results form Sierra and Müller’s (2014) soilR package are replicated.\nView(HTML)\n\nAuthor\n\nBob Carpenter\n\nKeywords\n\nbiogeochemistry, compartment ODE, soil carbon respiration, incubation experiment\n\nSource Repository\n\nsoil-metamodel/stan/soil-knit (GitHub)\n\nLicense\n\nBSD (3 clause), CC-BY\n\nR Package Dependencies\n\nrstan, ggplot2, rmarkdown"
  },
  {
    "objectID": "learn-stan/case-studies.html#contributing-case-studies",
    "href": "learn-stan/case-studies.html#contributing-case-studies",
    "title": "Stan Case Studies",
    "section": "Contributing Case Studies",
    "text": "Contributing Case Studies\nTo contribute a case study, please contact us through the Stan Forums. We require\n\na documented, reproducible example with narrative documentation (e.g., knitr or Jupyter with software/compiler versions noted and seeds fixed) and\nan open-source code license (preferably BSD or GPL for code, Creative Commons for text); authors retain all copyright."
  },
  {
    "objectID": "learn-stan/publications.html",
    "href": "learn-stan/publications.html",
    "title": "Published Articles and Books",
    "section": "",
    "text": "Bob Carpenter, Andrew Gelman, Matthew D. Hoffman, Daniel Lee, Ben Goodrich, Michael Betancourt, Marcus Brubaker, Jiqiang Guo, Peter Li, and Allen Riddell. 2017. Stan: A probabilistic programming language. Journal of Statistical Software 76(1).\nAndrew Gelman, Daniel Lee, and Jiqiang Guo. 2015. Stan: A probabilistic programming language for Bayesian inference and optimization. Journal of Education and Behavioral Statistics. 40(5):530–543.\nAlp Kucukelbir, Rajesh Ranganath, Andrew Gelman and David M. Blei. 2015. Automatic variational inference in Stan\nLu Zhang, Bob Carpenter, Andrew Gelman, Aki Vehtari. 2022. Pathfinder: Parallel quasi-Newton variational inference Journal of Machine Learning Research. 23(306):1−49, 2022.\nMichael Betancourt. 2017. A Conceptual Introduction to Hamiltonian Monte Carlo. arXiv:1701.02434.\nMatthew D. Hoffman, Andrew Gelman. 2014. The No-U-Turn Sampler: Adaptively Setting Path Lengths in Hamiltonian Monte Carlo. Journal of Machine Learning Research. 15(47):1593−1623.\nCole C. Monnahan, James T. Thorson, and Trevor A. Branch. 2017. Faster estimation of Bayesian models in ecology using Hamiltonian Monte Carlo. Methods in Ecology and Evolution. 8(3):339-348.\nRadford Neal. 2011. MCMC Using Hamiltonian Dynamics. In Handbook of Markov Chain Monte Carlo, edited by Steve Brooks, Andrew Gelman, Galin L. Jones, and Xiao-Li Meng. Chapman-Hall/CRC.\nBob Carpenter, Matthew D. Hoffman, Marcus Brubaker, Daniel Lee, Peter Li, and Michael J. Betancourt. 2015. The Stan Math Library: Reverse-Mode Automatic Differentiation in C++.   arXiv 1509.07164."
  },
  {
    "objectID": "learn-stan/publications.html#stan-language-and-algorithms",
    "href": "learn-stan/publications.html#stan-language-and-algorithms",
    "title": "Published Articles and Books",
    "section": "",
    "text": "Bob Carpenter, Andrew Gelman, Matthew D. Hoffman, Daniel Lee, Ben Goodrich, Michael Betancourt, Marcus Brubaker, Jiqiang Guo, Peter Li, and Allen Riddell. 2017. Stan: A probabilistic programming language. Journal of Statistical Software 76(1).\nAndrew Gelman, Daniel Lee, and Jiqiang Guo. 2015. Stan: A probabilistic programming language for Bayesian inference and optimization. Journal of Education and Behavioral Statistics. 40(5):530–543.\nAlp Kucukelbir, Rajesh Ranganath, Andrew Gelman and David M. Blei. 2015. Automatic variational inference in Stan\nLu Zhang, Bob Carpenter, Andrew Gelman, Aki Vehtari. 2022. Pathfinder: Parallel quasi-Newton variational inference Journal of Machine Learning Research. 23(306):1−49, 2022.\nMichael Betancourt. 2017. A Conceptual Introduction to Hamiltonian Monte Carlo. arXiv:1701.02434.\nMatthew D. Hoffman, Andrew Gelman. 2014. The No-U-Turn Sampler: Adaptively Setting Path Lengths in Hamiltonian Monte Carlo. Journal of Machine Learning Research. 15(47):1593−1623.\nCole C. Monnahan, James T. Thorson, and Trevor A. Branch. 2017. Faster estimation of Bayesian models in ecology using Hamiltonian Monte Carlo. Methods in Ecology and Evolution. 8(3):339-348.\nRadford Neal. 2011. MCMC Using Hamiltonian Dynamics. In Handbook of Markov Chain Monte Carlo, edited by Steve Brooks, Andrew Gelman, Galin L. Jones, and Xiao-Li Meng. Chapman-Hall/CRC.\nBob Carpenter, Matthew D. Hoffman, Marcus Brubaker, Daniel Lee, Peter Li, and Michael J. Betancourt. 2015. The Stan Math Library: Reverse-Mode Automatic Differentiation in C++.   arXiv 1509.07164."
  },
  {
    "objectID": "learn-stan/publications.html#bayesian-workflow",
    "href": "learn-stan/publications.html#bayesian-workflow",
    "title": "Published Articles and Books",
    "section": "Bayesian Workflow",
    "text": "Bayesian Workflow\n\nAndrew Gelman, Aki Vehtari, Daniel Simpson, Charles C. Margossian, Bob Carpenter, Yuling Yao, Lauren Kennedy, Jonah Gabry, Paul-Christian Bürkner, Martin Modrák. 2020. Bayesian Workflow\nAki Vehtari, Andrew Gelman, Daniel Simpson, Bob Carpenter, Paul-Christian Bürkner, 2021. Rank-Normalization, Folding, and Localization: An Improved R-hat for Assessing Convergence of MCMC (with Discussion) Bayesian Analysis 16(2).\nAki Vehtari, Andrew Gelman, and Jonah Gabry. 2016. Practical Bayesian model evaluation using leave-one-out cross-validation and WAIC. Statistics and Computing. doi:10.1007/s11222-016-9696-4.\nJonah Gabry, Daniel Simpson, Aki Vehtari, Michael Betancourt, Andrew Gelman. 2019 Visualization in Bayesian workflow. Journal of the Royal Statistical Society Series A: Statistics in Society 182(2):389–402.\nRobert L. Grant, Daniel C. Furr, Bob Carpenter, and Andrew Gelman. 2016. Fitting Bayesian item response models in Stata and Stan. arXiv 1601.03443."
  },
  {
    "objectID": "learn-stan/publications.html#books-using-stan",
    "href": "learn-stan/publications.html#books-using-stan",
    "title": "Published Articles and Books",
    "section": "Books using Stan",
    "text": "Books using Stan\n\nGelman, A., Hill, J., and Vehtari A. 2020. Regression and Other Stories\nGelman, A. and Vehtari A. 2024. Active Statistics\nKorner-Nievergelt, F., Roth, T., Von Felten, S., Guélat, J., Almasi, B. and Korner-Nievergelt, P. 2024. Bayesian Data Analysis in Ecology Using Linear Models with R and Stan. Online.\nSuzuki, J. 2023. WAIC and WBIC with R Stan: 100 Exercises for Building Logic. Springer.\nMatsuura, K.. 2022. Bayesian Statistical Modeling with Stan, R, and Python. Springer.\nJohnson, A.A., M. Q. Ott, M. Dogucu. 2021. Bayes Rules! An Introduction to Applied Bayesian Modeling CRC Press.\nHolmes, E. E., M. D. Scheuerell, and E. J. Ward. 2019. Applied Time Series Analysis for Fisheries and Environmental Sciences. NOAA Fisheries, Northwest Fisheries Science Center.\nHilbe, J. M., R.S. de Souza, and E. E. O. Ishida. 2017. Bayesian Models for Astrophysical Data Using R, JAGS, Python and Stan. Cambridge University Press.\nMatsuura, K.. 2016. Bayesian Statistical Modeling Using Stan and R. Wonderful R Series, Volume 2. Kyoritsu Shuppan Co., Ltd. [in Japanese]\nMcElreath, R. 2016. Statistical Rethinking: A Bayesian Course with R and Stan. Chapman-Hall/CRC.\nKorner-Nievergelt, F., Roth, T., Von Felten, S., Guélat, J., Almasi, B. and Korner-Nievergelt, P. 2015. Bayesian Data Analysis in Ecology Using Linear Models with R, BUGS, and Stan. Academic Press.\nKruschke, J. 2014. Doing Bayesian Data Analysis: A Tutorial with R, JAGS, and Stan. Academic Press.\nGelman, A., Carlin, J.B., Stern, H.S., Dunson, D.B., Vehtari, A. and Rubin, D.B. 2013. Bayesian Data Analysis, Third Edition. Chapman-Hall/CRC."
  },
  {
    "objectID": "learn-stan/tutorials.html",
    "href": "learn-stan/tutorials.html",
    "title": "Stan",
    "section": "",
    "text": "Getting Started with Bayesian Statistics using Stan and Python  Bob Carpenter\nFundamentals of Stan  Charles Margossian StanCon 2023 tutorial, includes slides, models, and a Google colab notebook for R users."
  },
  {
    "objectID": "learn-stan/tutorials.html#tutorials",
    "href": "learn-stan/tutorials.html#tutorials",
    "title": "Stan",
    "section": "",
    "text": "Getting Started with Bayesian Statistics using Stan and Python  Bob Carpenter\nFundamentals of Stan  Charles Margossian StanCon 2023 tutorial, includes slides, models, and a Google colab notebook for R users."
  },
  {
    "objectID": "learn-stan/tutorials.html#videos",
    "href": "learn-stan/tutorials.html#videos",
    "title": "Stan",
    "section": "Videos",
    "text": "Videos\nThe official Stan YouTube channel is: https://www.youtube.com/channel/UCwgN5srGpBH4M-Zc2cAluOA\n\nIntroductory Videos\n\nStan Tutorials   Maggie Lieu. A series of 8 videos that will get you started using Stan in R and Python.\n\n\n\nContributed Videos\n\nStatistical Rethinking Winter 2019 Lecture 15   Richard McElreath.\nHow to write your first Stan program   Ben Lambert.\nBayesian Modeling with R and Stan   Sean Raleigh for the R Users Group, Salt Lake City, UT.\nbrms: Bayesian Multilevel Models using Stan   Paul-Christian Bürkner."
  },
  {
    "objectID": "learn-stan/tutorials.html#podcasts",
    "href": "learn-stan/tutorials.html#podcasts",
    "title": "Stan",
    "section": "Podcasts",
    "text": "Podcasts\n\nLearning Bayesian Statistics   Alexandre Andorra. A fortnightly podcast on Bayesian inference - the methods, the projects, and the people who make it possible!\nBayesian Statistics   John Krohn and Rob Trangucci. An intro to Bayesian statistics - its history, tools you can use, plus a discussion of the uses of a PhD in statistics."
  },
  {
    "objectID": "learn-stan/stancon/StanCon2020-program.html",
    "href": "learn-stan/stancon/StanCon2020-program.html",
    "title": "StanCon 2020. A 24h Global Event.",
    "section": "",
    "text": "StanCon Thursday, 13 August 2020.\nThe conference was a 24-hour event with three main sessions spanning across different time zones (British Summer Time, Eastern Time and Pacific Time).\n\n\nThe sessions were recorded and uploaded to YouTube. The plenary talks and the discussions can be found in the recording for the live sessions.\nThe abstracts to the talks are included in the video descriptions.\n\n\nPlaylists: - Session 1 - Session 2 - Session 3 - All videos\n\n\n\n\n\n\nBST\nEST\nPT\n\n\n\n\n\n\n\n\n\n\n\n08:30\n03:30\n00:30\nVirtual coffee\n\n\n09:00\n04:00\n01:00\nLive welcome from StanCon UK Committee\n\n\n09:04\n04:04\n01:04\n6 x 1 minute pitches\n\n\n09:10\n04:10\n01:10\nPlenary: Hierarchical Models for Covid -\n\n\n\n\n\nidentifying effects of lockdown and an R package,\n\n\n\n\n\nSeth Flaxman, Imperial College, London\n\n\n\n\n\nvideo\n\n\n09:50\n04:50\n01:50\nDiscussion\n\n\n10:00\n05:00\n02:00\n6 x 1 minute pitches, followed by 9 minute discussions:\n\n\n10:06\n05:06\n02:06\nHierarchical Bayes and logistic growth: Predicting diagnosed\n\n\n\n\n\nCOVID19 cases and the corresponding burden on health care\n\n\n\n\n\nsystems, Brynjólfur Gauti Jónsson, Birgir Hrafnkelsson,\n\n\n\n\n\nJón Magnús Jónsson, Jóhanna Jakobsdóttir,\n\n\n\n\n\nBergdís Björg Sigurjónsdóttir,Þórarinn Jónmundsson,\n\n\n\n\n\nSigríður Haraldsdóttir, Unnur A. Valdimarsdóttir,\n\n\n\n\n\nThor Aspelund, Directorate of Health (Iceland),\n\n\n\n\n\nCenter of Public Health Sciences (University of Iceland),\n\n\n\n\n\nDepartment of Mathematics (University of Iceland),\n\n\n\n\n\nIcelandic Heart Association, National University Hospital of Iceland\n\n\n\n\n\nvideo\n\n\n10:15\n05:15\n02:15\nProcess fault detection using Stan, Jerzy Baranowski,\n\n\n\n\n\nWaldemar Bauer, Rafał Mularczyk, Bartłomiej Gondek,\n\n\n\n\n\nAGH University of Science & Technology, Kraków, Poland\n\n\n\n\n\nvideo\n\n\n10:24\n05:24\n02:24\nFailure prediction in hierarchical equipment system:\n\n\n\n\n\nspline fitting naval ship failure, Hyunji Moon, Jinwoo Choi,\n\n\n\n\n\nHyeonseop Lee, Seoul National University\n\n\n\n\n\nvideo\n\n\n10:33\n05:33\n02:33\nbaggr: a new meta-analysis package using Stan,\n\n\n\n\n\nWitold Wiecek and Rachael Meager, London School of Economics\n\n\n\n\n\nvideo\n\n\n10:42\n05:42\n02:42\nTowards an Interface for Streaming Stan,\n\n\n\n\n\nSimon Maskell and Alessandro Varsi, University of Liverpool\n\n\n\n\n\nvideo\n\n\n10:51\n05:51\n02:51\nEnforcing stationarity through the prior in vector autoregressions,\n\n\n\n\n\nSarah Heaps, Newcastle University\n\n\n\n\n\nvideo\n\n\n11:00\n06:00\n03:00\nVirtual coffee and poster session\n\n\n13:30\n08:30\n05:30\nEnd of session\n\n\n\n\n\n\n\n\n\nBST\nEST\nPT\n\n\n\n\n\n16:30\n11:30\n08:30\nVirtual coffee\n\n\n17:00\n12:00\n09:00\nLive welcome from StanCon UK + US Committee\n\n\n17:10\n12:10\n09:10\nCode of Conduct working group, Steve Bronder and Lauren Kennedy\n\n\n\n\n\nvideo\n\n\n17:14\n12:14\n09:14\nStan Governing Body update, Jonah Gabry\n\n\n\n\n\nvideo\n\n\n17:20\n12:20\n09:20\n6 x 1 minute pitches\n\n\n17:32\n12:32\n09:32\nDeveloper talk 1: posteriordb: a database with data, models and\n\n\n\n\n\nposteriors, Aki Vehtari, Måns Magnusson, Aalto University\n\n\n\n\n\nvideo\n\n\n17:39\n12:39\n09:39\nDeveloper talk 2: Scaling Stan’s performance with reduce_sum in practice,\n\n\n\n\n\nSebastian Weber, Ben Bales, Steve Bronder, Mitzi Morris,\n\n\n\n\n\nRok Češnovar, Imperial College of London COVID-19 team,\n\n\n\n\n\nNovartis Pharma AG, Basel, Switzerland, Columbia University,\n\n\n\n\n\nUniversity of Ljubljana\n\n\n\n\n\nvideo\n\n\n17:46\n12:46\n09:46\nDeveloper talk 3: The State of GPU Computation Support for Stan,\n\n\n\n\n\nSteve Bronder, Erik Štrumbelj, Rok Češnovar, Davor Sluga,\n\n\n\n\n\nJure Demšar, Tadej Ciglarič, Sean Talts, Columbia University,\n\n\n\n\n\nUniversity of Ljubljana\n\n\n\n\n\nvideo\n\n\n17:53\n12:53\n09:53\nDeveloper talk 4: Approximate Bayesian inference for latent Gaussian\n\n\n\n\n\nmodels in Stan, Charles Margossian, Aki Vehtari, Daniel Simpson,\n\n\n\n\n\nRaj Agrawal, Columbia University, Department of Statistics;\n\n\n\n\n\nAalto University, Department of Computer Science;\n\n\n\n\n\nUniversity of Toronto, Department of Statistical Sciences;\n\n\n\n\n\nMassachusetts Institute of Technology, CSAIL\n\n\n\n\n\nvideo, code and notebook\n\n\n18:00\n13:00\n10:00\nPlenary: Multi-Source Information Modeling, Curation, and\n\n\n\n\n\nFusion Enabling Transdisciplinary Decision-Making: A Case for Space!\n\n\n\n\n\nMoriba Jah, Oden Institute for Computational Engineering & Sciences\n\n\n\n\n\nvideo\n\n\n18:50\n13:50\n10:50\nDiscussion\n\n\n19:00\n14:00\n11:00\n6 x 1 minute pitches, followed by 9 minute discussions\n\n\n19:06\n14:06\n11:06\nUsing Stan for Spatial Smoothing of Regression Parameters,\n\n\n\n\n\nWade Brorsen, Bart Niyizibi, Davood Pourvina, Eunchun Park,\n\n\n\n\n\nOklahoma State University\n\n\n\n\n\nvideo\n\n\n19:15\n14:15\n11:15\nMultivariate Synthetic Control to Estimate Missing Data in\n\n\n\n\n\nHierarchically Correlated Series, Sean Pinkney, Tyler Morrison,\n\n\n\n\n\nGaurav Shahane, Comscore, Inc.\n\n\n\n\n\nvideo\n\n\n19:24\n14:24\n11:24\nBayesian Causal Effect Estimation with Stan: Parametric and\n\n\n\n\n\nNonparametric Approaches, Arman Oganisian, Jason A. Roy,\n\n\n\n\n\nUniversity of Pennsylvania\n\n\n\n\n\nvideo\n\n\n19:33\n14:33\n11:33\nBuilding effective uncertainty visualizations with Stan/brms,\n\n\n\n\n\ntidybayes, and ggdist, Matthew Kay, University of Michigan\n\n\n\n\n\nvideo\n\n\n19:42\n14:42\n11:42\nAPI for iterative interrogation of stanfit objects in R,\n\n\n\n\n\nJonathan Sidi, Associate Director of Modeling and Simulation at\n\n\n\n\n\nSage Therapeutics\n\n\n\n\n\nvideo\n\n\n19:51\n14:51\n11:51\nBayesian Inference without Probability Density Functions,\n\n\n\n\n\nBen Goodrich, Columbia University\n\n\n\n\n\nvideo\n\n\n20:00\n15:00\n12:00\nVirtual coffee and poster session\n\n\n21:30\n16:30\n13:30\nEnd of session\n\n\n\n\n\n\n\n\n\nBST\nEST\nPT\n\n\n\n\n\n00:30\n19:30\n16:30\nVirtual coffee\n\n\n01:00\n20:00\n17:00\nLive welcome from StanCon Committee\n\n\n01:04\n20:04\n17:04\n6 x 1 minute pitches\n\n\n01:10\n20:10\n17:10\nPlenary: STAN and US Politics, David Shor\n\n\n\n\n\nvideo\n\n\n01:50\n20:50\n17:50\nDiscussion\n\n\n02:00\n21:00\n18:00\n6 x 1 minute pitches, followed by 9 minute discussions:\n\n\n02:06\n21:06\n18:06\nSpatial models for plant neighborhood dynamics in Stan,\n\n\n\n\n\nCristina Barber, Andrii Zaiats, Cara Applestein, Trevor Caughlin,\n\n\n\n\n\nBoise State University\n\n\n\n\n\nvideo\n\n\n02:15\n21:15\n18:15\n​Stress-testing the Dawid–Skene model: Analysis of repeated\n\n\n\n\n\ncategorical ratings, Damjan Vukcevic, Jeffrey Pullin, Lyle Gurrin,\n\n\n\n\n\nUniversity of Melbourne\n\n\n\n\n\nvideo\n\n\n02:24\n21:24\n18:24\nArviZ, InferenceData, and NetCDF: A unified file format for Bayesians,\n\n\n\n\n\nRavin Kumar, Oriol Abril-Pla, Osvaldo Martin, Piyush Gautam,\n\n\n\n\n\nAri Hartikainen , Alexandre Andorra, ArviZ (all)\n\n\n\n\n\nvideo (English)\n\n\n\n\n\nvideo (Catalan)\n\n\n\n\n\nvideo (French)\n\n\n\n\n\nvideo (Finnish)\n\n\n​02:33\n21:33\n18:33\nOrbit: Probabilistic Forecast with Exponential Smoothing,\n\n\n\n\n\nEdwin Ng, Zhishi Wang, Steve Yang, Uber\n\n\n\n\n\nvideo\n\n\n02:42\n21:42\n18:42\nEffortless frequentist covariances of posterior expectations in Stan,\n\n\n\n\n\nRyan Giordano, Tamara Brodercik, MIT\n\n\n\n\n\nvideo\n\n\n02:51\n21:51\n18:51\nVirtual coffee and poster session\n\n\n05:30\n00:30\n21:30\nEnd of session\n\n\n\n\n\n\n\n\n\n\n\n\nWe can’t do this without the support of generous sponsors!\nOrganizers:\n\nSusana Marquez. The Rockefeller Foundation.\nDaniel Lee. Generable.\nKelli Cassidy. The University of Liverpool.\nSimon Maskell. The University of Liverpool."
  },
  {
    "objectID": "learn-stan/stancon/StanCon2020-program.html#program",
    "href": "learn-stan/stancon/StanCon2020-program.html#program",
    "title": "StanCon 2020. A 24h Global Event.",
    "section": "",
    "text": "The sessions were recorded and uploaded to YouTube. The plenary talks and the discussions can be found in the recording for the live sessions.\nThe abstracts to the talks are included in the video descriptions.\n\n\nPlaylists: - Session 1 - Session 2 - Session 3 - All videos\n\n\n\n\n\n\nBST\nEST\nPT\n\n\n\n\n\n\n\n\n\n\n\n08:30\n03:30\n00:30\nVirtual coffee\n\n\n09:00\n04:00\n01:00\nLive welcome from StanCon UK Committee\n\n\n09:04\n04:04\n01:04\n6 x 1 minute pitches\n\n\n09:10\n04:10\n01:10\nPlenary: Hierarchical Models for Covid -\n\n\n\n\n\nidentifying effects of lockdown and an R package,\n\n\n\n\n\nSeth Flaxman, Imperial College, London\n\n\n\n\n\nvideo\n\n\n09:50\n04:50\n01:50\nDiscussion\n\n\n10:00\n05:00\n02:00\n6 x 1 minute pitches, followed by 9 minute discussions:\n\n\n10:06\n05:06\n02:06\nHierarchical Bayes and logistic growth: Predicting diagnosed\n\n\n\n\n\nCOVID19 cases and the corresponding burden on health care\n\n\n\n\n\nsystems, Brynjólfur Gauti Jónsson, Birgir Hrafnkelsson,\n\n\n\n\n\nJón Magnús Jónsson, Jóhanna Jakobsdóttir,\n\n\n\n\n\nBergdís Björg Sigurjónsdóttir,Þórarinn Jónmundsson,\n\n\n\n\n\nSigríður Haraldsdóttir, Unnur A. Valdimarsdóttir,\n\n\n\n\n\nThor Aspelund, Directorate of Health (Iceland),\n\n\n\n\n\nCenter of Public Health Sciences (University of Iceland),\n\n\n\n\n\nDepartment of Mathematics (University of Iceland),\n\n\n\n\n\nIcelandic Heart Association, National University Hospital of Iceland\n\n\n\n\n\nvideo\n\n\n10:15\n05:15\n02:15\nProcess fault detection using Stan, Jerzy Baranowski,\n\n\n\n\n\nWaldemar Bauer, Rafał Mularczyk, Bartłomiej Gondek,\n\n\n\n\n\nAGH University of Science & Technology, Kraków, Poland\n\n\n\n\n\nvideo\n\n\n10:24\n05:24\n02:24\nFailure prediction in hierarchical equipment system:\n\n\n\n\n\nspline fitting naval ship failure, Hyunji Moon, Jinwoo Choi,\n\n\n\n\n\nHyeonseop Lee, Seoul National University\n\n\n\n\n\nvideo\n\n\n10:33\n05:33\n02:33\nbaggr: a new meta-analysis package using Stan,\n\n\n\n\n\nWitold Wiecek and Rachael Meager, London School of Economics\n\n\n\n\n\nvideo\n\n\n10:42\n05:42\n02:42\nTowards an Interface for Streaming Stan,\n\n\n\n\n\nSimon Maskell and Alessandro Varsi, University of Liverpool\n\n\n\n\n\nvideo\n\n\n10:51\n05:51\n02:51\nEnforcing stationarity through the prior in vector autoregressions,\n\n\n\n\n\nSarah Heaps, Newcastle University\n\n\n\n\n\nvideo\n\n\n11:00\n06:00\n03:00\nVirtual coffee and poster session\n\n\n13:30\n08:30\n05:30\nEnd of session\n\n\n\n\n\n\n\n\n\nBST\nEST\nPT\n\n\n\n\n\n16:30\n11:30\n08:30\nVirtual coffee\n\n\n17:00\n12:00\n09:00\nLive welcome from StanCon UK + US Committee\n\n\n17:10\n12:10\n09:10\nCode of Conduct working group, Steve Bronder and Lauren Kennedy\n\n\n\n\n\nvideo\n\n\n17:14\n12:14\n09:14\nStan Governing Body update, Jonah Gabry\n\n\n\n\n\nvideo\n\n\n17:20\n12:20\n09:20\n6 x 1 minute pitches\n\n\n17:32\n12:32\n09:32\nDeveloper talk 1: posteriordb: a database with data, models and\n\n\n\n\n\nposteriors, Aki Vehtari, Måns Magnusson, Aalto University\n\n\n\n\n\nvideo\n\n\n17:39\n12:39\n09:39\nDeveloper talk 2: Scaling Stan’s performance with reduce_sum in practice,\n\n\n\n\n\nSebastian Weber, Ben Bales, Steve Bronder, Mitzi Morris,\n\n\n\n\n\nRok Češnovar, Imperial College of London COVID-19 team,\n\n\n\n\n\nNovartis Pharma AG, Basel, Switzerland, Columbia University,\n\n\n\n\n\nUniversity of Ljubljana\n\n\n\n\n\nvideo\n\n\n17:46\n12:46\n09:46\nDeveloper talk 3: The State of GPU Computation Support for Stan,\n\n\n\n\n\nSteve Bronder, Erik Štrumbelj, Rok Češnovar, Davor Sluga,\n\n\n\n\n\nJure Demšar, Tadej Ciglarič, Sean Talts, Columbia University,\n\n\n\n\n\nUniversity of Ljubljana\n\n\n\n\n\nvideo\n\n\n17:53\n12:53\n09:53\nDeveloper talk 4: Approximate Bayesian inference for latent Gaussian\n\n\n\n\n\nmodels in Stan, Charles Margossian, Aki Vehtari, Daniel Simpson,\n\n\n\n\n\nRaj Agrawal, Columbia University, Department of Statistics;\n\n\n\n\n\nAalto University, Department of Computer Science;\n\n\n\n\n\nUniversity of Toronto, Department of Statistical Sciences;\n\n\n\n\n\nMassachusetts Institute of Technology, CSAIL\n\n\n\n\n\nvideo, code and notebook\n\n\n18:00\n13:00\n10:00\nPlenary: Multi-Source Information Modeling, Curation, and\n\n\n\n\n\nFusion Enabling Transdisciplinary Decision-Making: A Case for Space!\n\n\n\n\n\nMoriba Jah, Oden Institute for Computational Engineering & Sciences\n\n\n\n\n\nvideo\n\n\n18:50\n13:50\n10:50\nDiscussion\n\n\n19:00\n14:00\n11:00\n6 x 1 minute pitches, followed by 9 minute discussions\n\n\n19:06\n14:06\n11:06\nUsing Stan for Spatial Smoothing of Regression Parameters,\n\n\n\n\n\nWade Brorsen, Bart Niyizibi, Davood Pourvina, Eunchun Park,\n\n\n\n\n\nOklahoma State University\n\n\n\n\n\nvideo\n\n\n19:15\n14:15\n11:15\nMultivariate Synthetic Control to Estimate Missing Data in\n\n\n\n\n\nHierarchically Correlated Series, Sean Pinkney, Tyler Morrison,\n\n\n\n\n\nGaurav Shahane, Comscore, Inc.\n\n\n\n\n\nvideo\n\n\n19:24\n14:24\n11:24\nBayesian Causal Effect Estimation with Stan: Parametric and\n\n\n\n\n\nNonparametric Approaches, Arman Oganisian, Jason A. Roy,\n\n\n\n\n\nUniversity of Pennsylvania\n\n\n\n\n\nvideo\n\n\n19:33\n14:33\n11:33\nBuilding effective uncertainty visualizations with Stan/brms,\n\n\n\n\n\ntidybayes, and ggdist, Matthew Kay, University of Michigan\n\n\n\n\n\nvideo\n\n\n19:42\n14:42\n11:42\nAPI for iterative interrogation of stanfit objects in R,\n\n\n\n\n\nJonathan Sidi, Associate Director of Modeling and Simulation at\n\n\n\n\n\nSage Therapeutics\n\n\n\n\n\nvideo\n\n\n19:51\n14:51\n11:51\nBayesian Inference without Probability Density Functions,\n\n\n\n\n\nBen Goodrich, Columbia University\n\n\n\n\n\nvideo\n\n\n20:00\n15:00\n12:00\nVirtual coffee and poster session\n\n\n21:30\n16:30\n13:30\nEnd of session\n\n\n\n\n\n\n\n\n\nBST\nEST\nPT\n\n\n\n\n\n00:30\n19:30\n16:30\nVirtual coffee\n\n\n01:00\n20:00\n17:00\nLive welcome from StanCon Committee\n\n\n01:04\n20:04\n17:04\n6 x 1 minute pitches\n\n\n01:10\n20:10\n17:10\nPlenary: STAN and US Politics, David Shor\n\n\n\n\n\nvideo\n\n\n01:50\n20:50\n17:50\nDiscussion\n\n\n02:00\n21:00\n18:00\n6 x 1 minute pitches, followed by 9 minute discussions:\n\n\n02:06\n21:06\n18:06\nSpatial models for plant neighborhood dynamics in Stan,\n\n\n\n\n\nCristina Barber, Andrii Zaiats, Cara Applestein, Trevor Caughlin,\n\n\n\n\n\nBoise State University\n\n\n\n\n\nvideo\n\n\n02:15\n21:15\n18:15\n​Stress-testing the Dawid–Skene model: Analysis of repeated\n\n\n\n\n\ncategorical ratings, Damjan Vukcevic, Jeffrey Pullin, Lyle Gurrin,\n\n\n\n\n\nUniversity of Melbourne\n\n\n\n\n\nvideo\n\n\n02:24\n21:24\n18:24\nArviZ, InferenceData, and NetCDF: A unified file format for Bayesians,\n\n\n\n\n\nRavin Kumar, Oriol Abril-Pla, Osvaldo Martin, Piyush Gautam,\n\n\n\n\n\nAri Hartikainen , Alexandre Andorra, ArviZ (all)\n\n\n\n\n\nvideo (English)\n\n\n\n\n\nvideo (Catalan)\n\n\n\n\n\nvideo (French)\n\n\n\n\n\nvideo (Finnish)\n\n\n​02:33\n21:33\n18:33\nOrbit: Probabilistic Forecast with Exponential Smoothing,\n\n\n\n\n\nEdwin Ng, Zhishi Wang, Steve Yang, Uber\n\n\n\n\n\nvideo\n\n\n02:42\n21:42\n18:42\nEffortless frequentist covariances of posterior expectations in Stan,\n\n\n\n\n\nRyan Giordano, Tamara Brodercik, MIT\n\n\n\n\n\nvideo\n\n\n02:51\n21:51\n18:51\nVirtual coffee and poster session\n\n\n05:30\n00:30\n21:30\nEnd of session"
  },
  {
    "objectID": "learn-stan/stancon/StanCon2020-program.html#sponsors",
    "href": "learn-stan/stancon/StanCon2020-program.html#sponsors",
    "title": "StanCon 2020. A 24h Global Event.",
    "section": "",
    "text": "We can’t do this without the support of generous sponsors!\nOrganizers:\n\nSusana Marquez. The Rockefeller Foundation.\nDaniel Lee. Generable.\nKelli Cassidy. The University of Liverpool.\nSimon Maskell. The University of Liverpool."
  },
  {
    "objectID": "mc-stan-org/about.html",
    "href": "mc-stan-org/about.html",
    "title": "About the Stan Project",
    "section": "",
    "text": "Stan is freedom-respecting, open-source software (new BSD core, some interfaces GPLv3).  Stan is associated with NumFOCUS, a 501(c)(3) nonprofit supporting open code and reproducible science, through which you can help support Stan.\n\n\nStan has grown from a small research project started in 2011 at Columbia University to a global community of developers, researchers, and users. The Stan project owes its success to the contributions from hundreds of developers, researchers, active users, and funders. Individual contributions to the software and documentation can be tracked through GitHub.\nStan has been funded through grants for Stan and its developers, through in-kind donations in the form of companies contributing developer time to Stan and individuals contributing their own time to Stan, and through donations to the open-source scientific software non-profit NumFOCUS.\nWe are grateful to all the users who have taken the time to file bug reports and feature requests via the GitHub and the Stan forums; this feedback has greatly improved Stan’s usability and reliability."
  },
  {
    "objectID": "mc-stan-org/about.html#open-code-reproducible-science",
    "href": "mc-stan-org/about.html#open-code-reproducible-science",
    "title": "About the Stan Project",
    "section": "",
    "text": "Stan is freedom-respecting, open-source software (new BSD core, some interfaces GPLv3).  Stan is associated with NumFOCUS, a 501(c)(3) nonprofit supporting open code and reproducible science, through which you can help support Stan.\n\n\nStan has grown from a small research project started in 2011 at Columbia University to a global community of developers, researchers, and users. The Stan project owes its success to the contributions from hundreds of developers, researchers, active users, and funders. Individual contributions to the software and documentation can be tracked through GitHub.\nStan has been funded through grants for Stan and its developers, through in-kind donations in the form of companies contributing developer time to Stan and individuals contributing their own time to Stan, and through donations to the open-source scientific software non-profit NumFOCUS.\nWe are grateful to all the users who have taken the time to file bug reports and feature requests via the GitHub and the Stan forums; this feedback has greatly improved Stan’s usability and reliability."
  },
  {
    "objectID": "mc-stan-org/about.html#stan-user-and-developer-forums",
    "href": "mc-stan-org/about.html#stan-user-and-developer-forums",
    "title": "About the Stan Project",
    "section": "Stan User and Developer Forums",
    "text": "Stan User and Developer Forums\n\nStan forums - message board for questions, discussion, and announcements related to Stan for both users and developers.\nStan slack - developer discussions\nGitHub issues - report bugs"
  },
  {
    "objectID": "mc-stan-org/about.html#licensing",
    "href": "mc-stan-org/about.html#licensing",
    "title": "About the Stan Project",
    "section": "Licensing",
    "text": "Licensing\n\nText content: CC-BY ND 4.0 license\nComputer code: BSD 3-clause license\n\n\nCopyright and trademark\n\nCopyright 2011–2024, Stan Development Team and their assignees.\nThe Stan name and logo are registered trademarks of NumFOCUS.\n\n\n\nUsing the Stan Logo\nThe Stan name and logo are registered trademarks of NumFOCUS under the direction of the Stan Governing Body.\nBoth may be freely used when referencing Stan, for example, in blog posts, lecture notes, or open source software packages, but they may not be used in the branding of commercial entities, such as paid software packages or paid courses, without the express license of the Stan Governing Body. If you have any questions or would like to inquire about licensing the Stan name and/or logo for a commercial venture then please contact NumFOCUS at mailto:admin@numfocus.org.\nThe Stan name and Stan logo may not be used in ways that suggest the usage is endorsed by the Stan project without written permission from the Stan Governing Body.\nWhen using the Stan logo please use one of the following:\n\nStan Logo png\nStan Logo svg"
  },
  {
    "objectID": "mc-stan-org/about.html#citing-stan",
    "href": "mc-stan-org/about.html#citing-stan",
    "title": "About the Stan Project",
    "section": "Citing Stan",
    "text": "Citing Stan\nWe appreciate citations for the Stan software because it lets us find out what people have been doing with Stan and motivate further grant funding.\nWe appreciate citations for the Stan software because it lets us find out what people have been doing with Stan and motivate further grant funding. When citing Stan we recommend citing both Stan itself as well as the particular interface used.\nTo cite Stan itself you can cite the Stan Reference Manual or Stan User’s Guide taking the year and version from the latest release on the Stan Project’s Github releases page: https://github.com/stan-dev/stan/releases.\n\nStan Development Team. YEAR. Stan Reference Manual, VERSION. https://mc-stan.org\nStan Development Team. YEAR. Stan User’s Guide, VERSION. https://mc-stan.org\n\nTo cite the interface or post-processing package you used we recommend using the citation conventions for the language (R, Python, Julia, etc.) associated with the interface or package. For example, to cite RStan use the standard conventions for citing R packages."
  },
  {
    "objectID": "mc-stan-org/about.html#support-stan",
    "href": "mc-stan-org/about.html#support-stan",
    "title": "About the Stan Project",
    "section": "Support Stan",
    "text": "Support Stan\n\nContribute Money\nStan operates through NumFOCUS, a U.S. 501(c)(3) nonprofit organization that serves open-source software projects including NumPy, Julia, Jupyter, ScikitLearn, and many more.\n\nContribute to Stan via NumFOCUS    (Salsa Labs payment processing)\nSponsor Stan via GitHub\n\n\n\nContribute Expertise\nWe welcome new Stan contributors!\n\nCode\nWrite\nHost events"
  },
  {
    "objectID": "mc-stan-org/about.html#shop-for-stan-swag",
    "href": "mc-stan-org/about.html#shop-for-stan-swag",
    "title": "About the Stan Project",
    "section": "Shop for Stan Swag",
    "text": "Shop for Stan Swag\nIf you’re looking to infer in style, stop by one of our shops for Stan t-shirts and mugs.\n\nStan Shop [US]   (Spreadshirt US)\nStan Shop [UK]   (Spreadshirt UK)"
  }
]